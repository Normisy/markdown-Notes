“算法模型正在取代科学探究中的数学模型，计算模型在模拟自然现象，求解数学上难以求解的答案上有着优势，算法在其中扮演着重要的角色”

和61B不同，该课程中Java语法的内容很少，主要着眼于算法与数据结构

# Lecture 1. 并查集
并查集是一种用于解决所谓动态联通性问题的数据结构，本节课会介绍快速查找和快速合并两个经典算法

并查集问题的模型大体如下：

> [!Question] 
>有一组被标号为0到N-1的N个对象，假设两个对象之间可以相互联通，**有一个操作可以将两个对象进行联通**。现在问题的关键在于**查询两个对象之间是否能够联通**，若能够联通，返回“是”，反之返回“否”

我们需要**能对大量的对象高效地支持这样的联通操作和联通查询**，为了满足时间和空间上的需求，我们需要设计出一个这样的数据结构来高效地解决问题
该问题只关心“**两对象之间是否有通路**”，而不关心具体的通路是什么，这部分会在讲到确切找出路径的算法时介绍（

我们**将对象简单地映射为整数0到N-1**，我们需要对“联通”进行一个正式的描述：
我们假设“连接到”是**等价关系**：每个对象都能链接到自己；还是一个**对称关系**：若P链接到Q，那么Q链接到P；并且具有**传递性**：P链接Q，Q链接R，那么P链接R
有了这样的等价关系后，一个对象和链接的集合就可以分成一个子集，称为**连通分量：互相连接的对象的最大集合**，例如下图就是三个连通分量，其中一个只有一个对象：
![[Pasted image 20240924173745.png]]
连通分量具有如下性质：**连通分量中的任意两个对象都是相连接的，连通分量内的对象不与其他连通分量中的对象相连接**

那么为了高效地进行查询和合并，我们需要维护连通分量。
**查找：检查两个对象是否在同一个连通分量中**
**合并：将包含两个对象的分离替换为其并集**
![[Pasted image 20240924174028.png]]
为此，我们设计数据结构：**并查集UF**，它支持以下操作：
```
UF(int N)    创建N个对象的并查集
void union(int p, int q)    在p和q号对象间建立连接
boolean connected(int p, int q)    查询p和q号对象间是否有通路
```
实现时要记住：操作和对象数量可能非常大，我们要保证算法在大数据的情况下也能保持高效

## 1.1 快速查找与不快速合并
快速查找是一种用于求解动态连通性类问题的**贪心算法**，我们用于支持该算法的数据结构并查集**是一个简单的对象索引整数数组：当对象P和对象Q是联通的，它们在数组中的项保持相同**，例如：
![[Pasted image 20240924174645.png]]
这里0、5、6  |  3、4  |  1、2、7在同一个联通分量中
我们**只需要检查对象P和Q在数组中的项是否相同，就可以查找得出两个对象是否连通了**
而为了**进行两个对象的连通合并，我们需要将两个给定对象其一的id项变为与另一对象相同的id项**，不妨选择将P的id值改为与Q的id值相同的值
所以**将两个对象P和Q进行连通，需要将P以及其连通分量中的所有对象的id值改为Q的id值**
**在未进行任何联通时，我们简单地让对象P的id值就为其在0~N-1中的编号P**

构造和查询连通的代码非常直接了：
```
public class QuickFindUF {
	private int[] id;

	public QuickFindUF (int N) {
		id = new int[N];
		for (int i = 0; i < N; i++)
			id[i] = i;
	}

	public boolean connected(int p, int q) {
		return id[p] == id[q];
		}
}
```
合并操作也很直接：
```
public void union(int p, int q) {
	int pid = id[p];
	int qid = id[q];
	for (int i = 0; i < id.length; i++) 
		if (id[i] == pid) id[i] = qid;
}
```
也就是遍历整个数组，找到与p的id项相同的项，赋上q的id值

这是最简单的一种实现，我们看看其效率如何：
对于这个算法，我们只需要考虑**代码需要访问数组的次数**，在实现中我们可以看见**初始化和合并操作都包含了需要遍历整个数组的for循环，这代表它们以正比于N的次数访问数组**
显然这样的开销太大了，如果我们在N个对象上N次执行合并操作，其复杂度就是平方级别。**平方级别的时间开销太慢了，对于大型问题，这样的算法是不能接受的**

## 1.2 快速合并与可能会很慢的查找
我们使用一种称为**快速合并**的策略来改进我们的算法。这实际上是所谓的**懒惰策略：我们尽量避免计算，直到不得不进行计算**
它使用相同的数据结构，即大小为N的id数组，但是**数组含义不同：我们将数组视为一组树，即一片森林的集合**，如下图：
![[Pasted image 20240924181235.png]]
数组中的每一项包含它在树中的父节点，比如上图中3的父节点是4，4的父节点是9。现在**每个对象都有一个根节点，即它所在树的根节点**，我们**规定一个子节点指向它的父节点，树中的根节点指向自己**，因此对象9指向它自己
利用这个数据结构，**我们将一个对象与一个根节点相联系**，**该根节点就表示了它所在的连通分量**

所以，**在id数组中，一个对象的值就是它的父节点的编号**，例如上图中2和4的父节点是9，那么$id[2]=id[4]=9$
我们可以通过**检查两个对象的==根节点==是否相同，从而确定它们是否在同一连通分量中，即它们是否互相连通**

可以看见查询操作比起随机访问的常数复杂度要慢一些，但合并操作相当简单：**将对象P和对象Q进行合并，我们只需要将P的根节点的id值改为Q的根节点的id值即可**，通过简单地改变一个值来进行合并
代码也相对简单：
```java
public class QuickUnionUF {
	private int[] id;

	public QuickUnionUF(int N) {
		id = new int[N];
		for (int i = 0; i < N; i++)
			id[i] = i;
	}

	public int root(int i) {  //查找根节点
		while (i != id[i]) i = id[i]; 
	}

	public boolean connected(int p, int q) {
		return root(p) == root(q);
	}

	public void union(int p, int q) {
		int i = root(p);
		int j = root(q);
		id[i] = j;
	}
}
```
检查一下快速合并算法的性能：
![[Pasted image 20240924183002.png]]
不幸的是，虽然比起快速查找快了一些，**在平均情况下比快速查找快，但是在最坏的情况下，树可能太高了，回溯查询的开销可能非常大（得回溯整棵树）**

## 1.3 改进快速合并
一种非常有效的改进方法称为**带权**，目的是**在实现快速合并算法时执行一些操作来避免得到很高的树**
如果将一颗大树和一颗小树进行合并，我们会希望尽量避免把大树放到小树下面，因为这样会得到更深的树。依此思想，**带权维护的是每棵树中对象的个数，然后通过确保将小树的根节点作为大树的根节点的==子节点==（即把小树放在大树下）来维持平衡**
通过将小树的根节点作为大树根节点的子节点，我们**拓宽了树的宽度**，避免产生更深的树，我们先看看代码实现：
在之前的基础上，我们需要一个额外**数组sz**来维护**对于每个根节点，所有以该对象为根节点的树的结点个数**
维护的方法也很简单，**在合并时将大树根节点的sz值加上小树根节点的sz值即可**：
```
public void union(int p, int q) {
		int i = root(p);
		int j = root(q);
		if (i == j) return;
		if (sz[i] < sz[j]) {id[i] = j; sz[j] += sz[i];}
		else               {id[j] = i; sz[i] += sz[j];}
	}
```

从数学上，我们可以证明**我们的操作的时间与结点在树中的深度成正比，且树中任意结点的深度上限为$\log_2N$**
这是很小的数值，让我们来进行粗略的证明：
设某节点x所在的树为T1，与另一棵树T2进行合并。
从算法中，我们可以发现如果合并时x的深度加1，只可能是T2的大小大于等于T1时，即将T1的根节点作为子节点移到T2的根节点下面
也就是说，**此时T1的大小是T1和T2合并后的树的大小的小于等于$\frac{1}{2}$倍**，那么如果我希望**一个从单节点开始的节点，增长到深度为N的位置，那么树的大小至少要翻倍$\log_2N$次**，也就是最坏情况下对于一棵树，其结点深度为$\log_{2}N$
![[Pasted image 20240924193921.png]]

这个例子中，我们的算法还可以进一步改进：**使用==路径压缩==——当寻找一个节点的根节点时，我们会遍历该节点到根节点上的所有节点，那么我们可以在遍历的过程中，==让途径的所有结点都指向根节点==
```
private int root(int i) {
	while (i != id[i]) {
		id[i] = id[id[i]];  
		i = id[i]
	}
	return i;
}
```
可以证明，这样展开树后，若有N个对象，M个合并与查找操作的任意序列，只需要访问数组$C(N+M\lg^{*} N)$次，其中$\lg^{*}N$代表将N变成1所需取对数的次数，称为==迭代对数函数==**。有$\lg^{*}(2^{65536})=5$，因此可以认为$\lg^{*}N \leq 5$

这个结果非常接近关于N的线性时间复杂度了（$M\lg^{*} N$很小），不过实际上可以证明完全线性时间复杂度的算法是不存在的，**并查集不存在线性时间的算法**
实际应用中已经足够用于解决大数据量的问题了

## 1.4 并查集的应用
该算法的一个很经典的应用是**在图像处理中标记图像中的区域**，Kruskal最小生成树算法就是一个基于并查集的图像处理算法
物理上，也可以用于检测一个系统是否会出现“渗滤”：对于一个N\*N的方形网格，每个小方格称为位，**每个位是开放的的概率为p**，**当一个系统从顶端到底端有一条处处开放的路径时，称其为渗滤的**

当开放的概率p比较中等时，系统渗滤的可能就很难说是大还是不大了。这个问题中存在一个相变：系统渗滤的可能随p值变化很陡峭
![[Pasted image 20240924202139.png]]
它是无法精确求解的，我们只能通过计算模型，使用**仿真**来试图决定这个概率的值
仿真的过程就用到了我们的快速并查集算法

### 1.4.1 渗滤的蒙特卡洛仿真
我们将整个网格首先初始化为处处闭合的，然后随机加上开放的位，每次加一个，并且**检查系统在加了这个开放位后是否变得渗滤**
这个实验运行上百万次，其关键步骤就是检测系统是否变得渗滤，这一步就可以使用并查集算法了
我们将网格中的每个位构建为一个对象，然后**当加上一个开放位时，检测周围四格是否有开放位，对这些开放位依此执行连通操作，因此每次加位后执行连通操作的数目可能为0、1、2、3或4次**
由于渗滤的定义是网格的上端到网格下端，这两排的点，如果一个个去使用并查集检测，即使检测是线性复杂度，也得要平方级别的时间，因此我们**不妨在上下两排假想两个位，它们连着上面和下面一排的所有位**：
![[Pasted image 20240924202830.png]]
这样我们就只需检查这两个假想位是否连通了，使用快速并查集算法即可
最后计算出来的渗透阈值就是这样的图像，约为0.593
![[Pasted image 20240924202955.png]]

# Lecture 2. 算法分析
我们需要有一个科学的基础来了解算法的性能，这次讲座介绍的就是算法的性能分析。
我们的重点放在预测和比较算法性能的能力，对算法性能的预测和设计最著名的例子是FFT快速傅里叶变换算法，它将信号的N个采样波形分为若干周期分量，暴力做法是N的平方级别时间，而FFT却只要NlogN，它成为现代数字媒体技术的一个基石

## 2.1 观察程序的运行时间
很多领域中，对算法进行直接观察分析是很简单的，一种最简单的观察方法是看表：直接记录程序起止时间，J**ava标准库中就有一个秒表类`Stopwatch`，其方法`double elapsedTime()`可以计算用掉的时间**。
对于一个程序，我们很自然地会想到使用越来越大的输入来运行它，以测量它随输入量的性能变换
这就是所谓的**经验分析法**，**计算实际时间来进行时间-数据量曲线的绘制，采用回归的方法拟合出一条曲线**
往往我们将数据量N取对数$\log_2$来进行绘制，所以往往会得到一条直线，代表算法的时间为$aN^k$，k为直线的斜率
斜率可以通过每次把输入数据量翻倍的形式简单地估算得到：计算N和2N运行时间的比率，得到的是“N变为原来的2倍，时间变为原来的m倍”，k = m/2；而对于系数a，直接根据运行时间$t=aN^k$计算即可。
虽然程序运行时间影响因素很多，但是关键因素还是在算法以及数据量上，因此通过这样直接比较的方式得到指数k，然后计算a是一种很常见的估算方法

## 2.2 使用数学模型
使用数学模型估计算法性能的思想基于“**通过识别所有的基本操作，计算操作执行的开销，然后计算操作执行的频率，将所有操作开销乘上频率求和就是总的执行时间**”这种频率分析思想
而现在计算计算操作开销无需查表，对于很多操作我们**只需假定它是一个已知的常数即可**；**而有些操作和输入数据总量N是成正比的**，例如分配一个大小为N的数组(java默认将数组元素都初始化为0)，又或者**连接两个字符串的时间与字符串长度成正比**（不是常数，因为要分配空间）

实际上，在估计算法性能时我们并不一定关心细节上的时间，粗略的估计依然是很有用的，**我们只需要对开销最大的操作进行计数即可，即开销最大的和执行最多的那些操作**
所以我们在计算时间复杂度时，**忽略掉常数项，只在意与输入量N有关的那些操作，同时还会忽略掉N的低阶项，因为当N过大时低阶项的增长过于缓慢了**
一些常见的求和与近似如下
![[Pasted image 20240924215635.png]]
直接使用这些结论即可

## 2.3 增长顺序分类
分析算法时我们不会碰到很多各不相同的函数，因此我们可以将算法随问题大小的变化程度进行分类
我们讨论的算法中许多都能被下图的几个函数所描述：
![[Pasted image 20240925184425.png]]
当我们在讨论算法的**增长阶数**时，我们忽略前面的常系数。在上面的**双对数log-log图**中，从constant开始逆时针的几根图像分别代表复杂度为1、logN、...（就是图最上面的顺序）
可以发现，对于复杂度logN的算法，它已经非常接近常数，问题的规模对速度的影响不大；对于线性复杂度N和NlogN的算法，它们的运行时间成比例适应问题的规模，是我们主要希望设计出来的算法；对于更陡峭的复杂度，它们都不适合求解大型问题
下面是常见的复杂度与代码的对应关系：
![[Pasted image 20240925190101.png]]
对于logN的算法，每次问题的规模随着处理而变成原来的$\frac{1}{c}$，c为常数，最典型的例子就是二分搜索；对于**NlogN线性对数阶**的算法，它源于**分治法**的算法设计技巧，归并排序就是一个典型的例子

二分搜索是一个典型的理论上简单实际实现会有很多磨人的小错误的算法，主要在于整数的边界问题
可以证明，对于运行时间：
$$ T(N)\leq T(\frac{N}{2})+1$$
将右项的T也不断应用这样的不等式，就可以得到二分搜索的复杂度范围了：
![[Pasted image 20240925194048.png]]

## 2.4 算法理论
围绕时间复杂度分类，近年出现了许多研究。一种设计算法的原则是考虑最坏情况；另一种则是考虑随机情况，即平均时间复杂度
常用的符号表达如下：
![[Pasted image 20240925201735.png]]
对于很复杂的算法，确定上下界比较困难，也往往很难确定一个问题的最优方法，这也是很多人投入算法分析理论的原因

## 2.5 内存需求
虽然在不同的机器上会有所不同，但典型的内存占用如下：
![[Pasted image 20240925204136.png]]
指针的内存占用实际上是很大的，分析空间复杂度时，我们主要在意那些被new出来储存于堆上的对象。看表即可

# Lecture 3. 栈和队列
栈和队列都是用于管理多个对象的数据结构，它们的区别仅在于**取出元素时的选择方式不同：栈取出最近加入的元素，而队列取出最先加入的元素**
本节课需要特别遵守的原则是**模块化编程：将接口与实现完全分离**。客户端代码根据需求选择实现，实现则只完成它被指派的操作。Java这样的面向对象的语言很适合进行这样的模块化编程

## 3.1 栈
假设我们有一个字符串的集合，我们想要实现对该集合定期取出并返回最后加入的字符串，同时可以检查集合是否为空，这就是我们的接口：插入操作、出栈函数、检测栈是否为空和栈大小函数
客户端在检测到'-'时进行一次弹栈操作，这样便于对栈的功能进行设计
我们的第一个实现**使用链表来进行栈的实现**：执行入栈操作，在单链表尾部插入一个结点；执行出栈操作，删去单链表的第一个结点，返回其元素
出栈操作很容易实现，只需要用一个中间变量保存好要删去结点的值即可：
```
public class LinkedStackOfString {
	private Node first = null;
	private class Node {  //内嵌类
		String item;
		Node next;
	}

	public boolean isEmpty() {
		return first == null;
	}

	public void push(String item) {
		Node oldfirst = first;
		first = new Node();
		first.item = item;
		first.next = oldfirst;
	}

	public String pop() {
		String item = first.item;
		first = first.next;
		return item;
	}
}
```
这是一个很完美的栈的链表实现，每个接口都没有循环，只需要常数时间
在Java中，每个对象会有16字节的额外空间，因为有内嵌类，又增加了8个字节；每个栈结点需要40字节，估计的空间复杂度为40N

栈还有更快的实现。因为在很多算法中会用到栈（深度优先遍历），所以对栈操作再次提速是有必要的。另一种实现栈的自然方式是**使用数组来储存栈上的元素**
在链表和数组之间的选择经常会在算法中反复遇到，这里的介绍可以为之后更复杂的应用进行铺垫

使用数组，我们将栈中元素保存在数组中，索引为N的位置对应于栈顶的位置，入栈时将新元素加入s\[N]处，而出栈时将s\[N-1]处的元素返回，并且使N减1
使用数组的一个根本性缺点是**必须事先声明数组的大小**，所以栈会有一个确定的容量，当栈容量小于元素个数时就要进行处理

我们先让客户端提供栈大小`capacity`，初步地实现上面所说的接口：
```
public class FixedCapacityStackOfStrings {
	private String[] s;
	private int N = 0;

	public FixedCapacityStackOfStrings(int capacity) {
		s = new String[capacity];
	}

	public boolean isEmpty() {
		return N == 0;
	}

	public void push(String item) {
		s[N++] = item;
	}

	public String pop() {
		return s[--N];
	}
}
```
但客户端往往无法知道栈的确切大小，因此这个API是不合理的

而且要考虑内存问题：
由于Java的**对象游离机制：在栈的数组实现中有对象的引用，但将一个元素弹出栈后，即使我们不再使用该元素，但数组中依然有该元素的指针**，导致占用内存。**我们将出栈元素位置设置为null就可以解决这个问题：**
```
public String pop() {
	String item = s[--N];
	s[N] = null;
	return item;
}
```

## 3.2 调整数组大小
现在我们来看解决之前的API需要事先提供固定大小的数组的技术
首先考虑每次入栈一个元素时将数组大小加1；出栈一个元素时将数组大小减1，那么对于N次操作，由于我们分配内存只能新分配一个足够大小的空间，然后将老元素复制过去，所以时间为$1+2+\dots+N\sim N^2/2$，这样的性能是不可接受的
著名的解决方法是**反复倍增：每次建立新数组时建立一个大小翻倍的数组，将所有元素复制过去**，这样就不需要频繁复制了
```
public ResizingArrayStackOfString() {
	s = new String[1];
}

public void push(String item) {
	if (N == s.length)  resize(2*s.length);
	s[N++] = item;
}

private void resize(int capacity) {
	String[] copy = new String[capacity];
	for (int i = 0; i < N; i++) 
		copy[i] = s[i];
	s = copy;
}
```
这样一来，我们只需要平均N个时间复杂度就可以完成插入N个元素的操作了，因为$N + (2+4+8+\dots + N)\sim 3N$
这样的分析来源于**平摊分析**的思想：将一次操作花费的时间平摊分给所有元素

另一个问题则是**如何在出栈后缩小数组**。我们也许会认为当栈只有一半是满的的时候将容量缩减一半，但是有一种现象称为**抖动现象：如果客户端刚好反复地交替出栈和入栈，在数组满时就会反复地新建数组和复制，这也会带来平方级别的复杂度**。因此我们**不希望缩小后的数组太满**。有效的解决方案是**在数组变为原来的$\frac{1}{4}$满时才将容量减半:**
```
public String pop() {
	String item = s[--N];
	s[N] = null;
	if (N > 0 && N == s.length/4) resize(s.length/2);
	return item;
}
```

这保证了我们所使用的内存是数组元素个数的常数倍，同时resize操作不是很经常发生，平摊到所有对象的时间复杂度上也足以让人接受：只有当栈大小为2的幂次时，才会调用resize()方法，即在向一个空栈推入N个元素的过程中，执行次数$k = \log_2N$

## 3.3 队列
采用和栈同样的基本API，我们来考虑队列的实现。我们用出队enqueue和入队dequeue操作取代出栈pop和入栈push操作
还是先用链表进行实现。**队列需要两个指针：一个指向最前面的结点，进行删除操作；一个指向最后面的元素，在它的后面添加新结点**
```
public class LinkedQueueOfStrings {
	private Node first, last;

	private class Node {
		String item;
		Node next;
	}

	public boolean isEmpty() {
	return first == null;
	}

	public void enqueue(String item) {
		Node oldlast = last;
		last = new Node();
		last.item = item;
		last.next = null;
		if (isEmpty())  first = last;
		else            oldlast.next = last;
	}

	public String dequeue() {
		String item = first.item;
		first = first.next;
		if (isEmpty())  last = null;
		return item;
	}
}
```
链表实现很简单，下面看看也不算困难的数组实现：
考虑到两个指针指向队头和队尾，有一个要注意的情况是**指针的位置超过数组的最大容量时，将指针设置为指向s\[0]，然后经过和栈类似的调整大小操作后，把指针再移回该在的地方**

## 3.4 泛型编程
我们希望将之前的String类型的栈和队列扩展到任何类型都可以使用，使用泛型编程，我们就可以定义一个自己所希望的类型的数据结构：
```
Stack<Apple> s = new stack<Apple>;
Apple a = new Apple();
Orange b = new Orange();
s.push(a);
s.push(b);   //报错
a = s.pop();
```
这里将非定义的类型对象b入栈时会在编译时报错。**模块化编程欢迎编译时错误，避免运行时错误，因为这样就能在编译时提前检测到问题**，而运行时错误只有在使用时才可能发现
泛型编程的语法并不困难：
```
public class Stack<Item> {
... 省略，将所有String改成Item即可，Item也可以改成别的名字
}
```
Java不允许创建泛型数组，我们得使用强制类型转换：
```
s = (Item[]) new Object[capacity];
```
的形式才可以间接获得。Object是一个关键字
虽然优秀的的代码最好避免强制类型转换，但是这里的转换无可避免，算是语言的一个令人讨厌的小特性
对于基本类型，如果想使用泛型编程的容器，需要使用java提供的包装类，比如int的包装类Integer
基本类型打包和解包的过程是自动的，我们只需在需要类型的时候使用包装类即可
```
Stack<Integer> stack = new Stack<Integer>();
```

## 3.4 迭代器
我们希望允许客户端遍历我们的栈或队列数据结构，而不知道底层的实现是使用链表还是数组，为此java提供了**遍历机制**
**可遍历对象：具有返回迭代器的方法的类
迭代器：具有hasNext()和next()方法的类（虽然java也提供remove()方法，但它有可能成为调试隐患，因此不考虑）
next()方法返回指向下一个结点的指针，而hasNext()用于查询是否有下一个结点。
一个可遍历类就可以使用范围for循环来减少我们的代码工作量了**
```
for (String s: stack)
```
所以为我们的数据类型提供迭代器实现是很值得的。我们为栈实现返回迭代器的方法，**使用`implements`声明我们实现的接口为`Interable<Item>`的接口：**
链表实现的栈
```
public class Stack<Item> implements Interable<Item> {
...其他方法和成员
public Interator<Item> iterator() {return new ListIterator();}
private class ListIterator implements Iterator<Item> {
	private Node current = first;

	public boolean hasNext() {return current != null;}
	public void remove() {/* 不支持，最好编写一个异常抛出来防止调用 */}
	public Item next() {
		Item item = current.item;
		current = current.next();
		return item;
	}	
}

}
```

数组实现的栈
```
public class Stack<Item> implements Interable<Item> {
...其他方法和成员
public Interator<Item> iterator() {return new ListIterator();}
private class ListIterator implements Iterator<Item> {
	private int i = N;

	public boolean hasNext() {return i > 0;}
	public void remove() {/* 不支持，最好编写一个异常抛出来防止调用 */}
	public Item next() {
		return s[--i];
	}	
}

}
```

实际上很多客户端并不关心我们返回元素的顺序，而是直接向集合中插入元素和遍历已有元素，这种数据结构称为**背包**
背包的API有：向背包加入一个元素；获取背包的大小；获取一个背包的迭代器
这个很好实现，**只需要把栈和队列的出栈和出队操作移除即可，因为背包内元素的顺序不重要，所以使用哪个都行**，这里不赘述

另外还需要注意，链表实现的数据结构迭代器和数组实现的迭代器有区别：队列中的元素往往不会存储于下标0~N-1的位置（出队入队的操作导致的），因此数组迭代器的返回值有可能和我们所想的有些不同，同时组织顺序是先进后出；而链表的元素则按先进先出的顺序组织的，可以直接使用迭代器，按照我们所想的下标进行组织

## 3.5 应用
栈和队列有一些非常复杂的应用，在java的库中就能找到栈和队列的实现，但是在开发的过程中被添加了许多可能用不上的API，同时我们不知道其性能如何，所以我们最好还是使用自己的一些简单数据结构，等对库有所了解之后再使用它们

### 3.5.1 栈的应用
**Dijkstra双栈算术表达式求值算法：给定一个中缀算术表达式如$(1+((2+3)*(4*5)))$，有操作数和操作符，希望对表达式的结果进行求值**
算法的思想很简单：
**从左至右**处理表达式，维护两个栈：
- **看见数值，放在数值栈上；
- **看见操作符，放入操作符栈；**
- **看见左括号，忽略；**
- **看见右括号，将栈顶的操作符和两个操作数出栈，将运算结果入数值栈**

实现代码如下：
```
public class Evaluate {
	public static void main(String[] args) {
		Stack<String> ops = new Stack<String>();//操作栈
		Stack<Double> val = new Stack<Double>();//数值栈
		while (!Stack.isEmpty()) {
			String s = StdIn.readString();
			if (s.equals(‘(’)) continue;
			else if (s.equals('+'))  ops.push(s);
			else if (s.equals('*'))  ops.push(s);
			else if (s.equals(')')) {
				String op = ops.pop();
				if (op.equals('+'))  vals.push(vals.pop() + vals.pop());
				else if (op.equals('*'))  vals.push(vals.pop() * vals.pop());
			}
			else vals.push(Double.parseDouble(s));
		}
		StdOut.println(vals.pop());
	}
}
```
这里只实现了加法和乘法，而且没有考虑符号之间的优先级，如果希望完成更好的计算器，我们可以为操作符建立一个优先级表，显示计算时应该优先计算哪些表达式

# Lecture 4. 排序介绍
## 4.1 典型基本排序问题
排序问题：将数组中的n个元素根据元素中定义的**关键字**进行升序排列
例如，通过`java.io.File`中的`File`类，为其传递一个目录路径：
```
File directory = new File(args[0]);
```
使用该类的`listFiles()`方法，就可以获得目录下的所有文件名组成的数组：
```
File[] files = directory.listFiles();
```
然后通过排序算法对所有文件名按字母表顺序进行排序

除此之外，还有基于数字大小顺序进行的排序等关键字类型截然不同的排序问题，我们希望**实现一个适合多种数据类型关键字的排序程序**，使得它们可以被不同客户端使用
我们采取的策略是一种称为==**回调**==的机制：**使用指向客户端中给排序函数传入对象数组的那段可执行代码的指针（函数指针）**
这基于Java的一个隐含机制：**只要任何数据类型对象的数组具有`compareTo()`方法，排序函数就会在需要比较两个该类型元素时回调数组中对象对应的compareTo()方法**
不同的语言有不同的实现回调函数的机制，其核心思想是**将函数作为实参传递给其他函数**，例如cpp中的==**谓词**==，对于Java，由于需要在编译时检查类型，它使用的是称为**接口interfaces**的特殊**方法**

`compareTo()`方法来自于接口`Comparable`，使用`implements Comparable`来声明其实现：
```
public class File implements Comparable<File> {
	...
	public int compareTo(File b) {
		...
		return -1;  //返回-1表示小于
		...
		return +1； //返回+1表示大于
		... 
		return 0;  //返回0表示等于
	}
}
```
**泛型类型一般填上当前类名**，因为我们要进行的是类之间的比较

而我们的排序算法函数需要接受一个**类型为`Comparable[]`的参数：**
```
public static void sort(Comparable[] a)
```
这是因为排序需要使用到`Comparable`中的`compareTo()`方法，而**排序的实现中，是不含任何具体数据类型的，其中的比较都是由`Comparable`接口进行处理的**，例如：
```java
public static void sort(Comparable[] a) {
	int N = a.length;
	for (int i = 0; i < N; i++)
		for (int j = i; j > 0; j-- )
			if (a[i].compareTo(a[j-1]) < 0)
				exch(a, i, j-1);  //实现在后面，起到把i和j-1进行交换的作用
			else break;
}
```
不同类型的`Comparable`数组最终会被相同的方式排序，它直接回调到被排序对象类型的`compareTo()`的具体实现代码
 `compareTo()`方法实现的是**全序关系：元素在排序中能够按照特定顺序排列，满足以下三个性质：**
- 1. 非对称性：若$v\leq w$，且$w\leq v$，那么$v=w$
- 2. 传递性：$v\leq x, x\leq w \rightarrow v\leq w$
- 3. 完全性：v和w要么一个小于等于另一个，要么两个相等
很多我们考虑的关键字的数据类型都有这样的自然的全序关系，但也有不满足全序关系的，例如石头剪刀布这样的循环关系不满足传递性

按照这样的规则，我们可以使用`Comparable`接口对任何数据类型进行排序，把实现隐藏在机制之下，同样地，**交换操作也可以使用`Comparable`接口进行封装**：
```
private static void exch(Comparable[] a, int i, int j) {
	Comparable swap = a[i];
	a[i] = a[j];
	a[j] = swap;
}
```
声明数组`Comparable[]`时，储存的实际上是**任何实现了`Comparable`的对象，这适用于所有接口**，起到了多态性的作用
另一个需要的操作是`less`，用于判断俩对象之间的大小关系：
```
private static boolean less(Comparable a, Comparable b) {
	return a.compareTo(b) < 0;
}
```

## 4.2 选择排序
第一个基本排序思想很简单：**在第i次迭代中，我们在数组剩下的项中找到最小的，然后把它和剩下的项中的第一项进行交换**
使用两个指针来进行扫描，指针i左侧的项是已经被从大到小排序完成的
```
public class Selection {
	public static void sort(Comparable[] a) {
		int N = a.length;
		for (int i = 0; i < N; i++) {
			int min = i;  //用于储存指针i右边最小元素的索引
			for (int j = i+1; j < N; j++)
				if (less(a[i], a[min]))  min = j;
			exch(a, i, min);
		}
	}

	less和exch函数如前所述
}
```
选择排序的开销很简单，最坏情况下进行了$\frac{N^2}{2}$次比较less，N次交换exch
而且它进行比较的次数**与输入的序列无关，它总是需要扫描所有项进行比较来找到最小值，进行less比较的次数总是N的平方的数量级**

## 4.3 插入排序
插入排序依然是进行索引i从左到右的扫描，不同的是在第i次迭代中，**确保i当前与左侧的项是递增的**，每次从i开始往左前进，设迭代器为j，对于不满足递增关系的a\[j]，我们将a\[j]移动至其左边一个的位置
```
public class Insertion {
	public static void sort(Comparable[] a) {
		int N = a.length;
		for (int i = 1; i < N; i++) 
			for (int j = i; j > 0; j--)
				if (less(a[j], a[j-1]))
					exch(a, j, j-1);
				else break;
	}

	less和exch的实现如前所述
}
```
插入排序需要使用大约$\frac{N^2}{4}$次比较和交换操作，这个证明比较复杂，因为涉及到了随机的变量
插入排序与选择排序的性能不好说哪个更好，因为它的交换操作会更多，在某些情况下会优于选择排序时进行大量的无用比较，某些情况下大量的交换操作则成了累赘

用定量的关系考虑，我们定义**逆序对：数组中非顺序的一对关键字**
如果一个数组**部分有序**，即只有一部分的几个元素是无序的，那么此时**插入排序的运行时间是线性的：交换的次数与逆序对的个数相等，视为常数**，在此之前需要将一个元素与它左侧的元素进行比较，总共n-1次

## 4.3 希尔排序
希尔排序的出发点是**插入排序效率低下的原因是每个元素每次只向前移动一个位置**，我们每次如果将元素进行若干次排序（**称为对数组的h-排序，任意间隔为 h 的==元素对==之间已经按照升序（或降序）排列**），那么算法就能进行优化
我们称**一个具有h个交叉的有序子 另一个问题是对于希尔排序，应该使用何种递减序列？ 序列的递减方式是一个研究了很久的课题，我们只能提出一个性能不错的，但不知道它是否是最好的
我们采用$3x+1$的增量序列：首先找到一个范围内的满足该形式的最大增量，这里我们取最大增量$h_{max}\leq \frac{N}{3}$，让h从1开始，通过`h = 3*h + 1`达到最接近$h_{max}$的位置：
```java
public class Shell {
	public static void sort(Comparable[] a) {
		int N = a.length;
		int h = 1;
		while (h < N/3)  h = 3*h + 1;  //1、4、13、40、...最大阈值设为N/3，有些方法直接让h=N，然后h按照h = h/3 + 1的方式递减，性能也可以

		while (h >= 1) {  //h=1时就是插入排序，此时因为前面的过程，整个序列已经接近有序，只需要少量的交换即可变为有序
			for (int i = h; i < N; i++) {
				for (int j = i; j >= h && less(a[j], a[j-h]); j += h)  //从i开始，每次按步长h取元素，进行比较
					exch(a, j, j-h);
			}
			h = h/3;  //通过这个方式递减h
		}
	}

	//less和exch的实现如前所述

}
```

## 4.4 洗牌
排序的一个简单应用是洗牌：假设有一组扑克牌，我们希望随机地摆放卡牌至每个位置，达到洗牌的效果
这似乎和排序正好相反，但实际上这种洗牌的思想是：**为每个元素（卡牌）产生一个随机实数，将这些随机数升序排列，把对应的元素放在相应位置上**
可以证明这种方法在输入中没有重复值时可以产生一个均匀的随机排列
这种方法中，我们是否真的需要完全进行一次排序来达到随机分布的目的？答案是否定的
一种更简单且只需要线性时间的方法是：**遍历整个元素的数组，遍历到i时，我们都随机且均匀地从0和i之间挑选一个整数r，将a\[i]与a\[r]位置上的元素进行交换**
通过这样的交换，在第i张牌左边的牌都是被随机均匀地洗过的，并且只需要线性时间
```
public class StdRandom {
	...
	public static void shuffle(Object[] a) {
		int N = a.length;
		for (int i = 0; i < N; i++) {
			int r = StdRandom.uniform(i + 1);  //在0到i之间取一个随机数
			exch(a, i, r);
		}
	}
}
```
注意，**为每个数选择一个0~n-1的随机位置，让其与该位置元素进行交换并不能洗出一副随机均匀的卡牌，这是生成随机数的机制导致的限制**，因为在随机函数`random`的实现中，它使用32位的种子来进行随机数的生成，这就导致可能的洗牌结果只有$2^{32}$，而一个均匀随机的洗牌结果应该有$n!$种
所以如果我们简单地为我们的卡牌游戏设置类似下面这样的洗牌方法，那玩家很容易就能猜出洗牌的规律了：
![[Pasted image 20241007222444.png]]

## 4.5 计算几何：凸包
假设平面上有一个N个点构成的集合，从几何角度，我们可以找到一个**凸包：能包含所有点的最小的凸多边形**，所有点集都有凸包
凸包在数学上还有很多等价的定义，我们希望编写一个程序来生成给定点集的凸包
根据凸包的定义，我们应该输出**该凸多边形的顶点序列（它们都是点集中的点）** 来表示该凸包（那些在边上却不是顶点的点应该被舍弃）

计算几何往往是很困难的，尤其是在这种会出现简并性的问题上，实际情况会更为复杂。从物理角度看，点集中的点相当于是一堆钉子，凸包则是一条包围这些钉子的橡皮筋，用外层的钉子作为支撑
凸包有两个很好的几何特性：
1. 选择凸包上**y坐标最小的点（最低点）p**，将该点与点集中任意一点连成一条向量，这些向量在极坐标系中的**极角值从右往左递增**
	![[Pasted image 20241008132523.png]]

2. **对于凸包上的每一点**（上图的点p、1、5、9、12），**任意两点之间只能通过一条逆时针的路径到达**（反例：对于点集{1, 3, 2}，从1走到2只能通过顺时针的路径1->3->2达成）

我们将要学习的算法：==**葛立恒扫描法**==，就基于上述两个性质
**以最低点p作为起始点，按照以p为起点的向量的极角的大小，从小到大地将点集中的所有点进行排序（上图中为点标号1、2...）**，然后**舍弃那些导致无法产生逆时针旋转的点**（往往**枚举连续三个点**，检测**头尾**两个点能否**逆时针**到达，如果**不能**，则**舍弃掉==中间那个点==**）
例如枚举到下面这种情况时：
![[Pasted image 20241008135631.png]]
由于从1到5无法通过逆时针旋转到达，因此**舍弃掉中间的4**，；同理在5->6->7中，5到7无法逆时针到达，**舍弃掉中间的6**，以此类推

算法的实现其实涉及到一些计算几何的手段，比如如何判定逆时针到达和顺时针到达，我们重点不在于此，所以不作细究。
我们只关注这里需要使用到**排序算法**的两个地方：**1. 找到y坐标值最小的点p； 2. 将极角从小到大排序，并且为点标号**
可以发现，**排序的依据是点的不同属性**，在下一节会讲解**如何根据不同属性对同一类型进行排序**

补充一下判断两点能否通过逆时针移动到达的计算方法：
假设平面上有三个点a、b、c，我们需要从a走到b，再从b走到c才能从a走到c，下图左侧是一个逆时针移动的例子，而右侧则不是逆时针移动的：
![[Pasted image 20241008141336.png]]
不考虑简并的情况下，这样的计算并不困难：**计算每两点之间的斜率k，从a到c若$k_{ab}>k_{bc}$，就是逆时针；$k_{ab}<k_{bc}$，则为顺时针；相等，说明b是线段ac上的一点**
同时也有可能**两点连线是竖直的，斜率无限大**，而且也要考虑斜率相等时三点共线的情况，还要考虑浮点数计算精确度的问题，所以实际的编程过程会很复杂

计算几何的研究者已经解决了这些问题：
计算**点a,b,c连成向量所围成的平行四边形**的**有符号面积，如果面积＞0，为逆时针；面积=0，为共线（包括共同一竖线的情况）；面积＜0，为顺时针**：
![[Pasted image 20241008142607.png]]
这样一来就把斜率的计算转变为了叉乘的计算，避免了无穷大的情况，实现如下：
```
public class Point2D {
	private final double x;  //设置为final,使变量变为无法修改的常量
	private final double y;

	public Point2D(double x, double y) {
		this.x = x;
		this.y = y;
	}

	...

	public static int ccw(Point2D a, Point2D b, Point2D c) {
		double area2 = (b.x - a.x)*(c.y * a.y) - (b.y - a.y)*(c.x * a.x);
		//计算叉乘
		if (area2 < 0)  return -1;  //顺时针
		else if (area2 > 0) return +1;  //逆时针
		else  return 0; //共线
	}
}
```

借助函数ccw，我们可以对点进行扫描。**在凸包内的点的存储和更新用到了栈**：
```java
Stack<Point2D> hull = new Stack<Point>(); 

//数组p存储的是所有点
Arrays.sort(p, Point2D.Y_ORDER);   //将p按照y值排序，p[0]是y值最小的点
Arrays.sort(p, p[0].BY_POLAR_ORDER);  //将p中的其他点按照与p[0]点所成极角排序

//使用栈来进行凸包元素的存储
hull.push(p[0]);   //最低点必定在凸包里
hull.push(p[1]);   //从第1个点开始枚举

//枚举p中的所有点，利用ccw函数判断一串点中的第一个点到最后一个点是否构成逆时针转弯
for (int i = 2; i < N; i++) {
	Point2D top = hull.pop();  //弹出栈顶元素，它是最近枚举过的那个点，作为1号点
	
	while (Point2D.ccw(hull.peek(), top, p[i]) <= 0)
		top = hull.pop();   //peek查看栈顶元素，也就是弹出了一个栈顶元素后的栈顶元素，是中间点，当前遍历的点p[i]则是最后点，如果不构成逆时针转弯，弹出栈顶元素，即删除所有中间点
	
	hull.push(top);  //把1号点放进栈中
	hull.push(p[i]);  //把最后点放进栈中
	//如果没有进入while，中间点不会被弹出栈，依然保留
}

```

# Lecture 5. 归并排序
## 5.1 归并排序与优化
归并排序是系统和应用内两个重要的排序算法之一，它的大致思想就是将原来的数组一分为二，然后把分成的小数组再递归地一分为二...，这样把最小的单元进行排序后，按顺序进行合并，整个数组就排好序了
假设有**两个已经从小到大排好序**的数组，我们会将两个指针放在两个数组首端，比较两个指针指向的值：**如果一个指针指向的值小于另一个指针，将该值放进空答案数组里，移动这个指针而不动另一个指针**
从最小细分的数组开始，数组由小到大持续进行这个合并过程，就是归并排序的过程了
以此类推，可以将两个排好序的数组合并为一个排好序的大数组，其实现很简单：
```java
private static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi) {   //lo和hi是数组开头和结尾的索引，mid是数组中间的索引
	assert isSorted(a, lo, mid);
	assert isSorted(a, mid+1, hi);  //assert进行断言：确保后面的条件成立，否则抛出异常

	for (int k = lo; k <= hi; k++)
		aux[k] = a[k];
	
	int i = lo, j = mid+1;  //两个子数组的指针
	for (int k = lo; k <= hi; k++) {
		if (i > mid)                   a[k] = aux[j++];
		else if (j > hi)               a[k] = aux[i++];
		else if (less(aux[j], aux[i])) a[k] = aux[j++];
		else                           a[k] = aux[i++];
	}

	assert isSorted(a, lo, hi);
}
```
代码加入了非常多的断言`assert`，它们有助于帮助理清代码逻辑以及提示一段代码的作用：`assert`语句**接受一个boolean变量，如果该变量为false，则会抛出异常**
可以**在运行程序时**允许或禁止assert抛出异常：
```
java -ea MyProgram   //允许assert抛出异常
java -da MyProgram   //默认情况，禁止assert抛出异常
```

有了这样的合并代码，那么递归的归并排序就很简单了：
```java
public class Merge {
	private static void merge (...) { ... //如前所述 }

	private static void sort(Comparable[] a, Comparable[] aux, int lo, int hi) {
		if (hi <= lo) return;
		int mid = lo + (hi - lo)/2;  //计算中点值
		sort(a, aux, lo, mid);
		sort(a, aux, mid+1, hi);
		merge(a, aux, lo, mid, hi);
	}

	public static void sort(Comparable[] a) {  //提供操作更简单的接口
		aux = new Comparable[a.length];
		sort(a, aux, 0, a.length - 1); 
	}
}
```
这里重载的后一个sort不仅仅提供了更简单的接口，还将答案数组aux的**创建放在了递归之外**，这**避免了在递归过程中创建许多小的辅助数组从而导致的性能损失**

归并算法的算法时间复杂度是NlogN，它的计算满足下面的递归式子：
设C(N)代表N个元素的归并排序中进行比较的次数，A(N)代表进行数组访问的次数，那么有
![[Pasted image 20241008165853.png]]
左半、右半和进行合并时所花费的C和N在图中标出了，注意取整的不同，而且从数组a进行元素拷贝到数组aux这个过程的数组访问次数为2次
对于形如$D(N)=2D(N/2)+N, 其中N>1,D(1)=0$ 的递归式，有
$$ D(N) = NlgN$$'不妨假设N为2的幂次，那么有下图成立：
![[Pasted image 20241008170923.png]]

因为归并排序分到最后，就是2个元素为一组进行单独排序，所以最后地推的次数也就是lgN
（底数为2，这里省略了）用公式写出，用数学归纳法可以证明它适用于N为任意实数的情况：
![[Pasted image 20241008171618.png]]
将N视为2N即可

而对于内存占用，归并排序的一个特点是**它需要随N增大而增大的额外空间，因为有一个额外的答案数组来存储答案，而非“原地存储”**
而真正的原地归并排序，虽然有可行的方法，但是过于繁琐，有待被发现

我们可以对归并排序进行进一步的优化，这种优化技巧也适用于其他算法：
对**特别小的数组使用归并**会很繁琐，因为始终需要进行细分+重排。对此我们可以进行**切分：对于小于某个数值的小数组采用插入排序，而不是继续归并**，这样能提高其效率：
```
private static void sort(Comparable[] a, Comparable[] aux, int lo, int hi) {
	if (hi <= lo + CUTOFF -1) {  //如果hi与lo的距离小于界限CUTOFF，采用插入排序
		Insertion.sort(a, lo, hi); 
		return;
	}
	int mid = lo + (hi - lo)/2;
	sort(a, aux, lo, mid);
	sort(a, aux, mid+1, hi);
	merge(a, aux, mid, hi);
}
```

另一个改进是**如果merge之前的两个子数组之间已经是有序的，那么跳过这轮归并**，这只需要判断**前一半最大的数是否小于后一半最小的数**：
```
private static void sort(Comparable[] a, Comparable[] aux, int lo, int hi) {
	if (hi <= lo + CUTOFF -1) { 
		Insertion.sort(a, lo, hi); 
		return;
	}
	int mid = lo + (hi - lo)/2;
	sort(a, aux, lo, mid);
	sort(a, aux, mid+1, hi);
	if (!less(a[mid+1], a[mid])) return;  //如过该轮细分下，前一半最大的数小于后一半最小的数，那么说明它们已经是有序的了，无需再次合并
	merge(a, aux, mid, hi);
}
```

还有一个改进比较费解：为了**节省拷贝到辅助数组**的时间，**在每一轮递归时转换一下原数组和辅助数组的角色**
也就是在
```
	sort(a, aux, lo, mid);
	sort(a, aux, mid+1, hi);
	merge(a, aux, mid, hi);
```
时，每轮递归把`a`和`aux`交换一下，代码可以这么改：**将sort的结果放进另外的数组，然后把merge作用于该数组的结果合并进原数组**，从而节省了拷贝的开销

(自下而上的归并排序所谓的第一趟操作指的是递归到最深的基准情况时所进行的那步合并)
## 5.2 自下而上的归并排序
自下而上的归并排序并不是递归方法，它把开始未排序的**每一个元素**都视为**一个已经排好序的序列**，然后按原归并排序的反方向，把这些长度为1的序列合并为长度为2的序列......最后一步步合并为最终的总的序列
```
public static void sort(Comparable[] a) {
	int N = a.length;
	aux = new Comparable[N];
	for (int sz = 1; sz < N; sz = sz+sz)   //sz是当前合并的子序列大小
		for (int lo = 0; lo < N-sz; lo += sz+sz)
			merge(a, lo, lo+sz-1, Math.min(lo+sz+sz-1, N-1));
}
```
可以看见每次大小sz都是按原来的两倍进行增长的，所以外层复杂度为logN；内层循环则对子序列依次进行merge归并，**由于末尾的子序列长度可能不够sz，所以merge函数中右端点的参数为`Math.min(lo+sz+sz-1, N-1)`**，特别处理这种情况
这就是一个很好的业界使用的归并排序实现，除了会使用多余的空间以外没有别的缺点

这里也可以看出，归并排序的N并不需要一定是2的幂次，对于无法对齐的情况，它也是可以正常运行的

## 5.3 归并排序的复杂性
计算复杂性复杂性的目的是建立一个用于研究特定问题的**所有解决算法的效率**的框架。我们首先需要建立一个**计算模型：计算算法允许执行的操作**
对于排序，我们需要评判的就是进行比较的次数，我们为它寻找**上界与下界**，以评判解决该问题的最坏与最好情况。我们希望最优算法能保证拥有很好的性能，其上界与下界往往相同
**算法复杂性的计算模型通常使用==决策树==，成本模型则是比较的次数**：
对于三值比较a、b和c，普通的排序的决策树为：
![[Pasted image 20241008190959.png]]‘决策树的深度就是我们要找的上界：最差情况下的比较次数。

命题：一个**基于比较的排序算法**，在**最差情况**下至少需要使用$lg(N!)$，等价于$NlgN$次比较：
高度为h的二叉树至少有$2^h$个叶子结点，对于N个数，其叶节点数至少为$A_N^N=N!$
$$ 因此有2^h \geq N! \Rightarrow h\geq lg(N!)$$
由斯特林公式，$lg(N!)$正比于$NlogN$，因此命题得证

可以发现**归并排序就时间而言，是比较排序算法中最优的**（NlogN的时间复杂度），但是需要额外的空间
当然，在算法要求一些额外信息的输入，比如键值的分布与性质、输入的顺序等时，下界可能并不成立，因为可以利用这些信息达到更快的速度

## 5.4 比较器
java的比较器是一种可以帮助我们根据不同键值来进行元素比较的机制
为了能够为任何类型数据进行比较的定义，我们使用java的`Comparable`接口，它在`java.lang`包中被定义，用于定义对象的**自然排序顺序，该逻辑封装在类的内部**：
```
public class Date implements Comparable<D> {
...
}
```
我们要在类中实现的是`compareTo(D that)`方法，它返回int，+1代表大于，-1代表小于，0代表等于，我们在该方法中定义这种类型的数据的比较关系

还有一个不同的接口称为`Comparator Interface`，这是一种**帮助排序**的接口，用于**对相同的数据使用不同的顺序方式**（例如不同语言有着不同的排序，但它们都是字符串）
该接口定义在`java.util`包中，**它不需要修改原有类的代码，而是在类外部定义好比较逻辑，然后传递给用户进行比较**
它再次表示它将实现一个方法`compare`，该方法比较给定类型`Key`，它必须
```
public interface Comparator<Key>
	int compare(Key v, Key w)
```
类似于cpp中的函数指针，比较器的对象可以作为函数的参数被传递给排序函数，然后排序函数使用比较器对象提供的规则进行排序
比较器`Comparator`是一个对象，它具有一个方法`compare`用于比较，如：
```
public class NameComparator implements Comparator<Person> {
    public int compare(Person p1, Person p2) {  //定义compare对象
        return p1.getName().compareTo(p2.getName());
    }
}
```
而如果希望向方法传递一个**比较器对象**，通过增加一个`Comparator`类型参数来实现：
由于我们将比较与类相分离，我们**传递一个普通对象数组，而不是一个`Comparable`可比较对象数组**
```
public static void sort(Object[] a, Comparator comparator) {
	int N = a.length;
	for (int i = 0; i < N; i++)
		for (int j = i; i > 0 && less(comparator, a[j], a[j-1]); j--)
			exch(a, j, j-1);
}

private static boolean less(Comparator c, Object v, Object w) {
	return c.compare(v, m) < 0;
}

private static void exch(Object[] a, int i, int j) {
	Object swap = a[i]; a[i] = a[j]; a[j] = swap;
}
```
这里将比较器对象传递给函数，这样就可以调用其`compare`方法进行比较
一个类中可以定义多个`Comparator`对象，根据需要进行调用：
```
public class Student {
	public static final Comparator<Student> BY_NAME = new ByName;
	public static final Comparator<Student> BY_SECTION = new BySection;

	private final String name;
	private final int section;
......
	private static class ByName implements Comparator<Student> {
		public int compare(Student v, Student w) {
			return v.name.compareTo(w.name);
		}
	}

	private static class BySection implements Comparator<Student> {
		public int compare(Student v, Student w)
	}
}
```

## 5.5 稳定性
当我们对一个对象使用按不同方式进行排序时，例如对学生列表按照名字与成绩两个成员进行排序时，如果首先按名字首字母排序，然后按成绩排序的话，在算法不理想的情况下，按成绩排序所得到的表格的学生名字会一团糟（成绩相同的学生名字首字母无规律）
但如果我们希望在**对一个已经有一定顺序排列的对象，进行另一种比较后，对于键值相等的对象，组内的顺序保持原有顺序**，这就是**排序算法的稳定性问题**了

先说结论，**插入排序和归并排序是稳定的排序算法，而希尔排序和选择排序不是**，这可以通过算法对于**是否会略过相等元素**的处理方式的分析来得到
- 插入排序：插入排序在每次不满足递增关系的a\[i]，我们将a\[i]移动至其左边的位置

# Lecture 6. 快速排序
## 6.1 实现与优化
快速排序广泛用于多种系统中作为默认的排序算法，它也是一种递归算法，和归并排序不同，它的基本思想是在排序后进行递归，而归并排序是在排序之前递归
快速排序也基于分治思想，我们先介绍一种**随机快速排序**：它首先**对整个数组进行洗牌**，这一步后面再说；
然后进行数组a的分割：任意选择一个值K，将其移动到位置j，K也就是$a[j]$的值，保证它：
- 在j的左侧没有比$a[j]$更大的数
- 在j的右侧没有比$a[j]$更小的数
依据j位置上的点进行区间的一分为二，对于两个区间也进行这样的选点->排序工作（**后续不需要洗牌**），最后递归排序完成整个数组的排序
因为我们对整个数组先进行了一步洗牌，那么**随机取的值K只需要取第一个位置上的值就可以**了
有些实现中，在下面的交换过程随着每次找到小于等于选定值的数时，维护一个**分割位置++** 的操作，用于确定最后的值K应该在的位置（为小于等于K的元素空出空间）

使用两个指针，一个在数组第二个位置，从前往后移动；另一个在数组末尾位置，从后往前移动。当前面的指针遇到**小于等于选定值**的数，**往后移动**，直到遇到第一个大于该值的数**停止**；后面的指针则是遇到**大于等于选定值**的数才**向前移动**，直到停止。当**两个指针都停止时**，**交换**它们的值，然后继续移动，直到两个指针相遇（**交叉**时），最后将第一个位置上选中的值与尾指针相交换即可（因为最后出现了交叉，此时尾指针比头指针靠前了，指向的是小于选定值的部分）

这个过程通过while循环实现：
```java
private static int partition(Comparable[] a, int lo, int hi) {
	int i = lo, j = hi + 1;
	while (true) {
		while (less(a[++i], a[lo]))  //++i除了移动指针之外，还用于维护最后的基准元素K的位置
			if (i == hi)  break;  //这个if用于避免越界

		while (less(a[lo], a[--j]))
			if (j == lo)  break;  //也是防止越界，不过是多余的

		if (i >= j)  break;  //出现两个指针交叉，即头指针比尾指针大了，就退出循环
		exch(a, i, j);  //否则，在停止的时候进行交换
	}
	
	exch(a, lo, j);  //最后i==j，都是最后基准元素的位置，进行最后一次交换即可
	return j;
}
```
其中，`int lo`是左边界第一个数的索引，所以下面移动i和j的`less`判断都是根据`a[lo]`得到的；`int hi`是右边界最后一个数的索引，所以j的初始值要在尾后，i的初始值要在第一个值（本来应该是第二个值），因为先执行移动，再执行判断（前置运算符）
**方法返回的是选定元素最后所在的位置**

算法本身则是一个递归地使用该过程的过程：
```java
public class Quick {
	private static int partition(Comparable[] a, int lo, int hi) {
	...  }

	public static void sort(Comparable[] a) {
		StdRandom.shuffle(a);  //事先洗牌，提高性能，后面叙述
		sort(a, 0, length-1);
	}

	private static void sort(Comparable[] a, int lo, int hi) {
	if (hi <= lo)  return;
	int j = partition(a, lo, hi);
	sort(a, lo, j-1);
	sort(a, j+1， hi);
	
	}
}
```
快速排序的一个好处是不需要额外的空间，但是要**格外注意边界情况**，主要是因为指针交叉的情况很棘手。
在存在两个相等的值时

### 平均情况复杂度推导
设要排序的键值有N个，$C_N$是N个键值的平均比较次数，则有
$$ C_N = (N+1) + (\frac{C_0+C_{N-1}}{N})+ (\frac{C_1+C_{N-2}}{N})+\dots+(\frac{C_{N-1}+C_{0}}{N}) $$
这是一个递推式，将两边乘上N就可得到：
$$ \begin {align}
C_N*N \quad&= N(N+1)+2(C_0+C_1+\dot+C_{N-1})\\
NC_N-(N-1)C_{N-1}\quad&=2N+2C_{N-1}\\
\frac{C_N}{N+1}\quad &=\frac{C_{N-1}}{N}+\frac{2}{N+1}
\end {align} $$
然后再进行以下的递推拆分并使用积分近似：
![[Pasted image 20241102210541.png]]
可以得出最后的**平均情况比较次数**大约是$O(NlgN)$，很接近线性复杂度了
我们对数组事先进行的洗牌工作，**就是为了保证随机性，使得最终的复杂度接近平均情况，达到一个令人满意的性能**，不然会有可能出现二次时间复杂度（现在这个概率特别小了）

如果不洗牌，最坏情况下的复杂度：
$$ N+(N-1)+(N-2)+\dots +1 \sim \frac{N^2}{2}$$
这是因为在待排序序列已经完全排好序的情况下，整棵二叉树退化为单支二叉树，因此出现了平方级别的复杂度。进行洗牌可以最大程度地避免出现这种情况产生

洗牌操作是对数时间复杂度，小于NlogN，因此不会增加总的时间复杂度

**这样的快速排序是不稳定的，因为对于两个相同键值，可能会在交换的过程中换位（i >= j条件有等于）**

### 一些优化
#### 1. 截断优化
对于很小的子数组，使用快速排序也是会产生不必要的开销的，这时候没必要使用快速排序，而是像前面一样，**在某个截断值以下采用插入排序，使得排序过程更快：**
```
private static void sort(Comparable[] a, int lo, int hi) {
	if (hi <= lo + CUTOFF - 1) {
		Insertion.sort(a, lo, hi);
		return;
	}
	int j = partition(a, lo, hi);
	sort(a, lo, j-1);
	sort(a, j+1, hi);
}
```

#### 2. 尝试估计选取值K
我们可以尝试估计分区元素K。**三数中值法：取数组中间的那个元素和两个端点元素，获得三者的中位数，然后根据中位数，将该元素与首元素进行互换，而不是选取有随机性的每个子区间的首元素**
```
private static void sort(Comparable[] a. int lo, int hi) {
	if (hi <= lo)  return;

	int m = medianOf3(a, lo, lo + (hi - lo)/2, hi);
	swap(a, lo, m);

	int j = partition(a, lo, hi);
	sort(a, lo, j-1);
	sort(a, j+1, hi);

}
```
它的好处是，使用这样选取的中值作为选定值K进行数组的划分，能够**减少出现极端情况导致分区不平衡现象的发生**，以及减少递归深度、提高缓存局部性等等
中位数当然可以从很多个元素中选，但是实践证明只需要在这三个中位数之间进行选，能够提供最好的速度优化，约为10%

## 6.2 选择问题

> [!QUESTION] 选择问题
> 在含有n个项的有序数组中，找到第k大的元素

这个问题简单但是在很多数据处理的场景下会使用，在k比较小的情况下，比如取最值，我们直接遍历求max的复杂度上下限都是N；
而在快速排序算法中，我们可以通过参数k来控制区间，实现**快速选择**：
```
public static Comparable select(Comparable[] a, int k) {
	StdRandom.shuffle(a);
	int lo = 0, hi = a.length - 1;
	while (hi > lo) {
		int j = partition(a, lo, hi);
		if (j < k)  lo = j+1;
		else if (j > k)  hi = j-1;
		else        return a[k];
	}
	return a[k];
}
```
可以看见，每次进行子区间的排序后，我们查询当次选定元素所在位置j（函数返回值）以及位置k的大小关系
而对于选定元素，快速排序的性质是一次操作后它左侧的数都小于该元素，右侧的数都大于该元素，**这个性质就是帮我们找到第k大元素的关键所在**
我们调整下一次的区间，**使得快速排序时所选择的数最后所在的位置为k**，这就证明数列中有k-1个小于它的数，其它数都大于它，即该数是第k大的数

### 复杂度证明
快速选择的**平均复杂度为$O(N)$**，下面给出证明
直观来说，每一步
```
int j = partition(a, lo, hi);
		if (j < k)  lo = j+1;
		else if (j > k)  hi = j-1;
		else        return a[k];
```
的分区操作中，**数组被分为两半**，也就是比较次数为：
$$ N+N/2+N/4+\dots+1 \sim 2N$$
不过其实每部分的时间并不是刚好减半，只是**平均时间减半**了

我们分析以下最坏情况下的比较次数，采用和快速排序类似的比较次数分析有：
$$ C_N = 2N+2k\ln(N/k)+2(N-k)\ln(N/(N-k))$$
在最坏情况下，$k=N/2$，此时
$$ C_N = (2+2\ln2)N$$
是线性时间复杂度
同样的，它也是有可能出现二次时间复杂度的，但是概率非常小

## 6.3 大量重复键值的情况：三路分区
实际应用中，会出现元素键值大量重复的情况，通常的目的是将键值相等的元素组合在一起，同时文件数据量会很大
这种情况下，如果直接采用快速排序，会出现二次时间复杂度；归并排序比较次数则在$\frac{1}{2}N \sim N\log N$之间，我们希望进行改进
一个自然的方式是**将所有和分区值相同的元素放在同一处**，也就是所谓的**三路分区**：
![[Pasted image 20241103121452.png]]
这时我们使用了**四个指针和三个分区**，指针lt和gt是分界指针
这个方法的工作步骤是：设我们使用指针i进行遍历，选定值v是$a[lo]$，区间第一个值
- 当$a[i]<v$时，将$a[lt]$与$a[i]$交换，**同时递增lt和i**
- 当$a[i]>v$时，将$a[gt]$与$a[i]$交换，**只递减gt**
- 当$a[i]==v$时，**只递增i**
- 当i和gt相遇时，分区完成
指针lo和hi只起到防止越界和划定总区间的作用，**lt和gt的初始值等于lo和hi**

可以看到，通过这样的工作机制，我们可以很简单地把相等的键值都放在中间的区域，并且拥有很好的性能，这点在代码实现之后叙述

代码实现很直观：
```java
private static void sort(Comparable[] a, int lo, int hi) {
	if (hi <= lo)  return;
	int lt = lo, gt = hi;
	Comparable v = a[lo];  //选定值
	int i = lo;
	while (i <= gt) {
		int cmp = a[i].compareTo(v);
		if      (cmp < 0)  exch(a, lt++, i++);
		else if (cmp > 0)  exch(a, i, gt--);
		else               i++;
	}

	sort(a, lo, lt-1);
	sort(a, gt+1, hi);
	//对两侧子区间也进行这样的排序
}
```

### 复杂度分析
假设有n个各不相同的键值，且第i个出现次数为$x_i$，**任何基于比较的排序算法都至少**需要使用
$$ C = \lg(\frac{N!}{x_1!x_2!\dots x_n!})\sim -\sum_{i=1}^{n}x_i\lg\frac{x_i}{N}$$
次比较，而这种方法所需的比较次数正好就是这个值，所以是最优的
具体的数学证明超出了本书的范围，这里不作讨论

## 6.4 系统级的排序应用
一个快速的排序算法通常都作为应用程序的基础架构的一部分，例如java的`Arrays.sort()`方法
`import java.util.Arrays`
对于不同的应用场合，这些系统的排序方法会采用不同的排序算法。例如java的这个方法在对于对象时采用归并排序，而对于基本类型时采用快速排序，因为设计者认为前者使用时占用空间不是一个很重要的因素

有一个很古老的排序算法叫做`qsort`，之前的优化实际上大部分是因为在使用它的时候发现了各种各样的问题而提出的
这种排序并没有使用洗牌来事先打乱顺序，而是使用`Tukey's Nighter`方法来选择分区项。
该方法简单地从数组中随机选取九个数，然后取它们的中位数的中位数，因此找到的分区元素更加趋近中间值

看似这个方法比随机洗牌要稳定一些，但是它其实是灾难性的。在测试时出现了类似于这样的“杀手输入”，导致程序崩溃：
![[Pasted image 20241103133335.png]]
它不进行随机排序，因此更容易遭受到这种攻击，由于是递归的算法，过长的递归会导致系统栈崩溃

可以看见，排序算法由于其基础性，我们需要考虑到足够完全的方面，进行各种优化和选择，下面是目前为止我们所讲的排序算法的特点：
- 选择排序：N次交换，很慢，平均$N^2/2$
- 插入排序：对于足够小的N或是部分排好的数列具有很好的性能，用于截断优化
- 希尔排序：代码少，不稳定，复杂度只知道最优N，对中等大小的输入效果好
- 归并排序：稳定且NlogN级别复杂度，需要额外空间
- 快速排序：NlogN，实践中最快，无需额外空间，但会出现平方级别复杂度（等键值过多）
- 三路快排：优化了等键值多情况下的快速排序复杂度过高问题

# Lecture 7. 优先队列与堆
优先队列：可以进行插入操作，但是删除操作每次删除优先删除最大值或最小值
它和队列与栈很相似，只是实现中元素键值必须可比较并且有`compareTo`方法

## 7.1 数组和链表实现
代码少，但是寻找最大项需要遍历整个数组，看看就好
![[Pasted image 20241103140100.png]]

## 7.2 二叉堆
二叉堆的概念基于完全二叉树，除了叶节点以外度均为2，显然只有结点个数到达$2^k$时高度才会增加，k为正整数
实现优先队列首先需要将信息与结点进行关联。在二叉树中，我们将键值放在结点中，并且为其赋予一个先后顺序：**父节点的键值不会小于其子节点的键值**，对于每个结点都成立
我们**使用数组放置这个二叉树**。首先，**将索引0空出来，从$a[1]$开始放置元素**，这样我们就可以根据顺序来放置每一层结点到相应位置了
首先放根节点到$a[1]$，然后从左到右放置第二层、第三层……的结点到数组中：
![[Pasted image 20241103144428.png]]
可以看到，**在实际的数据结构中，我们不需要把连接关系使用指针等手段显示出来，它就是一个数组**，通过对索引进行计算来在树中进行移动

首先可以知道的是，**根节点中的元素是整个树中最大的**，从构造规则就可以看出来
然后，通过计算索引来在树中移动：
$$ 
假设结点位于位置k，则有：\begin{cases}
父节点索引p=\lfloor\frac{k}{2}\rfloor \quad (下取整)\\
子结点索引s=\begin{cases}
2*k \quad ,左儿子\\
2*k+1\quad,右儿子
\end{cases}
\end{cases}
$$
这就是我们在数据结构中要保持的**不变量**

现在我们来看维护规则的处理。在二叉堆中：
- 如果**子节点键值大于父节点的键值**，那么这个子节点就需要**向上调整**，即**将子节点的键值与父节点的键值交换**，直到满足父节点比子节点键值大为止
这点实现很简单，我们也称为**游泳移动**：
```
private void swim(int k) {
	while (k > 1 && less(k/2, k)) {
		exch(k, k/2);
		k = k/2;
	}
}
```

所以，当我们将一个新元素**插入到堆中时**，可以从最底部的叶子层从左往右放置，也就是**放入数组的后一个位置**，然后对它使用游泳移动：
```
public void insert(Key x) {
	pq[++N] = x;
	swim(N);
}
```
最坏情况下需要$1+\log_2 N$次比较和交换

- 如果**父节点的键值小于子节点的键值**，那么这个父节点就需要**向下调整**，也就是**将父节点和两个子节点中键值更大的那个进行交换**，直到都满足二叉堆的键值为止
我们称这个过程为**下沉移动**：
```
private void sink(int k) {
	while (2*k <= N) {
		int j = 2*k;  //左孩子，右孩子是2*k+1即下面的j+1
		if (j < N && less(j, j+1))  j++;  //选择更大的那个孩子
		if (!less(k, j))  break;  //如果满足要求，就不需要交换了
		exch(k, j);
		k = j;     
	}
}
```

所以，当我们**将最大的元素删除出堆时**，首先记录这个最大值，然后**把最大值与数组最后一个叶节点的值互换，从数组末尾删去这个值**，然后将调换到根节点的键值一路向下调整至合适的位置：
```
public Key delMax() {
	Key max = pq[1];
	exch(1, N--);  //对调根节点和叶节点，然后删去叶节点
	sink(1);
	pq[N+1] = null;  //防止游离引用导致越界
	return max;
}
```

总的实现和之前所讲的数据结构没有很大不同：
```
//约束Key必须是Comparable接口的一个子类
public class MaxPQ<Key extends Comparable<Key>> {
	private Key[] pq;
	private int N;

	public MaxPQ(int capacity) {  //构造函数，提供大小参数
	pq = (Key[]) new Comparable[capacity+1];
	}

	private void swim(int k); 
	private void sink(int k);

	public void insert(Key key);
	public Key delMax();

	private boolean less(int i, int j) {
		return pq[i].compareTo(pq[j]) < 0;
	}

	private void exch(int i, int j) {
		Key t = pq[i];
		pq[i] = pq[j];
		pq[j] = t;
	}
}
```

可以看到，上移和下调操作都是$\log_2 N$的数量级别的
现在专家们对该数据结构的一个改进是把它变为一个**d-方向**的数据结构，而不仅仅是上下两种方向
**斐波那契堆**是一种更高级的数据结构，它由**一组按照最小堆性质组织而成的树构成，通过懒惰合并来合并堆，而不是重新组织树结构**，查找、插入、合并、减小键值的复杂度都是常数级别的，而删去最值的操作虽然也是对数级别，但频率减小了很多
常用于**堆优化版的迪杰斯特拉算法**等需要高效优先队列的场景

在我们的实现中，还需要一些改进使其更符合工程需求，例如在客户端试图从空的优先级队列中删除时**抛出异常**；我们应该有一个没有大小参数的构造函数，**让数组大小随使用而调整**

在程序编写中，我们常常需要控制一些值不可变：
```
public final class Vector {
	private final int N;
	private final double[] data;

	public Vector(double[] data) {
		this.N = data.length;
		this.data = new double[N];
		for (int i = 0; i < N; i++)
			this.data[i] = data[i];
	}
}
```
例如这里的向量，进行建立后就不可被其他方法或客户端改变了，我们的字符串就是一个这样的例子
在优先队列的使用中，**我们必须确保键值是不可变的**，不然若键值能被随意更改，堆的顺序就乱套了，所以我们要通过为每个键值创建保持它不可变性的对象
“**我们应该尽可能地限制变量的可变性，除非有充分的理由**”

## 7.3 使用二叉堆实现堆排序
堆排序的过程非常直观，对于N个键值，依次取出根节点的最值就可以了。取出根结点的键值是通过**将根节点键值与数组最后一个叶节点键值互换，然后取出该键值，删去叶节点，向下调整根节点**实现的

而在排序最初，**整个数组肯定是乱序的**，这意味着我们**需要将乱序的数组调整为符合堆顺序的结构**，这个过程是**自下而上**的
调整乱序初始数组顺序的操作是**从叶节点的父节点开始**，先右后左地检测**每个子树（三结点）** 是否符合堆顺序，调整至正确顺序后，继续检测叶节点父节点的父节点与其儿子组成的三节点子树，自下而上，直到所有三节点堆都被调整为堆顺序

```
public class Heap {
	public static void sort(Comparable[] pq) {
	//完全二叉树中，索引N/2到N的结点都是叶节点，因此从N/2开始到1向上进行调整，把原数组组织为堆
		int N = pq.length;
		for (int k = N/2; k >= 1; k--)
			sink(pq, k, N);

	//取出堆顶元素
		while (N > 1) {
			exch(pq, 1, N);
			sink(pq, 1, --N);
		}
	}

	private static void sink(Comparable[] pq, int k, int N);
	private static boolean less(Comparable[] pq, int i, int j);
	private static void exch(Comparable[] pq, int i, int j);
	
}
```
注意堆构建的过程，第一个非叶结点索引为N/2

### 时间复杂度分析
结论：堆的构建使用$\leq 2N$次比较和交换；而堆排序使用$\leq 2N\lg N$次比较和交换
它是第一个**不需要额外空间就可以保证最坏、最好和平均情况都为$N\lg N$的就地排序算法**，且非常简单
（快速排序虽然通过洗牌使最坏情况几乎不可能出现，但还是存在二次时间复杂度的）

然而，**虽然堆排序在时间和空间上都是很优秀的，但却有以下的缺点：**
- 内部的循环要深于快速排序
- 由于堆排序**需要将根节点移动到最远的叶节点位置（数组尾部）**，同时，数组是连续存储的，但**父子结点并不连续，排序过程中需要频繁上调下移，移动并不连续**，需要频繁在内存跳转的性质使得它**对于缓存命中率非常小，导致很慢**
- 堆排序是不稳定的

因此没有快速排序那么应用广泛，**缺乏连续性和局部性**

## 7.4 事件驱动模拟
**事件驱动模拟**用于研究和分析系统在**离散事件发生**时的动态行为，**主要关注系统中发生的关键事件**，这些事件导致系统状态的变化
也就是说，事件驱动模拟**并不需要在每个时间步长上进行状态的更新，而是只在事件发生时进行状态更新**，因此在事件发生频率稀疏的系统中有很高的效率


> [!QUESTION] 弹珠问题
> 密闭容器内有许多弹珠，弹珠碰撞到墙壁或其他弹珠，假设动量守恒，会根据其质量改变速度，碰撞到墙壁则相应使水平或竖直方向速度等大反向

显然，这就是一个事件驱动模拟的例子：弹珠方向改变当且仅当碰撞到墙壁或其他弹珠的时候。
弹珠的类实现：
```
public class Particle { 
	private double rx, ry;   //两个位置分量
	private double vx, vy;  //两个速度分量
	private final double radius; // 半径
	private final double mass; // 质量
	private int count; //撞击次数
	public Particle(...) { } 
	public void move(double dt) { } 
	public void draw() { }  // number of collisions 
	
	public double timeToHit(Particle that) { }  //预测粒子相撞时间
	public double timeToHitVerticalWall() { }   //预测撞垂直墙的时间
	public double timeToHitHorizontalWall() { }   //预测撞水平墙的时间
	public void bounceOff(Particle that) { }   //粒子撞击后的状态改变
	public void bounceOffVerticalWall() { }   //撞垂直墙后的状态改变
	public void bounceOffHorizontalWall() { }  //撞水平墙后的状态改变
}
```
可以看到，这里**事件驱动模拟的关键在于预测粒子是否会发生撞击，以及发生撞击的时间会是什么时候**
对于粒子相撞时间预测及状态变化，这是一个物理动量守恒问题，我们不作具体阐述，但是给出代码：
![[Pasted image 20241105141015.png]]
最后为粒子撞击的次数`count`递增
而撞墙很简单，垂直墙面（上下两面墙）把vy改为等大反向；水平墙面把vx改为等大反向即可

下面我们来看事件驱动模拟的主要部分
1. 对于每个粒子，我们**计算它会撞到墙壁的时间**，也就是当粒子走向墙壁时，需要多久与墙壁相撞
   我们**将预测的碰撞时间作为键值**，然后**把以碰撞时间为键值的事件放入优先队列中**

2. 对于每一对粒子，我们也**计算任意两个粒子可能会碰撞的时间**，并将其作为事件的键值，放到优先队列中去

可以发现，对于第二步骤，它是一个平方时间复杂度的过程
注意到，我们的预测是非常理想的，如果在发生理想中的碰撞之前发生了其他的碰撞，导致速度方向改变，使得理想中的碰撞不会发生，事件就会失效

我们将事件定义如下：
```java
private class Event implements Comparable<Event> {
	private double time;
	private Particle a, b;
	private int countA, countB;

	public Event(double t, Particle a, Particle b) {}  //构造函数：两个粒子之间在时间t会发生一个事件。当a为null或b为null，说明是粒子和水平或垂直墙之间的事件

	public int compareTo(Event that) {
		return this.time - that.time;  //按照发生时间进行排序
	}

	public boolean isValid() {}  //检测事件是否有效：如果碰撞被干预，就无效
}
```

整个系统：
```java
public class CollisionSystem {
	private MinPQ<Event> pq;
	private double t = 0.0;   //时钟时间
	private Particle[] particles;  //粒子数组

	public CollisionSystem(Particle[] particles) {};

	private void predict(Particle a) {  //预测一个粒子a的情况
		if (a == null)  return;
		for (int i = 0; i < N; i++) {
			double dt = a.timeToHit(particles[i]);  //遍历整个粒子数组，调用预测方法，预测粒子a和每个粒子的相撞时间
			pq.insert(new Event(t + dt, a, particles[i]));
			//相应事件加入小根堆
		}
		pq.insert(new Event(t + a.timeToHitVerticalWall(), a, null));
		pq.insert(new Event(t + a.timeToHitHorizontalWall(), null, a));
		//撞墙事件加入小根堆
	}

	private void redraw() {};
	public void simulate() {  //事件驱动模拟的主要循环
		pq = new MinPQ<Event>();
		for (int i = 0; i < N; i++)  predict(particles[i]);
		//平方复杂度的初始化过程...
		pq.insert(new Event(0, null, null));  //标志事件，确保模拟持续进行

		while(!pq.isEmpty()) {
			Event event = pq.delMin();  //取出时间最小的事件
			if(!event.isValid()) countinue;  //如果事件失效，就跳过这次事件
			Particle a = event.a;
			Particle b = event.b;

			for(int i = 0; i < N; i++)
				particles[i].move(event.time - t); //按时间更新每个粒子的状态
			t = event.time;  //更新时间至当前处理事件的时间

			if (a != null && b != null)  a.bounceOff(b);
			else if (a != null && b == null)  a.bounceOffVerticalWall();
			else if (a == null && b != null)  b.bounceOffHorizontalWall();
			//根据事件情况，进行事件种类的分析与处理

			predict(a);
			predict(b);
		}
	
	}
} 
```

# Lecture 8. 符号表
符号表ST背后的思想是实现以下的抽象概念：
- 将一个键值对插入符号表
- 给定一个键值，搜索它相应的值
例如，服务器的统一资源定位符URL和其IP地址就形成一组键值对，当然谁是键谁是值可以按使用情况区分
几乎所有的计算机应用系统都有一个到多个的ST，映射是一个很重要的概念，符号表就是在键值之间创建一个一一映射

最简单的符号表形式就是创建一个数组，在索引`key`的位置放上值`val`，虽然在键类型不符合要求时是非法的，但有利于我们理解ST的想法
**方法`get()`用于根据键取出值，若键不存在，返回`null`；方法`put()`使用新值覆写原有的旧值，没有旧值则创建一个键值对**
对于任何符号表，**检查键是否对应一个值**的操作实现是一致的：
```
public boolean contains(Key key) {
	return get(key) != null;
}
```

对于删除操作，我们使用懒惰删除，直接让键对应的值为`null`：
```
public void delete(Key key) {
	put(key, null);
}
```

根据不同应用场合，我们对键会有不同的假设：
- 键类型具有全序排列的性质，即实现了`compareTo()`接口的`Comparable`类型

- 键类型是不可排序的，只能**使用`euqals()`方法来判定相等性**

- 键类型不可排序，使用`equals()`方法判断相等性，同时使用哈希编码`hashCode()`为生成过程加入随机性

首先，**键的值必须是不可改变的**，必须抹去然后重新赋值
其次，`equals()`方法必须具备下面的特性：
- 反身性：`x.equals(x)`必定是`true`
- 对称性：`x.equals(y)`为真，当且仅当`y.equals(x)`为真
- 传递性：若`x.equals(y)`且`y.equals(z)`，则`x.equals(z)`
- 非空性：`x.equals(z)`为`false`
`equals`的默认实现是检测两个引用的对象是否是同一个，但大部分不会使用这个实现，而是自己定义
一般来说，一个标准的`equals`实现如下：
```
public final class Date implements Comparable<Date> {
	private final int mouth;
	private final int day;
	private final int year;
	...
	public boolean equals(Object y) {  //对象类型是Object，因为java中所有类都直接或间接继承自java.lang.Object类，它是所有类的父类，除非使用extends标明了继承关系
		if (y == this)  return true;  
		if (y == null)  return false;  //空指针检测
		if (y.getClass() != this.getClass())   return false;  //同类型检测

		Date that = (Date)y;   
		if (this.day != that.day)  return false;
		if (this.month != that.month)  return false;
		if (this.year != that.year)  return false;
	}

}
```
因为java规定所有`equals`的参数类型都必须是`Object`，它又是所有类型（没有明确其他继承关系的）的父类，所以`equals`方法支持任何类型对象的输入，因此要进行同类型检测

## 8.1 基本实现：二分搜索（对于有序排列的情况）
符号表是最基础的映射，它向其中搜索值是逐个遍历，找到那个符合`equals`的键，线性复杂度；而插入只需要向后端插入就行
而对于有排列顺序的有序表，我们可以将其构造为全序的，然后应用二分搜索即可获得更好的搜索性能；但是这样的插入操作需要把所有比插入值大的元素向后移动一格，线性复杂度

本节只展示二分搜索的代码
```
private int rank(Key key) {
	int lo = 0, hi = N-1;
	while (lo <= hi) {
		int mid = lo + (hi - lo) / 2;
		int cmp = key.compareTo(keys[mid]);
		if      (cmp < 0)  hi = mid-1;
		else if (cmp > 0)  lo = mid+1;
		else              return mid;
	}
	return lo;
}
```
可以看见，二分搜索的**问题主要在于无法动态维护有序结构**，因此我们需要研究一种能够动态维护顺序的数据结构，以使得插入操作性能到达让我们能够接受的范围内。

# Lecture 9. 二叉搜索树
二叉搜索树BST是一种让我们有效地实现符号表的经典数据结构
和优先队列中通过数组隐式实现的二叉树结构不同，BST中我们将讨论的是显式树的构造

二叉搜索树中：
- 每个结点可以视为左右两个子树的连接，子树可以为空
- 每个结点都有一个键值，每个结点的键值满足：**大于所有左子树中结点的键值，小于所有右子树中的键值**
所以，**每个结点除了键值对之外，还需要有两个引用，指向左右子树的根节点**

```java
private class Node {
	private Key key;
	private Value val;
	private Node left, right;

	public Node(Key key, Value val) {
		this.key = key;
		this.val = val;
	}
	
}
```

现在我们看看它的插入、查找和删除、迭代器操作：
搜索操作的过程和二分查找一样，当需要找的键小于当前结点的键，往左子树找；反之往右子树找

```
public class BST<Key extends Comparable<key>, Value> { 
	public Value get(Key key) {
		Node x = root;
		while (x != null) {
			int cmp = key.compareTo(x.key);
			if      (cmp < 0)  x = x.left;
			else if (cmp > 0)  x = x.right;
			else               return x.val;
		}
		return null;
	}
}
```

插入操作要做的就是按照与搜索操作相同的步骤，直到我们遇到一个相应位置为空的结点，将目标位置新建一个键的值是要插入的这个值的结点即可；如果这个值已经存在，就覆写它
插入操作采用递归调用的形式完成：
```
public void put(Key key, Value val) {
	root = put(root, key, val);  //从根节点开始调用递归方法，并且把返回值设置为根节点
}

private Node put(Node x, Key key, Value val) {
	if (x == null)  return new Node(key, val);  //如果碰到了空树，创建结点
	int cmp = key.compareTo(x.key);
	if      (cmp < 0)  x.left  = put(x.left, key, val);
	else if (cmp > 0)  x.right = put(x.right, key, val);
	else               x.val = val;  //直接覆写
	return x;
}
```
可以看到，客户端的方法只包含键和值，但我们的递归调用需要接收一个结点并返回，因此**利用函数重载和访问控制符实现一个封装**
因为二叉树和二分是一致的思路，其插入和搜索的复杂度都$\sim 2\ln N$，能提供平均状态下的最优性能

这种最简单的二叉搜索树的**形态取决于键值输入的顺序**，但是最坏情况下有可能退化为链表，而且我们无法通过随机化输入键值来避免这种情况（键值输入一个，新建一个结点，否则性能太慢），所以我们需要对整个数据结构进行优化

## 9.1 二叉查找树的有序操作
寻找二叉查找树中小于或大于某一给定键值的最大或最小值
给定一个键值K，**查询最大的小于该键值的键值**是多少：
- 若树中恰好有该键值K，那么返回值就是这个键值
- 若该键值K比当前遍历的根节点要小，那么返回值在左子树
- 若该键值K比当前遍历的根节点要大，那么返回值在右子树（当右子树存在小于等于K的键值时）；若右子树的每个键值都大于K，那么返回值就是当前根节点的键值。
```java
public Key floor(Key key) {
	Node x = floor(root, key);
	if (x == null)  return null;
	return x.key;
}

private Node floor(Node x, Key key) {
	if (x == null)  return null;
	int cmp = key.compareTo(x.key);

	if (cmp == 0)  return x;
	if (cmp < 0)   return floor(x.left, key);

	Node t = floor(x.right, key);
	if (t != null)  return t;  //存在小于等于key的键值
	else            return x;  //不存在，即右子树的所有键值大于key，则返回根节点
}
```

而对于返回树大小的操作，我们需要为结点增加一个数据域：**以该结点为根节点的子树的结点数是多少**
```
private class Node {
	private Key key;
	private Value val;
	private Node left;
	private Node right;
	private int count; //子树结点个数
}
```
那么整个树的大小只需要**返回根结点的`count`域值即可：**
```
public int size() {
	return size(root);
}

private int size(Node x) {
	if (x == null)  return 0;
	return x.count;
}
```

而在构建树或插入树的时候，维护`count`值：
```
private Node put(Node x, Key key, Value val) {
	if (x == null)  return new Node(key, val, 1);
	int cmp = key.compareTo(x.key);
	if      (cmp < 0)  x.left = put(x.left, key, val);
	else if (cmp > 0)  x.right = put(x.right, key, val);
	
	x.count = 1 + size(x.left) + size(x.right);  //这一步用于维护每个结点的count值
	
	return x;
}
```

对于问题：给定键值K，有多少树中结点的键值小于K，依然使用递归，但是有三种不同的情况：
```java 
public int rank(Key key) {
	return rank(key, root);
}

private int rank(Key key, Node x) {
	if (x == null)  return 0;
	int cmp = key.compareTo(x.key);
	if      (cmp < 0)  return rank(key, x.left);
	else if (cmp > 0)  return 1 + size(x.left) + rank(key, x.right);
	else               return size(x.left);
} 
```
三种情况如下：
- 对于等于键值K的根节点，小于K的所有结点数就是x的左子树的`size`
- 对于大于键值K的根节点，那么我们继续在该根节点的左子树中寻找，直到找到小于等于键值K的根节点
- 对于小于键值K的根节点，其左子树的所有结点自然也小于K，因此值是左子树的大小+1+向右子树搜索找到的小于K的结点个数（递归）

对于二叉搜索树的前中后序遍历以及序列的输出，我们维护一个队列来存储：
```java
public Iterable<Key> keys() {
	Queue<Key> q = new Queue<Key>();
	inorder(root, q);
	return q;
}

//中序遍历
private void inorder(Node x, Queue<Key> q) {
	if (x == null)  return;
	inorder(x.left, q);
	q.enqueue(x.key);  //中序遍历在遍历完左子树后才处理当前结点
	inorder(x.right, q);
}
```
其他的遍历只需要改变`q.enqueue(x.key);`的相对位置即可

## 9.2 二叉查找树的删除
传统的删除方法是懒惰删除，保留键以提供引导，但是为这个键赋予“删除”记号
但是这种方式对于空间非常不友好，而且重建二叉查找树时需要删除它们，需要换一个方式删除

### 1. 最简单的情况：最值结点的删除
对于最小结点的删除，我们知道它肯定在最左边，我们**只需要一直向结点的左儿子移动，直到遇到左儿子为空的结点，然后将其父节点的左儿子替换为该结点的右儿子，删去该结点即可**
![[Pasted image 20241121193536.png]]
```java
private Node deleteMin(Node x) {  
	if (x.left == null)  return x.right;
	x.left = deleteMin(x.left);  //deleteMin的设计上是返回更新后的输入结点，所以为了更新x，先假设这个函数能正常工作，将更新后的结点情况覆盖输入结点
	x.count = 1 + size(x.left) + size(x.right);  //更新左子树计数
	return x;
}

public void deleteMin() {
	root = deleteMin(root);
}
```

**`deleteMin(Node x)`** 的功能是：

- 在以节点 `x` 为根的子树中找到最小节点（即最左的节点）。
- 删除该最小节点。
- 返回删除最小节点后更新过的子树根节点（也就是**更新完成后的输入参数所指示的结点**）

编写的思路应该从输入-输出-功能三个方面思考：
- 输入：以 `x` 为根的二叉搜索树。
- 输出：删除最小节点后的二叉搜索树的根节点（**其实仍然还是返回输入的那个结点，只是该结点的左子树被更新过了（体现在`count`域参数的更新上）**）。
- 功能：找到最小节点并删除它，同时保持树的结构和性质不变。
- 假设递归调用 `deleteMin(x.left)` 能够正确删除左子树的最小节点，并返回更新后的根节点

对于删除最大项，其过程和这个也是类似的，只需要把`left`和`right`互换即可

### 2. 稍微普遍一点的情况：删除只有一个孩子的结点
假设我们需要删除的键值R所在结点只有一个儿子，这个情况和最小与最大结点一致：找到这个结点，将它的唯一一个儿子与它的父节点相连（连在该结点原来所在的那一侧），删除该结点即可
![[Pasted image 20241121203124.png]]

### 3. 删除有两个孩子的结点
假设我们想删除的键值E所在结点有左右两个儿子，一个删除的方法是：
找到**该结点右子树中的最小节点**，然后将这个结点的键值与我们想删除的结点键值互换，然后使用删除单孩子结点的方式删除掉它即可
![[Pasted image 20241121203755.png]]
不难发现，我们**也完全可以找到左子树中的最大结点**，使用类似的方式进行互换+删除。但我们只选择了单边，这种不平衡性也会是该删除算法不够令人满意的重要原因

代码如下：
```java
private Node delete(Node x, Key key) {  //和deleteMin一样，返回更新后的输入结点x
	if (x == null) return null;
	int cmp = key.compareTo(x.key);  //比较当前x的键值x.key与输入键值key的大小
	if (cmp < 0)  x.left = delete(x.left, key);  //小于，往左找
	else if (cmp > 0)  x.right = delete(x.right, key);  //大于，往右找
	else {  //找到了，执行互换+单删
		if (x.right == null)  return x.left;
		if (x.left  == null)  return x.right;  //若已经是最值，那么和deleteMin一样处理即可

		Node t = x;  //存储原来的x，准备进行交换
		x = min(t.right);  //找到右子树的最小节点
		x.right = deleteMin(t.right);  //以交换前的x结点的右儿子作为根节点进行最小值的删除，将更新后的根节点连接到交换后的x的右侧
		x.left = t.left;	
	}
	x.count = size(x.left) + size(x.right) + 1;
	return x;
}
```

这样不对称的删除会使得左侧子树的大小越来越大，产生了不平衡的二叉树结构，在多次随机删除和插入后，树的高度变为了$\sqrt{N}$，**随机化地选取在左边删除或在右边删除并不能改善这样的不平衡情况**，这是一个长久以来没能找到解答的问题

## 9.3 2-3树
2-3搜索树这个数据结构也是一种基本的二元搜索树，它能够满足我们所需的快速操作以及平衡性的需求
它的思想在于：在原本的只容纳得下一个键值的二叉搜索树的基础上，增加一种**可以容纳两个键值的结点，该结点必须有左中右三个孩子，其中左孩子的键值小于结点中的两个键值、中孩子在两个键值之间、右孩子大于两个键值**。因此称为2-3树
![[Pasted image 20241121211855.png]]
进行搜索的过程和二叉树是一样的，只需要比较搜索键值和结点键值即可，只是需要增加一个中间值判定

而2-3树保持平衡的方式是**分裂：当插入操作搜索到应该放在一个双键值结点的某个儿子中时，我们并不直接进行放置，而是先将它放到该结点中，形成一个三键值结点**：
1. 搜索到双键值结点
![[Pasted image 20241121213026.png]]
2. 合成三键值结点，该结点有4个孩子
![[Pasted image 20241121213119.png]]

然后，对3键值4孩子结点进行**分离：将中间大小的键值移动到父节点中去，然后另外两个键值分裂成两个单键值结点，连接到父节点：**
![[Pasted image 20241121213300.png]]
如果父节点变成了三键值结点，那么也重复这个分裂过程即可。原来的四个孩子均分给两个分裂出来的单键值结点：
1. 
![[Pasted image 20241121213505.png]]
2. 
![[Pasted image 20241121213535.png]]


至于构建过程，第一个结点从1键值、2键值直到3键值，然后开始分裂，后续的结点就按普通的插入过程来就行
总之，2-3树的插入就是：**首先将键值结合到搜索到的最后位置的父节点中，然后根据父节点的键值个数是否达到3，决定是否分裂**

演示的情况虽然简单，但是实际上有非常多种的可能情况需要考虑：
![[Pasted image 20241121214145.png]]
可以看到，根据父子结点的情况不同产生了不同的树形，但是分裂后它们都保持着平衡的形状
我们可以进行一些分析：在最坏的情况下，树的高度是$\log_2N$，最好情况是$log_3N$，树的高度保持在这个区间内，是对数级别复杂度。

我们不讨论2-3树的具体代码实现，因为维持多个结点类型是非常复杂的，处理分裂的过程中需要很多比较，可能情况也非常多。后面会介绍更简单的平衡树模型，这里就不加赘述了

## 9.4 红黑树
红黑树的代码实现相对较少，我们的想法是将每棵2-3树表示为一棵二叉搜索树，也就是将双键值结点使用一个简单的单键值形式表示
例如，使用一个**内部左倾连接方式**将双键值结点的三个结点连接在一起，效果如下：
![[Pasted image 20241122113250.png]]
方法是：**将两个键值中较大的那个键值b拿出来作为根节点的键值，将三个子节点中键值大于b的子节点分配给b作为其右节点，剩余两个结点作为a的两个儿子，将a作为b的左儿子**，这就形成了左倾的连接方式
我们把a和b之间这样的**将双键值中较小的那个（a）作为较大的那个（b）的左孩子的连接弧段涂色为红色**
涂色的操作目的是将键值之间的连接弧段与树中的其他连接区分开来，从而在插入时分辨出哪些结点属于树结点，哪些结点是同一个双键值结点中的两个键值结点

其他没有被涂色的连接弧段就是黑色弧段，因此称为红黑树。有了这样的表示方法，我们可以将2-3树中的所有双键值结点拆分为这样的表现形式：
![[Pasted image 20241122113951.png]]
参考我们对2-3树的了解，可以发现：
- 没有任何一个结点同时被两条红链连接（不能有两条连续的左倾红链）
- 每条从根节点开始到叶结点的路径具有相同数量的黑链（黑链具有完美的平衡性）
- 红链永远是向左倾斜的
- 2-3树和红黑树是一一对应的，只需要把红链进行合并即可

红黑树的搜索和2-3树是一样的，非递归实现：
```
public Val get(Key key) {
	Node x = root;
	while (x != null) {
		int cmp = key.compareTo(x.key);
		if (cmp < 0)  x = x.left;
		else if (cmp > 0)  x = x.right;
		else if (cmp == 0) return x.val;
	}
	return null;
}
```
还有其他的不需要考虑链的颜色的操作，同理也并不需要更改

### 1. 左旋与右旋
我们先看看结点的表示形式：
```java
private static final boolean RED = true;
private static final boolean BLACK = false;

private class Node {
	Key key;
	Value val;
	Node left, right;
	boolean color;   //该结点与父节点之间的链的颜色
}

private boolean isRed(Node x) {
	if (x == null)  return false;  //空链都定义为黑
	return x.color == RED;
}
```

接下来，为了保持树的平衡，一个基本的操作叫做**左旋转**
这个想法是：**在插入操作中有时会看到向错误方向（右倾）的红链，我们需要重新定向它至左倾**

```java
private Node rotateLeft(Node h) {
	assert isRed(h.right);  //只在结点h的右链为红时执行
	Node x = h.right;  
	h.right = x.left;
	x.left = h;
	x.color = h.color;  //x与父节点链的颜色记得也要更改为和h一致
	h.color = RED;
	return x;  //旋转后x是h的父节点了
}
```

具体操作是：对于右链为红的结点，将其右孩子的左孩子替换为自己的右孩子，然后将其作为原右孩子（x）的左孩子，把连接到父节点的链连接到x上即可：
![[Pasted image 20241122160515.png]]-> ![[Pasted image 20241122160749.png]]


为了完成后面的插入操作，有时候我们**需要使一个正常的红链暂时右倾，稍后再转回来**，这就是右旋操作：
```java
private Node rotateRight(Node h) {
	assert isRed(h.left);  //结点左链是正常的
	Node x = h.left;
	h.left = x.right;
	x.right = h;
	x.color = h.color;
	h.color = RED;
	return x;
}
```
这个代码与操作和左旋是完全对称的：只需要把`right`和`left`的位置互换一下即可
即：将当前结点的左儿子的右儿子替换至当前结点的左儿子，然后当前结点作为原左儿子的右儿子，将原来与父节点的链接连到原左儿子上：
![[Pasted image 20241122161609.png]]  -> ![[Pasted image 20241122161628.png]]

### 2. 颜色翻转
对应于2-3树的临时3键值4儿子结点，红黑树中会出现这样一种情况：某结点的两条链都是红链：
![[Pasted image 20241122162439.png]]
我们**先不改变任何链接的形式，只是简单地把两条红链变成黑链，该结点与父节点的链接变为红链**：
```java 
private void flipColors(Node h) {
	assert !isRed(h); //h与父节点的链接非红
	assert isRed(h.left);
	assert isRed(h.right);
	h.color = RED;
	h.left.color = BLACK;
	h.right.color = BLACK;
}
```
这就是我们需要的三个基本操作：左旋、右旋和反转颜色

### 结合三个基本操作实现红黑树的插入
和2-3树对照地来看，上述操作在什么时候会被需要用到：
当我们将一个结点**加入一棵红黑树中**时，我们会**先直接将它放在搜索到的位置上，然后把该位置与父节点之间的链接涂成红色**
- 1. 左旋操作：出现了向右倾斜的红链
  ![[Pasted image 20241122164231.png]]
  搜索到的位置在某个结点的右儿子上，因此产生了右倾红链，此时左旋回来即可

- 2. 形成临时3键值4儿子结点的情况：插入的结点位置在某个双键值结点的儿子中，此时要**与这个双键值结点形成临时三键值结点**
  主要分为下面大于、小于、中间三种情况：
  ![[Pasted image 20241122170554.png]]
  - 大于：**插入的键值比双键值结点中的两个键值都大**，直接放入较大的那个结点的右儿子中，将链涂成红色，这就出现了中间结点的左右两条链都是红色的情况，**直接进行颜色反转**即可
  - 小于：**插入的键值比双键值结点中的两个键值都小**，此时应该放入较小的那个结点的左儿子中，出现了连续的红链。应该将中间大小的那个结点作为父节点，调整为中间节点左右两条链都是红链的情况（右旋），再进行反转，也就是**先右旋，再反转**
  - 中间：**插入的键值大小在原有的两个键值之间**，此时该键值应该作为中间的父节点，但是却被插入了较小结点的右儿子中，因此对这条链进行左旋，然后就形成了"小于"情况中的两条连续左红链，于是再次进行右旋，变为中间结点，左右两条链为红链，最后再进行反转。也就是**先左旋，再右旋，最后反转**

  可以发现，**所有可能情况都可以被拆分为左旋、右旋和反转操作的组合，我们只需要检测什么时候需要进行旋转和反转，并及时更新即可**

上图展示的是只有3个结点的树的情况，对于插入多个结点的树底下的某个双键值结点的情况也是类似的：
- 首先进行标准的二叉搜索树插入，然后将插入结点与父节点之间的链涂成红色
- 然后检查是否需要对形成的三键值结点进行旋转以平衡，如果需要就旋转
- 反转链的颜色，**将红色链传递给上一层级**
- 再次检测是否需要旋转以平衡
- 有可能传递后的上一层级结点需要重复进行这样的操作

这些变化都是局部的，在每个部分，我们都只使用之前说的三个基础操作：
- 出现右倾红链+对应左链为黑：左旋
- 出现左孩子以及左孩子的左孩子之间都是左倾红链：右旋
- 出现结点的两条链都是红链：反转颜色

于是我们只需要在普通二叉搜索树的基础上增加这样的判断来保证平衡即可：
```java
private Node put(Node h, Key key, Value val) {  //输出：返回经过更新后的输入结点h，若h为空，就是插入的结点，key是插入结点的键，val是插入结点的值
	if (h == null)  return new Node(key, val, RED);  //插入的结点，无论什么情况都先将它与父节点的链设置为红色
	int cmp = key.compareTo(h.key);
	if      (cmp  < 0)  h.left  = put(h.left,  key, val);  //小于就向左搜索（更新）
	else if (cmp  > 0)  h.right = put(h.right, key, val);  //大于就向右搜索（更新）
	else if (cmp == 0)  h.val = val;    //若已经存在对应结点，覆盖它的值

    //根据不同情况，进行不同处理
	if (isRed(h.right) && !isRed(h.left))      h = rotateLeft(h);
	if (isRed(h.left)  &&  isRed(h.left.left)) h = rotateRight(h);
	if (isRed(h.left)  &&  isRed(h.right))     flipColors(h);

	return h;  //返回经过更新后的输入节点
}
```
这就是红黑树插入操作的简单实现，将2-3树进行这样的表示后，只需要三个额外的操作就可以了

红黑树的删除算法要更加复杂，因为它要同时维护二叉搜索树的结构和红黑树的基本性质，这里暂时

## 9.5 红黑树的推广应用：B树
B树是红黑树的其中一个非常典型的泛化版本。在计算机存储中，通常我们需要存储的数据量是很大的，我们需要为存储和定位、索引找到一个合适的高速数据结构来迅速完成这个过程
从磁盘中读取特定数据的主要时间消耗在于定位到数据所在的特定页，一个页可能被非常多的键值索引，我们为这个索引个数设置一个上限，比如M=6：
![[Pasted image 20241122202443.png]]
它的思想是：一个结点容纳N个键值，在键值为满的时候分裂这个结点为两个，每个结点包含$\frac{N}{2}$个键值
就像红黑树那样，我们推广这个数据结构：每个结点中包含一个存储着多个键的表，**一个 m 阶 B 树的每个节点最多可以有 m-1 个键值和 m 个子节点**，每个结点的子节点数量与存储的键值数量有关

对应于红黑树的颜色机制与旋转机制，B树采取**结点分裂与合并**来维护树的平衡性：
- **节点分裂**：当一个节点存储的键值数超过最大允许值时，将其分裂为两个节点，并**将中间键值提升到父节点**。
- **节点合并**：当节点键值数低于最小值时，**从兄弟节点借键值**或将节点**合并到兄弟节点**中

在B树中：
- 每个节点的键按升序排列：如果节点包含 $k_1,k_2,...,k_t，则k_1 < k_2 < ... < k_t$
- 除了根节点外，每个结点最多有m-1个关键字，至少有m/2个关键字
- 每个关键字引出两条链，左子树的关键字都小于它，右子树的关键字都大于它
- 



# Lecture 10. 线段树


# Lecture 11. 哈希表


# Lecture 12. 无向图
无向图：由边连接的成对出现的结点的集合，边没有方向的限制（每条边可以任取方向行进）
路径：由边所连接起来的结点的序列
环：头和尾是相同结点的路径
连通：两个结点之间存在路径
连通块：是图的子集，其中的所有结点都相互连通

一笔画问题：图中是否存在包含了每一条边且只包含了一次的环？即我是否能够遍历完所有的边并且不重复经过某条边？
哈密顿路径问题：只关心结点，是否存在只使用了一次每个结点的环？
最小生成树问题：如何使用总数最少（最短）的边集合连接所有结点
连通问题：是否存在一个结点，使得移除它会导致整个图不连通？
绘图问题：能否在平面中画出这个图，并且所有的边之间不会相交？

## 12.1 图的API
首先需要为图设计一个API进行简单的表示，并且提供一组方法来供客户端简单地调用和图有关的处理
本讲座中将结点使用0到V-1的V个整数进行索引，其中V是所有顶点的数量
```c
public class Graph
	Graph(int V)   //创建一个具有V个结点的空图
	Graph(In in)   //通过输入流in创建一个图
	void addEdge(int v, int w)  //为图增加一条边v-w
	Iterable<Integer> adj(int v)   //迭代器：接受顶点作为参数，遍历与该顶点相邻的顶点
	int V()    //顶点个数
	int E()    //边数
	String toString()    //字符串表示
```

一个使用这套API进行图中边的打印的例子：
```java
In in = new In(args[0]);
Graph G = new Graph(in);

for (int v = 0; v < G.V(); v++)  //对于每个顶点
	for (int w : G.adj(v))  //遍历它们相邻的点，点号为w
		StdOut.println(v + "-" + w);  //输出边。一条边会被输出两次
```

借助这些API，我们可以实现一些对图的计算：度的计算、自环检测
```java
public static int degree(Graph G, int v) {
	int degree = 0;
	for (int w : G.adj(v))  degree++;
	return degree;
}

public static int maxDegree(Graph G) {
	int max = 0;
	for (int v = 0; v < G.V(); v++)
		if (degree(G, v) > max)
			max = degree(G, v);
	return max;
}

public static double avergeDegree(Graph G) {
	return 2.0 * G.E() / G.V();
}

public static int numberOfSelfLoops(Graph G) {
	int count = 0;
	for (int v = 0; v < G.V(); v++)
		for (int w : G.adj(v))
			if (v == w)  count++;
	return count/2;   //每次
}
``` 

# Lecture 13. 有向图

# Lecture 14. 最小生成树
最小生成树问题指的是在边权重不同的图中，寻找到边权之和最小的**无环连通图**
## 14.1 贪心算法
为了研究获取最小生成树的算法，我们需要了解**获取最小生成树的贪心算法**。为了简化问题，我们设下面我们讨论的图中每条边的权重各不相同

### 14.1.1 分割
贪心算法需要一个称为分割的图的基本操作来实现。一个图上的分割指的是**将图中的结点分到两个非空集合当中，每个集合中的结点不一定互相连通**
那么给定一个分割，必定有一些边将一个集合中的一些结点连接到另一个集合中的结点，这些边称为**交叉边**
只要给定一个分割，那么必定会生成一些交叉边。由于边权各不相同，那么这些交叉边中能选出边权最小的一条边

证明：**给定任何一个分割，所产生的交叉边中最小的那条边一定在图的最小生成树中**
- **反证法：** 假设最小交叉边 e 不属于 MST。
- **构造 MST：**
    1. 设 T′ 是图的一个最小生成树，且 $e \notin T′$。
    2. 如果将 e 加入 T′，那么 T′ 会形成一个环，**因为 MST 是树，加入额外的边必然形成环**
    3. 这个环上必然有一条边$f \neq e$ 是连接 S 和 T 的交叉边。
- **比较权值：**
    1. 根据假设，e 是交叉边中权值最小的边，因此$w(e) \leq w(f)$。
    2. 但如果 f 被替换为 e，则新的生成树 T′′=T′−f+eT'' = T' - f + eT′′=T′−f+e 的权值总和小于或等于 T′，矛盾于 T′ 是最小生成树。
- **结论：** 因此，最小交叉边 e 必然在 MST 中。

### 14.1.2 找到最小生成树
如果我们**遍历整个图的所有分割**，将所有的**最小交叉边**都找到并加入集合，那么最终得到的就是最小生成树，让我们证明这一点：
首先，根据之前的证明可以知道，任何一条最小交叉边都在最小生成树中
我们知道，若结点个数为n，那最小生成树中的边数必定固定为n-1条，并且最小生成树中没有环。因为每次加入集合的边都是两部分之间的最小权值边，因此不会形成环。所有边均满足生成树的性质，只需要这样找到n-1条不会形成环路的边，就能保证构造出的是最小生成树

可以看到，这样每次取最小交叉边的方式就是典型的贪心算法的思路
### 14.1.3 总结
我们之后所讲的算法都是基于这样的分割-取最小交叉边的思想进行的，它们的区别在于选择分割的方式不同，取得最小交叉边的方式也不同
我们将会介绍kruskal算法和prim算法，在它们的基础上，我们使用很多现代数据结构来实现更高的效率

如果整个图的

## 14.2 带权图的API
我们需要一个表示具有边权的图的方式，因此我们先定义什么是边。在我们之前的图的实现中，边实际上一直是被隐含的，没有显式定义，对于带权图，我们就需要定义了。
抽象数据结构：
```java
public class Edge implements Comparable<Edge> {
	Edge(int v, int w, double weight);  //创建一条边v-w，具有权重weight
	int either()  //返回边的两个顶点中的任意一个，用于起始
	int other(int v)   //返回边其中一个顶点v对应的另一个顶点w
	int compareTo(Edge that)  //比较器
}
```

它的实现也很简单：
```java
public class Edge implements Comparable<Edge> {
	private final int v, w;
	private final double weight;

	public Edge(int v, int w, double weight) {
		this.v = v;
		this.w = w;
		this.weight = weight;
	}

	public int either() {
		return v;
	}

	public int other(int vertex) {
		if (vertex == v)  return w;
		else return v;
	}

	public int compareTo(Edge that) {
		if (this.weight < that.weight)  return -1;
		else if (this.weight > that.weight) return +1;
		else return 0;
	}
}
```

于是，我们的带权图的API如下：
```java
public class EdgeWeightedGraph {
	EdgeWeightedGraph(int V)  //V个结点的空图
	EdgeWeightedGraph(In in)  //从输入流中构造图
	void addEdge(Edge e)      //加入边e
	Iterable<Edge> adj(int v)  //获取包含顶点v的所有边的可迭代对象
	
}
```
其实就是将原来的图的API中，用两个结点隐含的边显式地包装了起来，并且包含了权重信息而已。我们依然使用邻接链表
```java
public class EdgeWeightedGraph {
	private final int V;
	private final Bag<Edge>[] adj;

	public EdgeWeightedGraph(int V) {
		this.V = V;
		adj = (Bag<Edge>[]) new Bag[V];
		for (int v = 0; v < V; v++) 
			adj[v] = new Bag<Edge>();
	}

	public void addEdge(Edge e) {
		int v = e.either(), w = e.other(v);
		adj[v].add(e);
		adj[w].add(e);
	} 

	public Iterable<Edge> adj(int v) {
		return adj[v];
	}
}
```

对于最小生成树，我们也可以表示出这么一个API，它的构造函数接收一个带权图：
```java
public class MST {
	MST(EdgeWeightedGraph G)
	Iterable<Edge> edges()  //MST的边集合，用类似于v-w的形式储存
	double weight()  //MST的总权重
}
```
代表根据这个图G，寻找到其中的最小生成树MST

一个客户端使用的例子如下：
```java
public static void main(String[] args) {
	In in = new In(args[0]);
	EdgeWeightedGraph G = new EdgeWeightGraph(in);
	MST mst = new MST(G);
	for (Edge e : mst.edges())
		StdOut.println(e);
	StdOut.printf("%.2f\n", mst.weight());
}
```
直接在最小生成树中的边集中遍历即可

## 14.3 kruskal算法
该想法很简单：我们首先将所有的边按照权重从小到大进行排序，每次取其中最小的一条边进行判断：若将这条边加入结点集合中，不会出现回路，那么就加入它；若出现回路，就跳过这条边

这个算法就是我们之前所讲的贪心算法的一个特例：
假设该算法将边 e = v-w 加入集合，那么它所选择的分割就是已经连接为树的图的子集T中，连接着v的所有顶点的集合，另一个集合
因为我们总是从小到大取的，所以我们每次取的一定是最小的那个交叉边

### 14.3.1 连通性判断
克鲁斯卡尔算法需要我们判断一条边加入集合后会不会导致集合出现环路，虽然也可以使用DFS这样的搜索算法实现，但更好的方法显然是使用并查集
我们为T中每个连接着的部分维护一个集合，如果v和w在同一个集合中，那么加入边v-w会导致构造出一个回路；如果v和w在不同集合，则可以加入v-w，此时将v和w所在的集合进行合并即可

### 14.3.2 实现
```java
public class KruskalMST {
	private Queue<Edge> mst = new Queue<Edge>();  //使用队列来存储最小生成树的边集
	public KruskalMST(EdgeWeightedGraph G) {
		MinPQ<Edge> pq = new MinPQ<Edge>();
		for (Edge e : G.edges())
			pq.insert(e);

		UF uf = new UF(G.V());
		while (!pq.isEmpty() && mst.size() < G.V()-1) {//最小生成树最多有n-1条边
			Edge e = pq.delMin(); 
			int v = e.either(), w = e.other(v);
			if (!uf.connected(v, w)) {
				uf.union(v, w);
				mst.enqueue(e);
			}
		}
	}
}
```
