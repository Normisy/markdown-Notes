# L1. 信息表示
## 1.1 信息论、不确定性、量化
使用$p_1, p_2, \cdots, p_N$表示当离散变量X取$x_1,x_2,\cdots,x_N$时的概率，对于更高的概率，其不确定性就越弱。信息就是用于确定变量取值是什么的，当变量是某个值（给定的事件）的概率越大，该事件的不确定性就越弱，因此不确定性与它的概率成反比。
在信息论中，信息量定义为：
$$ I(x_i)=\log_2(\frac{1}{p_i})$$
其单位是**位数bit**，二进制位中一个位只能取0或1，而不确定性则是对概率的倒数取以2为底的对数，这意味着**不确定性代表使用二进制对一个给定选择进行编码时，达到理论上最优编码方案所需要使用的位数（理想长度）**

这里“对事件编码时的理论最优编码方案”的含义是，**使用二进制位表示每个事件（取值）时，出现概率大的事件出现频率大，因此需要更少的二进制位以使得在大量数据存储下减少存储压力**

假设现在存在N个相等概率的事件，并且我们获得了一些数据，得知已经发生的事件类型在M个以内，那么这些数据的信息量就是
$$ I(data)=\log_2(\frac{1}{M\cdot (1/N)})=\log_2(\frac{N}{M}) \quad bits$$
值得注意的是，这样的计算公式会产生小数，而电路中只能处理二进制位，因此**真正的信息量计算中，对最终结果需要==向上取整==**

## 1.2 熵
信息量指导我们理想状态下应该为每个事件分配多少位，但它并不能评判一个编码策略的好坏。
为了评估我们在电路中使用的位编码策略的性能，信息论使用**随机变量的熵**H(X)来描述

**随机变量的熵**指的是**当学习随机变量的值时所接收到的期望信息量**，即：
$$H(X)=\text{E}(I(X))=\sum\limits_{i=1}^{N}p_i\cdot \log_2(\frac{1}{p})
$$
而对于一个编码策略来说，它的熵就是**该策略下的事件期望信息量**，即事件编码位数按照概率的加权平均数，一个好的策略的熵应该接近随机变量的熵

## 1.3 编码
接下来，我们就需要探究将数据编码为二进制位的策略。编码本质上是一组位字符串和一组对象之间的一一映射；这样的位表示可以是位数固定的，也可以是可变长度的
一个编码策略必须是一一对应的，并且在表示消息时不会出现二义性，即一串位只能被唯一地解码为一条信息

在图形上，我们可以将这样明确的编码使用二叉树表示，类似于词典树，两个子节点分别表示下一位取0和1，一条叶结点到根节点的路径代表一个字符的编码表示
![[Pasted image 20260206215534.png]]
叶结点到根节点的边数就是它的编码长度
而对于许多字符组成的字符串的二进制位表示，例如`01111`，则能够直接将这串位视为在二叉树中转向的指示，从根结点开始，遇到0向左子树转，遇到1向右子树转，遇到叶结点则回到根节点开始找下一个字符

### 1.3.1 固定长度编码
在我们认为一组符号的出现概率相同时，使用固定长度编码。在编码二叉树中，这意味着所有叶结点到根结点的边数相同，在数据序列中通过固定字长作为偏移量即可分离出每个符号
固定长度编码的熵值为
$$ \sum\limits_{i=1}^{N}(1/N)\log_2(\frac{1}{1/N})=\log_2 N$$
其中N为所有需要表示的字符的总量
编码策略的熵值也代表信息量的含义：每个字符需要熵值向上取整后得到的位数值来表示，即**固定字长等于熵值向上取整**

以常见的ASCII编码为例，它具有94个字符，至少需要$\log_2 (94)$的位来表示，该值向上取整为7位，熵值约为6.555，所以ASCII码长为7位

最重要的编码之一是数字的编码表示。首先考虑无符号整数的表示（参见深入理解计算机系统笔记第2.2节），使用二进制表示无符号整数时
$$ V=\sum\limits_{i=0}^{N-1}2^ib_i，其中b_i=0或1$$
即一个无符号整数分解为2的不同次幂乘上0或1的和
![[Pasted image 20260207173226.png]]
更常见的是以16为基数的十六进制表示，因为它的一个符号代表一组4个二进制位
![[Pasted image 20240712223729.png]]

### 1.3.2 数字的补码表示
使用补码表示有符号整数，在朴素的思想中，我们可以将无符号整数表示的最高位设置为符号指示位，它为0代表负数，为1代表正数，后面的其余N-1个位代表有符号整数的绝对值。然而这样的方式会导致出现两种零的表示；更关键的是，这种表示会使得对有符号整数的加法和减法计算的电路产生不同，我们希望这两种运算尽量使用同一个电路来表示
因此，现代计算机通常使用**为最高位赋予负数权值$-2^{N-1}$的补码表示**
![[Pasted image 20260207175732.png]]
其值域为$[10\cdots 0000, 01\cdots 1111]$即$[-2^{N-1},2^{N-1}-1]$
当这种补码表示的位全为1时，代表十进制值-1；加上0000...01之后，由于溢出一位，正好是0000...00，即十进制0的唯一表示
对于任意两个数A和B，计算B-A，通过这种补码表示，能够统一为B+(-A)，即只需要找到-A的补码表示即可
而-A的补码表示可以通过以下方式得到：
$$ \begin{align}
A+(-A)&= 0 = 1+(-1)\\
-A &= (-1-A)+1\\
-A &= \sim A + 1
\end{align}$$
因为-1的补码表示是位全为1的二进制位，它减去一个数就等于**对这个数的二进制表示逐位取反**，因此只需要先对数A取反再加一，即可得到有符号整数A的相反数了

#### 补码加法溢出
（在深入理解计算机系统笔记的第2.3节 ”整数运算“之后有更详细的介绍）
若两个补码数进行加减乘除后，超出了N位表示法的表示上限，就意味着发生了溢出。这种溢出能够通过查看参与运算的两个数字的符号和结果数的符号检查出来：
1. 若两个正数（最高有效位为0）相加获得了一个负数（最高有效位为1），则发生了正溢出
2. 同理负数相加得到了正数，则发生了负溢出
3. 若两个在表示范围内正负不同的数相加，结果不会发生溢出

#### 补码范围
（这部分也在深入理解计算机系统笔记的第二章有详细介绍）
一个N位补码表示的数字范围为$[-2^{N-1}, 2^{N-1}-1]$


### 1.3.3 可变长度编码
对于出现概率（频率）不同的$x_i$，我们希望通过它的$p_i$来加权其编码长度，出现概率大的编码长度应该更短，以使得总的数据的期望编码长度接近它的熵H(X)，这就是**可变长度编码**

用之前二叉树编码ABCD的例子，假设我们已知每个符号的出现概率，并且依照概率计算得到了它的熵，那么这个熵值就是保存一个符号所需使用的平均二进制位的下限
![[Pasted image 20260207201426.png]]

## 1.4 霍夫曼算法
给定一组符号集合和它们的概率分布，构造出最优的可变长度编码的算法是霍夫曼算法：
1. 选择概率$p_i$最小的两个符号结点，作为一阶二叉树的两个叶子，根节点的概率值为它们的概率之和，作为一个结点入堆
2. 每一步，持续选择两个最小概率的结点，构造新的二叉子树
3. 最后得到的树就是编码所有符号的二叉树了，向左的边代表0，向右的边代表1即可

## 1.5 检错和纠错
### 1.5.1 海明距离：E+1的最小海明距离可以检查出最多E个错误
还需要考虑如果发生了错误，使得编码数据中一个或多个位被破坏时的情况。我们主要讨论单个位的错误，但是这样的讨论也可以推广到多个位的情况
例如，考虑对一些不可预测事件的结果进行编码，如抛硬币用0和1表示正面和背面。如果传输过程中产生了位的错误，那么结果会截然不同

海明距离：**两个相同长度的编码中相同位数所对应的二进制位不同的数量**
例如，0110010和0100110中第三位和第五位的二进制位不同，因此它们之间的海明距离是2
若两个编码之间的海明距离为0，则它们相同，这样就可以测量编码之间的差异

在抛硬币的例子中，单个位的表示会使得在错误发生时无法知道得到的结果是正确的还是错误的，无法进行校验。
一个很直接的想法是**我们需要一组有效的编码，使得少量的位错误不会导向另外一个合法的结果**，即需要这组编码集合中的编码字之间的**最小海明距离**大于一定位数

例如，在这个例子中，我们需要向这个单位编码中加入**奇偶校验位**：令`00`表示正面，`11`表示背面，这样最小海明距离就增加为2了，任何单位的错误都只会出现`01`或`10`这样的结果，称为**奇偶错误**，只需要计算编码中的`1`的值，若为奇数，则发生错误；若为偶数，则没有发生错误。
这样的奇偶校验可以通过**异或电路**来很快地检查到，在接下来的章节会进行介绍

当然，奇偶校验不适用于可能会出现**偶数个比特的错误**的情况，需要更加复杂的编码时，若我们需要**检查出E个比特的错误**，那么**编码的最小海明距离需要为E+1**
例如，将上述例子的正面编码为`000`，反面编码为`111`，那么这样的编码方式最小海明距离是3，最多可以检查出2个比特位上发生的位错误
![[Pasted image 20260302185525.png]]

### 1.5.2 纠错
是否存在一种能够检查到单比特错误，并且还能将其纠正回原始数据的方式？是存在的

**当两个有效编码字之间的海明距离增加至3的时候，能够保证由单个比特的错误所产生的编码字的集合不会重叠**
![[Pasted image 20260302185525.png]]
就像这张例图，由原始数据`000`和`111`发生单比特错误所产生的无效编码字的两个集合并不重合，因此获得无效编码字后，能够立刻判断出它们的原始数据是`000`还是`111`

同理推广可得，**若我们需要能够纠正出最多E个比特上产生的错误，则有效编码字之间的最小海明距离必须至少为2E+1**。
这是编码理论所研究的内容，它们研究如何开发编码算法使得编码具有检验和纠错的基本功能

### 1.5.3 例题
下图是二维奇偶校验码的示例图，其中D表示数据位，7个P为奇偶校验位，其中除了Pxx以外的校验位对每一行和每一列进行奇偶校验，
![[Pasted image 20260302192929.png]]