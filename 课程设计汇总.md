# 城市餐厅商业活力分析与预测 - 答辩技术要点详解

## 目录

1. [数据预处理方法](https://15659118.4omini.xyz/chat/8b87bbd9-7628-462a-a5af-e60cb4af8929#1-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95)
2. [主题建模算法](https://15659118.4omini.xyz/chat/8b87bbd9-7628-462a-a5af-e60cb4af8929#2-%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95)
3. [网络可达性分析](https://15659118.4omini.xyz/chat/8b87bbd9-7628-462a-a5af-e60cb4af8929#3-%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%BE%BE%E6%80%A7%E5%88%86%E6%9E%90)
4. [特征工程方法](https://15659118.4omini.xyz/chat/8b87bbd9-7628-462a-a5af-e60cb4af8929#4-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E6%96%B9%E6%B3%95)
5. [空间聚类与竞争分析](https://15659118.4omini.xyz/chat/8b87bbd9-7628-462a-a5af-e60cb4af8929#5-%E7%A9%BA%E9%97%B4%E8%81%9A%E7%B1%BB%E4%B8%8E%E7%AB%9E%E4%BA%89%E5%88%86%E6%9E%90)

---

## 1. 数据预处理方法

### 1.1 地理空间过滤

**目的**：从大规模数据集中提取特定城市的餐饮业数据
主要思路：首先根据城市名称（这里

**方法**：

- **行政区划过滤**：基于城市名称(city)和州代码(state)的精确匹配
- **业态识别**：通过关键词匹配识别餐饮业商户

**关键词库**：

```
restaurant, food, cafe, bar, pizza, chinese, mexican, italian, 
sushi, burger, bakery, diner, bistro, grill, steakhouse, buffet, 
deli, bbq, seafood, pub, american, asian, sandwiches
```

**数学表示**： 设商户集合为 $B = {b_1, b_2, ..., b_n}$，城市为 $c$，州为 $s$，则筛选条件：

$$ R = {b_i \in B \mid b_i.city = c \land b_i.state = s \land \exists k \in K: k \in b_i.categories} $$

其中 $K$ 为餐饮关键词集合，$R$ 为筛选后的餐厅集合。

---

### 1.2 坐标数据质量控制

**问题识别**：

1. **缺失值问题**：latitude/longitude 为空
2. **零岛问题**：坐标值为 (0, 0)
3. **边界外问题**：坐标超出城市地理边界

**解决方案**：

#### 1.2.1 边界框验证

对于 Philadelphia，使用边界框： $$ \begin{aligned}
\text{LAT_MIN} &= 39.8° \\
\text{LAT_MAX} &= 40.2° \\
\text{LON_MIN} &= -75.3° \\
\text{LON_MAX} &= -74.9° 
\end{aligned} 
$$

**验证条件**： $$ \text{Valid}(p) = \begin{cases} \text{True} & \text{if } \text{LAT_MIN} \leq p.lat \leq \text{LAT_MAX} \ & \land \text{LON_MIN} \leq p.lon \leq \text{LON_MAX} \ & \land p.lat \neq 0 \land p.lon \neq 0 \ \text{False} & \text{otherwise} \end{cases} $$

---

### 1.3 文本标准化处理

**目的**：将非结构化评论文本转换为可分析的标准格式

**处理流程**：

#### 1.3.1 小写转换

$$ \text{text}_{\text{lower}} = \text{lowercase}(\text{text}_{\text{raw}}) $$

#### 1.3.2 标点符号移除

使用 Python string.punctuation 集合移除所有标点： $$ \text{text}_{\text{clean}} = \text{text}_{\text{lower}} \setminus \text{Punctuation} $$

#### 1.3.3 停用词过滤

**停用词集合** $S$：包含常见无意义词汇

```python
S = {'i', 'me', 'my', 'we', 'the', 'a', 'an', 'and', 'but', 'or', ...}
```

**过滤公式**： $$ W_{\text{filtered}} = {w \in W \mid w \notin S \land |w| > 1} $$

其中 $W$ 是分词后的词集合，$|w|$ 是词的长度。

#### 1.3.4 最小文档长度过滤

$$ D_{\text{valid}} = {d \in D \mid |d| \geq 5} $$

保留至少包含5个词的文档。

---

### 1.4 评论数量阈值过滤

**目的**：确保样本代表性，移除评论数不足的餐厅

**统计公式**： $$ \text{review_count}(r) = |{v \in V \mid v.business_id = r.id}| $$

**筛选条件**： $$ R_{\text{final}} = {r \in R \mid \text{review_count}(r) \geq \text{MIN_REVIEWS}} $$

本项目设置 $\text{MIN_REVIEWS} = 5$

---

## 2. 主题建模算法

### 2.1 LDA (Latent Dirichlet Allocation)

**概念**：无监督概率主题模型，用于发现文档集合中的潜在主题结构

#### 2.1.1 数学模型

LDA假设每个文档是多个主题的混合，每个主题是多个词汇的概率分布。

**生成过程**：

对于文档 $d$：

1. 从 Dirichlet 分布中采样主题分布： $$\theta_d \sim \text{Dir}(\alpha)$$
    
2. 对于文档中的每个词 $w_{d,n}$：
    
    - 从 $\theta_d$ 中采样主题：$z_{d,n} \sim \text{Multinomial}(\theta_d)$
    - 从主题 $z_{d,n}$ 的词分布中采样词：$w_{d,n} \sim \text{Multinomial}(\phi_{z_{d,n}})$

**参数说明**：

- $K$：主题数量（本项目设为6）
- $\alpha$：文档-主题 Dirichlet 先验参数（自动优化）
- $\eta$ (beta)：主题-词 Dirichlet 先验参数（自动优化）
- $\theta_d$：文档 $d$ 的主题分布，维度为 $K$
- $\phi_k$：主题 $k$ 的词分布，维度为 $V$（词汇表大小）

#### 2.1.2 联合概率分布

$$ P(W, Z, \theta, \phi \mid \alpha, \eta) = \prod_{k=1}^{K} P(\phi_k \mid \eta) \prod_{d=1}^{D} P(\theta_d \mid \alpha) \prod_{n=1}^{N_d} P(z_{d,n} \mid \theta_d) P(w_{d,n} \mid \phi_{z_{d,n}}) $$

#### 2.1.3 参数推断

使用**变分贝叶斯推断**（Variational Bayes）近似后验分布。

目标：最大化证据下界 (ELBO)： $$ \mathcal{L}(W \mid \alpha, \eta) = \mathbb{E}_q[\log P(W, Z, \theta, \phi \mid \alpha, \eta)] - \mathbb{E}_q[\log q(Z, \theta, \phi)] $$

**训练参数**：

- `passes=10`：完整遍历语料库10次
- `iterations=50`：每次遍历中的迭代次数
- `random_state=42`：随机种子，确保可重复性

---

### 2.2 词典构建与过滤

#### 2.2.1 词典创建

$$ D = {(w, \text{id}_w) \mid w \in \bigcup_{d \in \text{Corpus}} d} $$

#### 2.2.2 极端词汇过滤

**低频过滤**： $$ D_{\text{filtered}} = {w \in D \mid \text{doc_freq}(w) \geq 5} $$ 移除在少于5个文档中出现的词

**高频过滤**： $$ D_{\text{filtered}} = {w \in D \mid \frac{\text{doc_freq}(w)}{|D|} \leq 0.5} $$ 移除在超过50%文档中出现的词

**词典大小限制**： $$ D_{\text{final}} = \text{top}(D_{\text{filtered}}, n=5000) $$ 保留最常见的5000个词

---

### 2.3 Bag-of-Words (BoW) 表示

将文档转换为词袋表示： $$ \text{BoW}(d) = {(w_i, c_i) \mid w_i \in d, c_i = \text{count}(w_i, d)} $$

其中 $c_i$ 是词 $w_i$ 在文档 $d$ 中出现的次数。

---

### 2.4 模型评估指标

#### 2.4.1 困惑度 (Perplexity)

衡量模型对未见数据的预测能力，值越低越好。

$$ \text{Perplexity}(D_{\text{test}}) = \exp\left(-\frac{\sum_{d \in D_{\text{test}}} \log P(d)}{\sum_{d \in D_{\text{test}}} N_d}\right) $$

其中：

- $P(d)$ 是文档 $d$ 的概率
- $N_d$ 是文档 $d$ 中的词数

#### 2.4.2 主题一致性 (Coherence Score)

使用 C_v 指标衡量主题内词汇的语义一致性：

$$ C_v = \frac{1}{|T|} \sum_{t \in T} \text{coherence}(t) $$

**一致性计算**： $$ \text{coherence}(t) = \frac{2}{|t|(|t|-1)} \sum_{i < j} \text{NPMI}(w_i, w_j) \cdot \text{cosine}(\vec{v}_{w_i}, \vec{v}_{w_j}) $$

其中：

- NPMI：归一化点互信息
- $\vec{v}_w$：词 $w$ 的上下文向量

取值范围：[-1, 1]，值越高表示主题一致性越好。

---

### 2.5 主题分配与聚合

#### 2.5.1 文档级主题分布

对于每篇评论 $d$，获得主题概率向量： $$ \theta_d = [P(z=1|d), P(z=2|d), ..., P(z=K|d)] $$

满足： $$ \sum_{k=1}^{K} P(z=k|d) = 1 $$

#### 2.5.2 餐厅级主题聚合

对于餐厅 $r$，其主题分布为该餐厅所有评论主题分布的平均：

$$ \theta_r = \frac{1}{|R_r|} \sum_{d \in R_r} \theta_d $$

其中 $R_r$ 是餐厅 $r$ 的所有评论集合。

#### 2.5.3 主导主题识别

$$ \text{dominant_topic}(r) = \arg\max_{k \in [1, K]} \theta_r[k] $$

$$ \text{dominant_prob}(r) = \max_{k \in [1, K]} \theta_r[k] $$

---

### 2.6 主题标签定义

本项目定义的6个主题：

|主题ID|标签|解释|
|---|---|---|
|0|食物质量|菜品口味、食材、烹饪水平|
|1|服务与员工|服务态度、响应速度、专业性|
|2|环境与氛围|装修、清洁度、氛围营造|
|3|性价比|价格合理性、分量|
|4|位置与便利性|交通、停车、地理位置|
|5|特色与体验|独特性、创新性、整体体验|

---

## 3. 网络可达性分析

### 3.1 街道网络建模

#### 3.1.1 OSMnx 网络获取

从 OpenStreetMap 获取城市街道网络，构建为图 $G = (V, E)$：

- $V$：节点集合（路口、端点）
- $E$：边集合（街道段）

**网络类型**：`all`（包含所有可通行道路）

#### 3.1.2 图的属性

**节点属性**：

- $(x, y)$：坐标（初始为WGS84经纬度）
- `osmid`：OpenStreetMap节点ID

**边属性**：

- `length`：长度（米）
- `highway`：道路类型
- `geometry`：几何形状（LineString）

---

### 3.2 坐标投影变换

#### 3.2.1 投影原理

**WGS84 (EPSG:4326)** → **UTM Zone 18N (EPSG:32618)**

**为什么需要投影？**

1. WGS84是球面坐标系，距离计算复杂且不准确
2. UTM是平面坐标系，可用欧氏距离，单位为米
3. Philadelphia位于UTM 18N区域，投影误差最小

#### 3.2.2 投影变换公式

使用 pyproj 的 Transformer：

```python
transformer = Transformer.from_crs("EPSG:4326", "EPSG:32618", always_xy=True)
x_utm, y_utm = transformer.transform(longitude, latitude)
```

**数学表示**： $$ (x_{\text{UTM}}, y_{\text{UTM}}) = \mathcal{T}_{\text{4326 → 32618}}(\text{lon}, \text{lat}) $$

投影后单位为米，便于距离和面积计算。

---

### 3.3 边的行程时间计算

#### 3.3.1 步行时间

**步行速度**：$v_{\text{walk}} = 4.5 \text{ km/h} = 1.25 \text{ m/s}$

对于边 $e$ 的步行时间： $$ t_{\text{walk}}(e) = \frac{L(e)}{v_{\text{walk}}} $$

其中 $L(e)$ 是边的长度（米）。

#### 3.3.2 驾车时间

**道路速度映射**：

|道路类型|速度 (km/h)|
|---|---|
|motorway|100|
|trunk|80|
|primary|60|
|secondary|50|
|tertiary|40|
|residential|30|
|service|20|
|unclassified|30 (默认)|

$$ t_{\text{drive}}(e) = \frac{L(e)}{v_{\text{road_type}}} $$

---

### 3.4 餐厅到网络节点的匹配

#### 3.4.1 最近节点查找

对于餐厅 $r$，找到网络中距离最近的节点：

$$ n_{\text{nearest}}(r) = \arg\min_{n \in V} d(r, n) $$

**距离计算**（UTM坐标系中的欧氏距离）： $$ d(r, n) = \sqrt{(x_r - x_n)^2 + (y_r - y_n)^2} $$

#### 3.4.2 关键修复说明

**原问题**：直接使用WGS84坐标在UTM投影网络中查找节点

**解决方案**：

1. 先将餐厅坐标投影到UTM
2. 使用投影后的坐标查找最近节点
3. 保证坐标系统一致

---

### 3.5 等时圈分析（Isochrone Analysis）

#### 3.5.1 步行等时圈

**定义**：从餐厅出发，在给定时间内可到达的所有节点集合。

**时间限制**：$T_{\text{walk}} = 10$ 分钟 $= 600$ 秒

**计算方法**：使用 NetworkX 的 `ego_graph` 函数

$$ \text{Ego}(n, T) = {v \in V \mid \exists \text{ path } p: n \to v, \sum_{e \in p} t(e) \leq T} $$

**步行可达性指标**：

1. **可达节点数**： $$\text{WalkNodes}(r) = |\text{Ego}(n_r, T_{\text{walk}})|$$
    
2. **可达街道长度**： $$\text{WalkLength}(r) = \sum_{e \in \text{Ego_edges}(n_r, T_{\text{walk}})} L(e)$$
    
3. **综合可达性得分**： $$\text{WalkScore}(r) = \text{WalkLength}(r)$$ （单位：米）
    

#### 3.5.2 驾车等时圈

**时间限制**：$T_{\text{drive}} = 15$ 分钟 $= 900$ 秒

**可达区域面积估算**：

使用**凸包算法**（Convex Hull）估算可达区域面积：

$$ \text{DriveArea}(r) = \text{Area}(\text{ConvexHull}({(x_n, y_n) \mid n \in \text{Ego}(n_r, T_{\text{drive}})})) $$

**凸包面积计算**： $$ A = \frac{1}{2} \left| \sum_{i=0}^{n-1} (x_i y_{i+1} - x_{i+1} y_i) \right| $$

转换为平方公里： $$ \text{DriveArea_km}^2 = \frac{A}{1,000,000} $$

**驾车可达性指标**：

1. **可达节点数**：$\text{DriveNodes}(r)$
2. **可达面积**：$\text{DriveArea}(r)$ (km²)
3. **综合得分**：$\text{DriveScore}(r) = \text{DriveArea}(r)$

---

### 3.6 介数中心性（Betweenness Centrality）

#### 3.6.1 定义

衡量节点在网络中作为"桥梁"的重要性。

**数学定义**：

$$ BC(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}} $$

其中：

- $\sigma_{st}$：节点 $s$ 到 $t$ 的最短路径总数
- $\sigma_{st}(v)$：通过节点 $v$ 的最短路径数

#### 3.6.2 归一化

$$ BC_{\text{norm}}(v) = \frac{BC(v)}{(|V|-1)(|V|-2)/2} $$

取值范围：[0, 1]

#### 3.6.3 近似算法

对于大型网络（节点数 > 5000），使用**采样近似算法**：

- 随机选择 $k = 1000$ 个源节点
- 计算这些源节点的最短路径
- 估算介数中心性

**时间复杂度**：

- 精确算法：$O(|V| \cdot |E|)$
- 近似算法：$O(k \cdot |E|)$

#### 3.6.4 物理意义

- **高介数中心性**：位于交通要道，客流潜力大
- **低介数中心性**：位于边缘区域，客流有限

---

## 4. 特征工程方法

### 4.1 单热编码（One-Hot Encoding）

#### 4.1.1 原理

将分类变量转换为二进制向量。

**示例**：

```
餐厅类别：["Chinese", "Italian", "Mexican"]
单热编码：[1, 0, 0] + [0, 1, 0] + [0, 0, 1]
```

#### 4.1.2 数学表示

对于 $m$ 个类别，单热编码为：

$$ \text{OneHot}(c_i) = [0, ..., 0, 1, 0, ..., 0] \in {0, 1}^m $$

其中第 $i$ 个位置为1，其余为0。

#### 4.1.3 本项目应用

提取Top 30最常见菜系类别，生成30个二进制特征：

$$ \text{cat_chinese} = \begin{cases} 1 & \text{if "Chinese" in categories} \ 0 & \text{otherwise} \end{cases} $$

---

### 4.2 价格等级标准化

#### 4.2.1 原始价格等级

Yelp价格等级：1-4（$ 到 $$$$）

#### 4.2.2 分位数标准化

**分位数计算**：

$$ \text{price_percentile}(r) = \frac{\text{rank}(r.\text{price})}{\text{total_count}} $$

取值范围：[0, 1]

**分位数解释**：

- 0.25：处于最便宜的25%
- 0.50：中等价格
- 0.75：处于最贵的25%

#### 4.2.3 价格分类

$$ \text{price_category}(r) = \begin{cases} \text{Low} & \text{if } \text{percentile} < 0.33 \ \text{Medium} & \text{if } 0.33 \leq \text{percentile} < 0.67 \ \text{High} & \text{if } \text{percentile} \geq 0.67 \end{cases} $$

---

### 4.3 评论数变换

#### 4.3.1 对数变换

评论数分布通常呈长尾分布，使用对数变换：

$$ \text{review_log}(r) = \log(1 + \text{review_count}(r)) $$

**加1的原因**：避免 $\log(0)$ 未定义

#### 4.3.2 分位数标准化

$$ \text{review_percentile}(r) = \frac{\text{rank}(r.\text{review_count})}{\text{total_count}} $$

#### 4.3.3 变换的统计学意义

**原始分布**：严重右偏，大部分餐厅评论数少，少数餐厅评论数极多

**对数变换后**：

- 压缩大值，扩展小值
- 接近正态分布
- 便于机器学习模型训练

**变换示例**：

```
原始：1, 10, 100, 1000
对数：0.69, 2.40, 4.61, 6.91
```

---

### 4.4 特征标准化理论

#### 4.4.1 Z-Score标准化

$$ z = \frac{x - \mu}{\sigma} $$

其中：

- $\mu$：均值
- $\sigma$：标准差

转换后：均值=0，标准差=1

#### 4.4.2 Min-Max标准化

$$ x' = \frac{x - x_{\min}}{x_{\max} - x_{\min}} $$

转换到 [0, 1] 区间

---

## 5. 空间聚类与竞争分析

### 5.1 情感极性计算

#### 5.1.1 情感极性公式

基于评分计算情感极性：

$$ \text{sentiment_polarity}(r) = \frac{\text{stars}(r) - 3}{2} $$

**映射关系**：

|评分|极性|解释|
|---|---|---|
|1星|-1.0|非常负面|
|2星|-0.5|负面|
|3星|0.0|中性|
|4星|+0.5|正面|
|5星|+1.0|非常正面|

#### 5.1.2 情感分类

$$ \text{sentiment_category}(p) = \begin{cases} \text{Very Positive} & \text{if } p > 0.5 \ \text{Positive} & \text{if } 0 < p \leq 0.5 \ \text{Negative} & \text{if } -0.5 < p \leq 0 \ \text{Very Negative} & \text{if } p \leq -0.5 \end{cases} $$

---

### 5.2 DBSCAN空间聚类

#### 5.2.1 算法原理

**DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**

基于密度的聚类算法，能够：

1. 发现任意形状的聚类
2. 识别噪声点
3. 不需要预先指定聚类数量

#### 5.2.2 核心概念

**邻域定义**： $$ N_\epsilon(p) = {q \in D \mid \text{dist}(p, q) \leq \epsilon} $$

**核心点**： $$ \text{Core}(p) \Leftrightarrow |N_\epsilon(p)| \geq \text{MinPts} $$

**直接密度可达**： $$ p \xrightarrow{\text{直接}} q \Leftrightarrow p \in \text{Core} \land q \in N_\epsilon(p) $$

**密度可达**： $$ p \leadsto q \Leftrightarrow \exists p_1, ..., p_n: p = p_1 \xrightarrow{\text{直接}} p_2 \xrightarrow{\text{直接}} ... \xrightarrow{\text{直接}} p_n = q $$

**聚类定义**： $$ C = {p, q \mid p \in \text{Core} \land p \leadsto q} $$

#### 5.2.3 参数设置

**情感聚类**：

- $\epsilon = 0.5$ km（搜索半径）
- $\text{MinPts} = 5$（最小密度）

**主题聚类**：

- $\epsilon = 0.3$ km
- $\text{MinPts} = 3$

#### 5.2.4 特征组合

**空间-属性联合聚类**：

$$ \vec{f}_i = [\underbrace{w \cdot x_i, w \cdot y_i}_{\text{空间坐标}}, \underbrace{a_i}_{\text{属性值}}] $$

其中：

- $(x_i, y_i)$：坐标（转换为公里）
- $a_i$：属性值（情感极性或主题强度）
- $w = 2.0$：空间权重

**权重说明**：

- 空间权重 > 1：强调地理邻近性
- 空间权重 = 1：等权重
- 空间权重 < 1：强调属性相似性

#### 5.2.5 坐标转换

**经纬度到公里**（Philadelphia纬度≈40°）：

$$ \begin{aligned} x_{\text{km}} &= \text{longitude} \times 85.0 \ y_{\text{km}} &= \text{latitude} \times 111.0 \end{aligned} $$

**近似公式**： $$ \begin{aligned} 1° \text{ 纬度} &\approx 111 \text{ km} \ 1° \text{ 经度} &\approx 111 \times \cos(\text{lat}) \approx 85 \text{ km (at 40°)} \end{aligned} $$

---

### 5.3 邻域竞争特征

#### 5.3.1 邻域定义

对于餐厅 $r_i$，其邻域定义为：

$$ \mathcal{N}(r_i, R) = {r_j \mid d(r_i, r_j) \leq R, j \neq i} $$

本项目设置 $R = 1.0$ km（竞争半径）

#### 5.3.2 距离矩阵计算

使用欧氏距离计算所有餐厅对之间的距离：

$$ D_{ij} = \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2} $$

**距离矩阵**：$D \in \mathbb{R}^{n \times n}$，其中 $n$ 是餐厅数量

#### 5.3.3 邻域统计特征

**1. 邻域餐厅数量**： $$ \text{NeighborCount}(r_i) = |\mathcal{N}(r_i, R)| $$

**2. 邻域平均评分**： $$ \text{NeighborAvgStars}(r_i) = \frac{1}{|\mathcal{N}(r_i, R)|} \sum_{r_j \in \mathcal{N}(r_i, R)} \text{stars}(r_j) $$

**3. 邻域平均价格**： $$ \text{NeighborAvgPrice}(r_i) = \frac{1}{|\mathcal{N}(r_i, R)|} \sum_{r_j \in \mathcal{N}(r_i, R)} \text{price}(r_j) $$

**4. 竞争强度**： $$ \text{CompetitionIntensity}(r_i) = \text{NeighborCount}(r_i) \times \log(1 + \text{NeighborAvgStars}(r_i)) $$

**物理意义**：

- 邻域餐厅多 → 竞争激烈
- 邻域评分高 → 竞争质量高
- 对数平滑：避免极值影响

---

### 5.4 差异化特征

#### 5.4.1 主题独特性（余弦距离）

**余弦相似度**： $$ \text{cosine_sim}(\vec{a}, \vec{b}) = \frac{\vec{a} \cdot \vec{b}}{||\vec{a}|| \cdot ||\vec{b}||} = \frac{\sum_i a_i b_i}{\sqrt{\sum_i a_i^2} \cdot \sqrt{\sum_i b_i^2}} $$

**余弦距离**： $$ \text{cosine_dist}(\vec{a}, \vec{b}) = 1 - \text{cosine_sim}(\vec{a}, \vec{b}) $$

**主题独特性计算**：

对于餐厅 $r_i$，其主题向量为 $\vec{\theta}_i = [\theta_{i,1}, ..., \theta_{i,K}]$

$$ \text{TopicUniqueness}(r_i) = \frac{1}{|\mathcal{N}(r_i, R)|} \sum_{r_j \in \mathcal{N}(r_i, R)} \text{cosine_dist}(\vec{\theta}_i, \vec{\theta}_j) $$

**取值范围**：[0, 1]

- 接近0：与邻域主题高度相似
- 接近1：主题非常独特

#### 5.4.2 价格差异化

**标准差方法**： $$ \text{PriceDiff}(r_i) = |\text{price}(r_i) - \text{NeighborAvgPrice}(r_i)| $$

**标准化**： $$ \text{PriceDiff_norm}(r_i) = \frac{\text{PriceDiff}(r_i)}{\sigma_{\text{price}}} $$

#### 5.4.3 菜系稀缺性

**类别向量**：$\vec{c}_i = [c_{i,1}, ..., c_{i,M}]$，$M$ 为类别总数

**邻域类别频率**： $$ f_k = \frac{1}{|\mathcal{N}(r_i, R)|} \sum_{r_j \in \mathcal{N}(r_i, R)} c_{j,k} $$

**稀缺性得分**： $$ \text{CategoryRarity}(r_i) = 1 - \max_{k: c_{i,k}=1} f_k $$

**解释**：

- 若餐厅类别在邻域中很常见 → 稀缺性低
- 若餐厅类别在邻域中很少见 → 稀缺性高

---

### 5.5 相对竞争表现

#### 5.5.1 评分优势

$$ \text{StarsAdvantage}(r_i) = \text{stars}(r_i) - \text{NeighborAvgStars}(r_i) $$

**解释**：

- 正值：评分高于邻域平均，有竞争优势
- 负值：评分低于邻域平均，处于劣势
- 零值：与邻域持平

#### 5.5.2 综合竞争优势得分

**多维度加权**： $$ \begin{aligned} \text{CompAdv}(r_i) = &\ w_1 \cdot \text{StarsAdvantage}(r_i) \ &+ w_2 \cdot \text{TopicUniqueness}(r_i) \ &+ w_3 \cdot \text{PriceDiff_norm}(r_i) \ &+ w_4 \cdot \text{CategoryRarity}(r_i) \end{aligned} $$

**默认权重**：$w_1 = w_2 = w_3 = w_4 = 0.25$（等权重）

**标准化**（Min-Max）： $$ \text{CompAdv_norm}(r_i) = \frac{\text{CompAdv}(r_i) - \min(\text{CompAdv})}{\max(\text{CompAdv}) - \min(\text{CompAdv})} $$

---

### 5.6 战略区域识别

#### 5.6.1 多维度分类规则

基于竞争强度、质量和独特性的组合分类：

**规则系统**：

1. **Premium District（高端区域）** $$ \text{CompIntensity}(r) > Q_{75} \land \text{NeighborAvgStars}(r) \geq 4.0 $$
    
2. **Saturated Market（饱和市场）** $$ \text{CompIntensity}(r) > Q_{75} \land \text{NeighborAvgStars}(r) < 3.5 $$
    
3. **Niche Opportunity（细分机会）** $$ \text{CompIntensity}(r) < Q_{25} \land \text{TopicUniqueness}(r) > 0.6 $$
    
4. **Underserved Area（服务不足区域）** $$ \text{CompIntensity}(r) < Q_{25} \land \text{TopicUniqueness}(r) \leq 0.6 $$
    
5. **Standard Zone（标准区域）** $$ \text{其他情况} $$
    

其中 $Q_{25}$、$Q_{75}$ 分别是竞争强度的第25和第75分位数。

#### 5.6.2 战略含义

|区域类型|特征|建议策略|
|---|---|---|
|Premium District|高竞争+高质量|品质优先，差异化定位|
|Saturated Market|高竞争+低质量|质量提升或退出|
|Niche Opportunity|低竞争+高独特性|保持特色，精准营销|
|Underserved Area|低竞争+低独特性|市场培育，规模扩张|
|Standard Zone|中等竞争|稳健经营，持续优化|

---

## 6. 统计学方法总结

### 6.1 描述性统计

**均值**： $$ \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i $$

**标准差**： $$ \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2} $$

**分位数**（百分位数）： $$ Q_p = \text{value at position } \lceil p \cdot n \rceil \text{ in sorted data} $$

### 6.2 距离度量

**欧氏距离**： $$ d_{\text{Euclidean}}(\vec{x}, \vec{y}) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2} $$

**曼哈顿距离**： $$ d_{\text{Manhattan}}(\vec{x}, \vec{y}) = \sum_{i=1}^n |x_i - y_i| $$

**余弦距离**： $$ d_{\text{Cosine}}(\vec{x}, \vec{y}) = 1 - \frac{\vec{x} \cdot \vec{y}}{||\vec{x}|| \cdot ||\vec{y}||} $$

### 6.3 数据变换

**对数变换**： $$ y = \log(1 + x) $$

**Box-Cox变换**： $$ y = \begin{cases} \frac{x^\lambda - 1}{\lambda} & \text{if } \lambda \neq 0 \ \log(x) & \text{if } \lambda = 0 \end{cases} $$

---

## 7. 复杂度分析

### 7.1 LDA训练

- **时间复杂度**：$O(P \times I \times K \times D \times N)$
    - $P$：passes（轮数）
    - $I$：iterations（迭代次数）
    - $K$：主题数
    - $D$：文档数
    - $N$：平均文档长度

### 7.2 距离矩阵计算

- **时间复杂度**：$O(n^2 \times d)$
    
    - $n$：餐厅数量
    - $d$：特征维度
- **空间复杂度**：$O(n^2)$
    

### 7.3 DBSCAN聚类

- **时间复杂度**：$O(n^2)$（最坏情况）
- **使用空间索引优化**：$O(n \log n)$（KD-Tree）

### 7.4 介数中心性

- **精确算法**：$O(|V| \cdot |E|)$
- **近似算法**：$O(k \cdot |E|)$，$k$ 为采样数

---

## 8. 关键技术要点总结

### 8.1 为什么使用LDA？

1. **无监督学习**：不需要标注数据
2. **主题可解释性**：提取的主题有明确语义
3. **概率模型**：给出主题分布的不确定性
4. **适合短文本**：评论文本适合主题建模

### 8.2 为什么使用DBSCAN？

1. **无需预设聚类数**：自动发现聚类
2. **识别任意形状**：不限于球形聚类
3. **噪声识别**：自动识别离群点
4. **密度自适应**：适应不同密度区域

### 8.3 为什么使用余弦距离？

1. **适合高维稀疏数据**：主题向量通常稀疏
2. **关注方向而非大小**：侧重主题分布模式
3. **取值范围固定**：[0, 1]，便于解释

### 8.4 为什么进行坐标投影？

1. **准确距离计算**：球面变平面
2. **单位统一**：米为单位，便于理解
3. **减少误差**：选择合适投影减少变形

---

## 9. 可能的答辩问题与回答要点

### Q1: LDA的主题数K=6是如何确定的？

**答**：

1. 业务经验：餐饮评论通常涉及6个核心维度（食物、服务、环境、价格、位置、体验）
2. 困惑度实验：尝试K=4-10，选择困惑度和一致性平衡点
3. 可解释性：主题数太多难以解释，太少无法区分

### Q2: 为什么步行等时圈选择10分钟？

**答**：

1. 城市规划标准：步行10分钟≈800米，符合社区生活圈概念
2. 消费者行为：多数顾客愿意步行前往的最大距离
3. 数据分布：10分钟能覆盖足够邻域但不过度重叠

### Q3: DBSCAN的eps参数如何选择？

**答**：

1. K-距离图：观察数据在不同半径下的密度变化
2. 领域知识：0.5km符合商业区规模
3. 实验调优：尝试0.3-1.0km，评估聚类效果

### Q4: 为什么竞争半径选择1公里？

**答**：

1. 消费者选择半径：顾客通常在1km内比较餐厅
2. 城市密度：Philadelphia餐厅密度下1km覆盖足够竞争者
3. 计算效率：半径太大导致计算复杂度显著增加

### Q5: 如何验证模型的有效性？

**答**：

1. **LDA**：一致性得分、困惑度、人工评估主题质量
2. **聚类**：轮廓系数、DB指数、可视化检查
3. **可达性**：与实际POI分布、人流数据对比
4. **竞争分析**：与业务表现（评分、评论数）的相关性

---

## 10. 技术创新点

### 10.1 多模态特征融合

整合了：

- 文本语义特征（LDA主题）
- 地理空间特征（可达性、聚类）
- 商业属性特征（价格、类别）
- 竞争关系特征（邻域分析）

### 10.2 空间-属性联合聚类

不是单纯的空间聚类或属性聚类，而是： $$ \vec{f} = [w \cdot \vec{x}_{\text{spatial}}, \vec{x}_{\text{attribute}}] $$

同时考虑地理邻近性和属性相似性。

### 10.3 多层次可达性评估

- **微观**：步行可达性（10分钟）
- **中观**：驾车可达性（15分钟）
- **宏观**：网络中心性（全局位置）

三个层次综合评估位置价值。

### 10.4 战略区域智能识别

基于多维度规则的自动分类系统，为商业决策提供直接支持。

---

## 附录：核心公式速查

|方法|核心公式|
|---|---|
|LDA主题分布|$\theta_d \sim \text{Dir}(\alpha)$|
|困惑度|$\exp(-\frac{\sum_d \log P(d)}{\sum_d N_d})$|
|一致性|$C_v = \frac{1}{\|T\|} \sum_t \text{coherence}(t)$|
|介数中心性|$BC(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}}$|
|DBSCAN核心点|$\|N_\epsilon(p)\| \geq \text{MinPts}$|
|余弦距离|$1 - \frac{\vec{a} \cdot \vec{b}}{\|\vec{a}\| \cdot \|\vec{b}\|}$|
|竞争强度|$\text{Count} \times \log(1 + \text{AvgStars})$|
|主题独特性|$\frac{1}{n} \sum_j \text{cosine_dist}(\vec{\theta}_i, \vec{\theta}_j)$|
|情感极性|$\frac{\text{stars} - 3}{2}$|

---

**文档版本**：v1.0  
**最后更新**：2026-01-02  
**适用于**：基于Yelp数据集的城市餐厅商业活力分析课程设计答辩