# Chapter 1. 计算机系统漫游：概述一下即将学到的东西
## 1.1 信息就是位+上下文
  **源程序（源文件）：程序员通过编辑器创建的文本文件**（以 .c或 .cpp为后缀）

  一个程序的生命周期是从一个源程序开始的，**源程序实际上就是一个由值0和1组成的** **位(比特)序列**。8个位被组织成一组，称为**字节**

  每个字节用于表示程序中的某些文本字符。现代的大部分计算机系统都采用**ASCII标准**来表示文本字符：**用唯一的单字节大小整数值来表示每个字符**

例如：字符-ASCII码： a - 97   \n - 10

  一个name.c或name.cpp程序是以**字节序列**的方式存储在文件中的，每个字节都有一个整数值对应于某些字符 (**注意：每个文本行都由一个看不见的换行符\n结束**)

  **只由ASCII字符构成的文件称为** **文本文件** **，其他均称为** **二进制文件**

这提示我们一个基本思想：**系统中的所有信息(包括磁盘文件、内存中的程序及用户数据、网络上传输的数据) 都是由一串比特表示的**

**而区分不同数据对象的唯一方法是根据我们读到这些数据对象时的** **上下文**，例如：在不同的上下文中，一个同样的字节序列可能表示一个整数/浮点数/机器指令/......

## 1.2 程序被其他程序翻译为不同格式
  以C语言为例，**一个程序的生命周期从一个** **高级C语言程序** **开始**，这种形式的代码可以被人读懂。然而为了能在系统上运行，每条C语言语句都必须被其他一系列程序转化为一系列的低级机器指令，然后这些指令按照一种称为"**可执行目标程序（又称"可执行目标文件"）**"的格式打好包，并以**二进制磁盘文件**的形式存放。

  在Unix系统上，由源文件到目标文件的转化是由**编译器驱动程序**完成的，即由编译器驱动程序读取源程序文件name.c并将它翻译为一个可执行目标文件name（无后缀）

  翻译过程主要分为四个阶段，**执行这四个阶段的程序构成** **编译系统** ：
  ![[Pasted image 20240711135022.png]]
  ①预处理阶段： 预处理器（cpp）根据以字符#开头的命令，修改原始的c程序。

例如：#include <stdio.h>命令告诉预处理器去读取系统头文件stdio.h的内容，并将其直接插入程序文本中，从而得到另一个**通常以 .i 作为文件扩展名的C程序**

②编译阶段：编译器（ccl）将文本文件name.i翻译为文本文件name.s，该文本文件包含一个**汇编语言程序**（**以一种文本格式描述低级机器语言指令**）

**汇编语言为不同高级语言的不同编译器提供通用的输出语言**

③汇编阶段：汇编器（as）将name.s翻译为机器语言指令，并将这些指令以**可重定位目标程序**的格式打包，将结果保存在name.o中

name.o 是一个二进制文件，它包含的字节是main函数的指令编码

④链接阶段：我们的程序会调用许多编译器提供的标准库函数，此时这些函数存在于名为"函数名.o"的单独的已经预编译好了的**目标文件**中，这些目标文件必须以某种方式合并到程序name.o中，这个过程通过链接器（ld）实现

而链接的结果就是得到**可执行(目标)文件**name，它可以被加载至内存中，由系统运行。

一些最令人困扰的错误往往与链接器操作有关。对编译系统工作方式的深入理解有利于我们优化代码、理解出现的各种错误以及避免可能的安全漏洞。

## 1.3 处理器 读并解释存储在内存中的指令
  在源程序name.c被编译系统翻译为可执行目标文件name并存放在磁盘上以后，**要想在Unix系统上运行该可执行文件，需要将其文件名输入到名为shell的应用程序中**，例如：

                                linux> ./name

                                 (执行命令)

                                linux>

  shell是一个命令行解释器，它输出一个提示符>，并等待输入一个命令行再执行它。**如果该命令行的第一个单词不是一个内置的shell命令，那么它会假设这是一个可执行文件的名字，然后加载并运行它**。在执行结束后会输出另一个提示符，并等待下一个命令行输入

## 1.4 系统的硬件组成
一个典型系统的硬件组织：
![[Pasted image 20240711135638.png]]
①**总线：贯穿整个系统的一组电子管道**

  它携带信息字节并负责在各个部件间传递。通常被设计为传送定长的字节块（即字word）。**字中的字节数（****字长****）**是一个基本的系统参数，在不同系统有所不同。现在大多数机器是4个字节(32位)或8个字节(64位)

②**I/O设备 (输入/输出设备)：是系统与外部世界联系的通道**

我们的示例系统中包括四个I/O设备：作为用户输入的键盘与鼠标，作为用户输出的显示器，用于长期储存数据与程序的磁盘。

每个I/O设备都通过一个**控制器或适配器**与I/O总线相连。

控制器是设备本身或者系统的主板，而适配器是一块插在主板插槽上的卡。**它们的功能是在I/O设备与I/O总线之间传递信息**

③**主存：一个在处理器执行程序时存放程序与程序处理的数据的==临时存储设备**==

主存是由一组动态**随机存取存储器芯片**组成的，它是一个**线性的字节数组**，每个字节都有其唯一的地址（数组索引，从0开始）。

**一般来说，组成程序的每条机器指令都由不同数量的字节组成**。变量相对应的数据的字节大小则根据其类型变化

④**处理器(CPU，中央处理单元)：是解释或执行存储在主存中机器指令的引擎**

**处理器的核心在于一个大小为一个字的存储设备(寄存器)**，称为**程序计数器(PC)**。PC在任何时刻都指向主存中的某条机器指令（含有该条指令的地址）

**处理器则一直不断地处理程序计数器指向的机器指令，处理完毕后更新程序计数器至下一条指令**。(**下一条指令不一定与处理完毕的这条相邻**)

处理器按照指令集架构决定的指令执行模型工作，该模型中指令有严格的执行顺序，处理器按顺序执行指令指导的简单操作

于是，一个程序在运行时发生的过程大体可以被归纳为：

向shell程序输入字符串"name"，shell程序将字符逐一读入寄存器，再将它存放到内存中(主存储器)。当输入完毕并按下回车键后，shell执行一系列指令将目标文件name中的代码从磁盘复制到主存，随即处理器开始执行目标文件main程序中的机器指令，将其输出的字符串逐字符地从主存复制到寄存器，再从寄存器复制到显示设备上。

可以发现，**系统花费大量时间用于将信息从一个地方挪动到另一个地方（各种复制操作）**，这些复制操作就是所谓的开销，减慢了程序的工作。**因此我们希望这些复制操作能尽量快地被完成**

**机器原理** **告诉我们：一个较大的存储设备比一个较小的存储设备运行得慢，而快速设备的造价会比同类的低速设备高**。寄存器能存储的信息远小于主存，而处理器从寄存器中读取信息的速度则远大于从主存中读取的速度，因此我们从处理器入手提升运行速度会比提升主存运行速度更好。

我们不妨在处理器与一个较大较慢的设备（例如主存）之间插入一个更小更快的存储设备。高速缓存存储器就是其中一种，高速缓存作为处理器与主存之间暂时的集结区域，存放处理器近期可能会用到的信息，通常的系统包含L1到L2高速缓存的两级高速缓存，而性能更好的系统则会有L1到L3高速缓存的三级高速缓存，这会使系统具有一个很大的存储器，同时访问速度还很快。

**局部性原理** **：程序具有访问局部区域里的数据和代码的趋势**。这就是在高速缓存中存储近期可能经常访问的数据会大幅度提升运行速度的原因。

顺着这样的思想，我们可以将计算机中的每个存储设备组织成一个**存储器层次结构**
![[Pasted image 20240711135951.png]]

**存储器层次结构的主要思想是上一层的存储器作为下一层层存储器的高速缓存**。因此，寄存器文件就是L1的高速缓存，L1就是L2的高速缓存......以此类推。

对存储器层次结构的深刻理解有利于我们利用它来提高程序的性能

## 1.5 操作系统管理硬件
在加载和运行一个程序时，解释器程序与目标程序并没有直接访问各硬件，而是通过**操作系统**提供的服务来实现。我们可以将操作系统视为应用程序与硬件之间插入的一层软件。

**所有应用程序对硬件的** **操作尝试** **都必须经过操作系统来完成**。操作系统有两个基本功能：

**①防止硬件被失控的应用程序滥用；②为应用程序提供简单一致的机制来控制复杂又不同的低级硬件设备**。  这两个功能通过以下几个基本抽象概念实现
### 1.5.1 进程
  程序运行时，操作系统会提供一种**整个系统上只有该程序在运行，它独占地使用了系统的所有硬件**的假象，这种假象是通过**进程**实现的。

   **进程** **是操作系统对一个正在运行的程序的抽象，一个系统上可以同时运行多个进程，每个进程看上去都像是在独占地使用硬件。**

**并发运行：一个进程的指令与另一个进程的指令是交错执行的**

在大多数系统中，需要运行的进程往往大于cpu个数，令cpu看上去像是在**并发地执行多个进程**，**正是通过处理器在进程间切换来实现的，** **操作系统** **实现这种交错执行的机制称为** **上下文机制**。

**上下文：操作系统所保持的跟踪进程运行所需的所有状态信息**，例如PC与寄存器文件的当前值、主存的内容等等

**当操作系统决定要把控制权从当前进程转移到某个新进程时，就会** **保存** **当前进程的上下文，** **恢复** **新进程的上下文，将控制权转移到新进程，使新进程** **从上次停止的地方开始** **，这就是** **上下文切换**。

以shell程序进程与name程序进程为例，其上下文切换机制如下图所示：

一开始只有shell进程在运行，当我们让它运行name程序时，创建一个新进程name及其上下文，并且将控制权转让给name进程，name进程终止后恢复shell进程的上下文，并将控制权转让给它，让shell程序等待下一个指令的输入。
![[Pasted image 20240712223402.png]]
**操作系统内核** **管理从一个进程到另一个进程的转换**。**内核是操作系统的代码中** **常驻在主存中的部分**，它并不是一个独立的进程，**而是系统管理全部进程所用代码和数据结构的集合**。

当应用程序需要操作系统的某些操作时，它就执行一条特殊的**系统调用指令**，将控制权传递给内核，然后内核执行被请求的操作并返回给应用程序。

### 1.5.2 线程

**在现代系统中，一个** 进程 **实际上可以由多个被称为** 线程 **的执行单元组成。每个线程都运行在进程的上下文中， 并共享同样的代码与全局数据**。多线程之间比多进程更容易共享数据，同时线程一般来说比进程更加高效，多线程是一种使程序运行得更快的方法

### 1.5.3 虚拟内存

**虚拟内存**也是一个抽象概念，它为每个进程提供一个假象：**每个进程都在独立地使用主存**。每个进程看到的内存都是一致的，这个内存称为虚拟地址空间。

Linux进程的虚拟地址空间如下图所示，地址空间的底部区域存放用户进程定义的代码与数据，而最上面的区域保留给操作系统的代码与数据，地址从下往上增大
![[Pasted image 20240712223532.png]]
可见每个进程的虚拟地址空间由大量准确定义的区组成，每个区都有专门的功能：

从最低的地址开始，逐步向上介绍
①**程序代码与数据**：对于所有进程，代码是从同一固定地址开始的，而数据指的是全局变量的数据，保存在相应位置上。代码与数据区按照可执行目标文件的内容初始化。

②**堆**：也叫**运行时堆**，代码与数据区在进程开始运行时就被指定了大小，而堆随着函数调用等，在运行过程中动态扩展与收缩大小

③**共享库**：地址空间靠近中间的部分是用来存储类似于标准库与数学库这些共享库的代码与数据的。

④栈：用户栈位于用户虚拟地址空间顶部，编译器用它来实现函数调用，栈在调用函数时扩张，函数返回时收缩，在程序期间动态改变大小。

⑤内核虚拟内存：地址空间的顶部是为内核保留的，不允许应用程序读写这个区域的内容或直接调用内核代码定义的函数，而是通过调用内核来执行这些操作

     虚拟内存的运作需要硬件与操作系统软件之间的精密交互，其基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为磁盘的高速缓存。

### 1.5.4 文件

文件就是字节序列。每个IO设备，包括键盘、显示器甚至网络，都可以视为是文件。实际上系统中的所有输入输出都是通过使用一小组称为Unix I/O的系统函数调用读写文件来实现的。

文件为应用程序提供了一个统一的视图，来看待系统中可能含有的各式各样的I/O设备，这会在后面学习到

## 1.6 系统之间利用网络通信

现代系统经常通过网络与其他系统连接到一起。对于一个单独的系统，网络可以看作是一个I/O设备，系统通过网络适配器与网络进行交互，并且传输自己主存中复制的字节或接受其他机器的数据并储存到主存。

基于网络复制信息是非常重要的用途，特别是在客户端与服务器之间的交互中。

## 1.7 贯穿计算机系统所有方面的重要概念

### 1.7.1 Amdahl定律

该定律的主要思想是：当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。

设系统执行某应用程序所需的时间为T_old，系统**某一部分所需执行时间**与**总时间**的比例为α，而**该部分性能提升比例**为k，提升该部分性能后执行该应用程序所需时间为T_new，则有：
![[Pasted image 20240712223608.png]]
也就是说，要想显著加速整个系统，必须提升全系统中相当大的部分的速度。

我们常用T_old / T_new 来表示性能提升，若性能有所提升，该比值应大于1。我们用后缀"X"表示比例，例如“2.2X”读作“2.2倍”

在Amadahl定理中，求k→∞时的极限可把α/k这项去掉，也就是说该极限式刻画了当性能加强到这部分的运行几乎不花时间的地步时，整个系统能被加速到多少倍（上界）

### 1.7.2 并发和并行

**并发：指一个同时具有多个活动的系统**

**并行：用并发来使一个系统运行得更快**

 并行可以在计算机系统的多个抽象层次上使用，我们按照系统层次结构中由高到低的顺序重点强调以下三个层次：

①线程级并发：通过在线程这个抽象上构建，我们能够设计出同时有多个程序执行的系统，从而导致并发。而运用线程，我们甚至可以在一个进程中执行多个控制流。

在**传统意义的并发**中，它的执行只是模拟出来的，**本质上是通过使一台计算机在它正执行的进程间快速切换来实现的**。而且以前即使处理器必须在多个任务中切换，大多数计算也都是由一个处理器完成的，这种配置称为==**单处理器系统**==

多处理器系统：一个由单操作系统内核控制的多处理器组成的系统。多处理器分为多核处理器与超线程的：

- 多核处理器是将多个CPU(核)集成到一个集成电路芯片上，每个核都有自己的L1与L2高速缓存，其中L1高速缓存又分为保存最近取到的指令的指令高速缓存，与保存数据的数据高速缓存。除此以外，所有的核还共享一个统一的高速缓存L3，以及到主存的接口

- 超线程（同时多线程）是一项允许一个CPU执行多个控制流的技术，因为CPU的某些硬件有多个备份，其处理器可以在单个周期的基础上决定要执行哪个线程，使cpu更好地利用其处理资源

多处理器的使用减少了在执行多个任务时模拟并发的需要，并且可以使程序运行得更快。

②指令级并行：在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。处理器使用了非常多的聪明技巧来同时处理多条指令，例如流水线技术。

如果处理器能够达到比一个周期一条指令更快的执行速率，就称其为超标量处理器，利用其高级模型可以理解程序的性能，写出更高程度指令级并行性的代码，加快程序运行。在后面会学到

③单指令、多数据并行：在最低层次上，许多现代处理器用有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即SIMD并行。

提供SIMD指令大多是为了提高处理影像与声音等的执行速度

### 1.7.3 抽象
抽象的使用是计算机科学中最为重要的概念之一。计算机系统中使用的几个抽象如下图所示：
![[Pasted image 20240712223625.png]]
     在处理器中，指令集架构提供了对实际处理器硬件的抽象，使用该抽象，机器代码程序表现得就好像运行在一个一次只执行一条指令的处理器上。其底层的硬件远比抽象描述的要复杂

   而虚拟机则是对整个计算机的抽象，包括操作系统，处理器与程序员，在后面的章节中，这些抽象将被详细介绍


---



# Chapter 2. 信息的表示和处理

现代计算机存储和处理的信息以二值信号表示，这些二进制数字（位）是数字革命的基础。二值信号更容易被表示，存储与传输。孤立的位并没有作用，只有把位组合在一起，再加上某种解释（赋予不同的可能位模式以含义），我们就可以表示任何有限集合的元素，例如用位组编码非负数，用标准字符码编码文档中的字母与符号。

**三种最重要的数字表示：

**❶无符号编码：基于传统的二进制表示法，表示大于等于零的数字

**❷补码编码：表示有符号整数的最常见的方式

**❸浮点数编码：用于表示实数的以2为基数的版本的科学计数法

计算机用这些不同的表示方法来进行算术运算，这些表示方法的位数是有限的，因此若结果太大以至于不能被表示时，某些运算就会被溢出，产生令人吃惊的结果。

**整数的计算机运算满足人们熟知的整数运算的许多性质**，如乘法结合律和交换律。**而浮点数运算表示的精度有限，是不可结合的。

整数和浮点数运算的数学属性不同来自于它们处理数字表示有限性的方式不同——整数的表示虽然只能编码一个相对较小的数值范围，但这种表示是精确的；而浮点数编码的范围虽然较大，但它的表示是近似的。

大量计算机的安全漏洞都是由于计算机算术运算的微妙细节引发的，因此对程序如何进行算术运算的深入理解有助于我们去理解这些不良行为的产生原因并进行预防。

## 2.1 信息存储

大多数计算机使用**8位的块，或者字节**，作为**最小的可寻址的内存单位**，而不是访问内存中单独的块。

机器级程序将内存视为一个非常大的**字节数组**，称为**虚拟内存**；**内存的每一个字节都由一个唯一的数字来标识，称为它的地址**；所有可能地址的集合就称为**虚拟地址空间。

这个虚拟地址空间并不是真实的，只是一个展现给机器级程序的概念性映像，其实际的实现在后面会讲到。

下面的章节我们将学习编译器和运行时系统是如何将存储器空间划分为更可管理的单元，来存放不同的程序对象（即程序数据、指令和控制信息）。可以用各种机制来分配和管理程序不同部分的存储，这种管理完全是在虚拟地址空间内完成的。

例如，c语言中**一个指针的值**（无论指针指向一个整数、结构还是其他程序对象）都是**某个存储块的第一个字节的虚拟地址**，同时c编译器还把每个指针和类型信息联系起来，从而可以根据指针值的类型生成不同的机器级代码来访问指针指向位置处存储的值。（**注意编译器生成的机器级程序并不包含数据类型的信息**）

**每个程序对象可被视为一个字节块，而程序本身就是一个字节序列。**

### 2.1.1 十六进制表示法

一个字节由8位组成，在二进制表示中其值域为00000000~11111111，即0~255。十进制与二进制表示法都不适合描述位模式：二进制表示法过于冗长，而十进制表示法与位的互相转换非常麻烦。因此一个替代的方法是十六进制表示法：以16为基数来表示位模式。

十六进制使用数字0~9以及字符A~F来表示16个可能的值，在c语言中使用0x或0X进行标识。一个字节的值域为00~FF

编写机器级程序的一个任务就是在位模式的十进制、二进制与十六进制之间进行转换。

二进制与十六进制之间的转换比较简单，**给出一个十六进制数，想把它转换为二进制数，只需要根据下表将每一位数字转换为二进制数即可：**
![[Pasted image 20240712223729.png]]
反之，如果想把二进制数转换为十六进制，**只需要将二进制数从右往左每4位分为一组，如果到了最左边余下的数不足4位，那就用0将左边的空位补上补足4位，然后将所有组别的二进制值数转换为十六进制数即可。**

当值x为2的非负整数n次幂$2^n$时，写成十六进制形式十分简单，因为此时x的二进制表示是最左一位为1，后面为n个0，此时我们只需要把n表示为i+4j的形式，i只能为0或1或2或3，此时补0后对应的十六进制数是1或2或4或8，然后后面的j个十六进制数均为0。

**十进制与十六进制之间的转换需要使用乘法或除法来处理一般情况**。将一个十进制数x转换为十六进制数，可以**反复地用16除x，得到一个商q和余数r，此时x = 16q + r，然后我们用余数r的十六进制表示作为最低位数字，令x = q继续这个过程，余数的位数逐渐升高，直到q = 0停止**，就得到了完整的十六进制表示。

反之，将十六进制数转换为十进制，我们用16的(**对应位次号 - 1**)次幂乘上该位次上的数的十进制表示，然后分别加起来即可，例如：0x7AF转换为十进制就是7 * 16^(3 - 1) + 10 * 16^（2 - 1） + 15 * 16^(1 - 1) = 1967

### 2.1.2 字数据大小

**每台计算机都有一个字长，指明指针数据的标称大小**。因为**虚拟地址是用这样一个字来编码的**，所以字长决定的最重要的系统参数就是**虚拟地址空间的最大大小**：对于一个字长为w位的机器而言，虚拟地址的范围为 0 ~ ($2^w$)-1 ，程序最多访问$2^w$个字节。

例如32位字节限制虚拟地址空间为4千兆字节(4GB)，64位字节则为8GB

大多数64位机器也可以运行为32位机器编译的程序，反之32位机器则不能向上兼容64位机器程序。因此我们将程序分为“32位程序”与“64位程序”并不是取决于机器类型，而是取决于程序是如何编译的。

计算机与编译器支持多种方式编码的数字格式，如不同长度的整数与浮点数。C语言支持整数和浮点数的多种数据格式，例如int 有符号 ，unsigned int 无符号，且在32位与64位程序中各类型的字节可能有所变化，例如long类型。

为了避免由于依赖类型大小与不同编译器设置带来的奇怪行为，ISO C99引入了**大小不随编译器与机器设置而改变的数据类型**，其中包含int32_t和int64_t，分别占4字节与8字节。想精准控制数据表示时，**应该尽量使用这样大小固定的数据类型**。

大部分数据类型都被编码为有符号数值，除非有前缀关键字unsigned或对确定大小的数据类型使用了特定的无符号声明。要注意一个例外: char，尽管大多数编译器和机器设置将它们视为有符号数，但在C标准下这一点并不被保证，需要添加关键字signed char才能保证它是有符号的。（不过对于char是否有符号在大部分情况下程序都不敏感）

顺带一提，关键字的声明顺序在c语言中非常自由， unsigned long 和 long unsigned和unsigned long int和long unsigned int都可以使用，且表示相同的数据类型。

一些其他类型的字长如下：
![[Pasted image 20240712223757.png]]
为了保证程序的**可移植性**，程序员必须确保程序对不同数据类型的确切大小不敏感。后面会了解到，C语言为不同数据类型的数字范围设置了下界，而并没有设置上界，正是因为32位程序移植到64位机器上时常常因**隐藏的对字长依赖性**而产生问题。

### 2.1.3 寻址和字节顺序

对于跨越多字节的程序对象，我们必须建立两个规则：这个对象的地址是什么，以及在内存中如何排列这些字节。

❶对象的地址：在几乎所有机器上，多字节对象都被存储为连续的字节序列，而该对象的地址为所使用字节中最小的地址。例如：设一个int类型的变量x的地址为0x100，即&x为0x100，那么x的四个字节就被存储在内存的0x100, 0x101, 0x102和0x103位置上。

❷如何排列这些字节：排列表示一个对象的字节的通用规则：考虑一个w位的整数，其位表示为`[x(w-1), x(w-2), ..., x(1), x(0)]`，其中x(w-1)为最高有效位，x(0)最低。假设w是8的倍数，将这些位分组为字节，其中包含位`[x(w-1), x(w-2), ..., x(w-8)]`的是最高有效字节，而包含位`[x7, x6, ..., x0]`的是最低有效字节。机器可以选择最高有效字节在前，直到最低有效字节在最后的方式顺序存储对象，称为大端法；也可以选择反之令最低有效字节在前，最高有效字节在最后的方式顺序存储，称为小端法。例如：

![](file:///C:\Users\34382\AppData\Local\Temp\ksohtml24656\wps1.jpg) 

有时候字节顺序也会引发问题，例如：

①在使用不同排列方法的机器之间通过网络传输二进制数据时，接收程序会发现字里的字节变成了反序。为了避免这样的问题，网络应用程序的代码必须遵守已建立的关于字节顺序的规则，从而确保发送方机器把数据的内部表示转换为网络标准，然后接受方机器把网络标准表示的数据转换为自己的内部表示，这种转换会在后面学到。

②当阅读表示整数数据的字节序列时，字节顺序也很重要。这种情况通常发生在对机器级程序进行检查时，如果生成机器级指令的机器使用小端法存储字节，那么经常会将字节按照相反的顺序显示，这是因为书写字节序列的自然方式是最低位字节在左边，而最高位字节在右边（这正好和通常书写数字时最高有效位在左边，最低有效位在右边的方式相反）。

③当我们希望编写规避正常的类型系统的程序时，字节顺序也很重要。C语言中，我们可以使用强制类型转换或联合来允许一个数据类型引用另一个与其类型不同的对象，这种编码技巧在应用编程中并不被推荐，但却在系统级编程中尤为重要。

例如以下程序：

int a = 0x12345678;

char* p = (char*)&a;  // 将 int 类型的地址转换为 char* 类型的指针

printf("%02x\n", \*p);  // 打印 int 的第一个字节（在小端法架构下是78）

这个例子通过转换指针类型来访问整数内部的字节表示，%x表示以16进制形式输出，x前面的0则指示输出要补充0，2则是指定宽度（输出的最小字符），也就是规定输出必须两个两个字符地输出，不足两个则补0

上述类型转换(char*)告诉编译器，应该将&a这个指针看作指向一个字节序列的指针，而非指向原始数据类型对象。我们可以使用sizeof(T) 来确定存储一个类型为T的对象所使用的字节数，使用它有利于增强代码在不同类型机器上的可移植性。

如果我们在不同机器上运行这类程序，会发现字节都是相同的，只是顺序可能会不同，同时对指针输出其字节，会发现几乎各不相同，因为不同机器/操作系统配置使用不同的存储分配规则。

### 2.1.4 表示字符串

C语言中字符串被编码为以一个null(其值为0)字符结尾的字符数组，每个字符由某个标准编码来表示。最常见的是ASCII字符码，例如 "12"使用ASCII字符码表示就为 31 32 00 。

因为一个十进制数字num的ASCII码正好是0x3num，而终止字符的ASCII码始终是0x00，因此使用ASCII表示的文本数据在任何系统上都将得到相同的结果，比二进制数据具有更强的平台独立性。

### 2.1.5 表示代码

不同的机器类型使用不同的且不兼容的指令和编码方式，这就导致对于一个相同的进程，运行在不同的操作系统上时也会有不同的编码规则，因此二进制代码是不兼容的，二进制代码很少能在不同机器和操作系统组合之间进行移植。

计算机系统的一个基本概念就是：**从机器的角度，程序仅仅只是字节序列，机器除了可能有一些用来帮助调试的辅助表之外，没有关于原始源程序的任何信息（即程序经过指令和编码方式转变为字节序列后才传入机器，机器本身没有源程序的任何信息）。** 这在之后学习机器级编程时会更清晰地看到。

### 2.1.6 布尔代数简介

将逻辑值True和False编码为二进制值1和0，可以设计出一种代数以研究逻辑推理的基本原则，这就是布尔代数。最简单的布尔代数的定义就是在二元集合{0, 1}基础上的定义，其几种运算如下：![](file:///C:\Users\34382\AppData\Local\Temp\ksohtml24656\wps2.jpg)

其中符号^表示异或，在命题逻辑中使用⊕表示，对于P^Q，当P和Q中有且仅有一个为真时，P^Q才为真

将上述4个布尔运算扩展到位向量的运算，位向量就是固定长度为w，由0和1组成的串。位向量的运算定义成参数的每个对应元素之间的运算，设a和b分别是位向量\[a(w-1), a(w-2), ... , a0] 和 \[b(w-1), b(w-1), ... , b0] ，a&b的结果也为一个w位的位向量，每一位的值是a(i)&b(i) 的结果。其他三个运算也可以这样类似地定义。
> [!NOTE] 布尔代数的更深刻内容
> 布尔代数和整数算术运算有很多相似之处，例如满足&对|的分配律：写为 a & (b | c) = (a&b) | (a & c) ，不同之处是布尔运算 | 对 ＆ 也有分配律，写为 a I ( b &c) = (a |b) &(a |c ），而加法对乘法没有这样的分配律

位向量一个重要用途就是表示有限集合，例如算法竞赛中常用的位压缩优化。具体来说，**我们可以用位向量\[a(w-1), ... , a1, a0]编码任何子集 A ∈ { 0, 1, …, w-1}。当i∈A时，有相应的二进制位a(i)=1，否则为0。**
例如，位向量a=\[01101001]表示集合A={0, 3, 5, 6}
用位向量对集合进行编码的操作在实际应用中很常见，在后面会用于表示有效信号集合以屏蔽部分无用信号

> [!NOTE] 布尔环
> 当考虑长度为 w 的位向量上的＾ 、＆ 和 ～ 运算时，会得到一种不同的数学形式，我们称为布尔环,它与整数运算有许多相同之处。例如，和加法一样，^运算具有逆元：对任何位向量a来说，a^a的值为0，即a的逆元为它本身。且有(a^b)^a=b

### 2.1.7 C语言中的位级运算、逻辑运算与位运算
**C语言支持按位布尔运算**： I 就是 OR( 或），＆就是 AND( 与），～就是 NOT( 取 反），而＾就是 EXCLUSIVE-OR( 异或）。**这些运算能运用到任何“整型”的数据类型上**
例如：~0x41即~\[0100 0001] 结果为 \[1011 1110] 即0xBE

C 语言还提供了一组逻辑运算符 II 、&&和！，分别对应命题逻辑中的或、与、非，并且有短路运算符的性质，不赘述。

C语言提供向左或向右移动位模式的移位运算符：
对于一个位表示为 \[x(w-1), ... x0]的操作数 x, C 表达式 x<<k 会生成一个值，其位表示为 \[Xw-k - 1 , X w -k- 2 , …, X0 , 0, …, 0] 。也就是说，**x 向左移动 K 位，丢弃最高的 K 位，并在右端补 K 个 0**

而表达式x >> k右移有两种形式：**逻辑右移和算数右移**
**逻辑右移：对于一个位表示为$[x_{w-1}, ... , x0]$的操作数x，逻辑右移在左端补k个0： $[0, ..., 0, x_{w-1}, ..., x_{k}]$
算数右移：算数右移在左端补k个最高有效位的值，即结果为：\[x(w-1), ... ,x(w-1), ... x(w-1), ... ,x(k)]**
C标准并未明确区分两种右移，**对于有符号数，几乎所有编译器-机器组合都使用算数右移**（可能产生可移植性问题），而**无符号数的右移必须是逻辑右移**

看上去算术右移的做法有些奇怪，但是**算数右移对于有符号整数的运算至关重要**

## 2.2 整数表示

用位来编码整数有两种不同的方式 ：一种只能表示非负数，而另一种能够表示负数 、零和正数。
以下是即将介绍的术语及符号：
![[Pasted image 20240803193754.png]]
### 2.2.1 整型数据类型
**整型数据类型表示有限范围的整数**，每种类型用关键字来指定大小。C语言的整型数据类型如下：
![[Pasted image 20240803193956.png]]
![[Pasted image 20240803194219.png]]
**根据程序编译为32位还是64位，这些大小可能会有所不同，例如大小指示符long**，64位机器使用8个字节的表示，比4个字节的32位机器大很多

上图一个值得注意的特点是**取值范围并不对称：负数下限的绝对值比正数上限的绝对值大1，其原因与表示负数的方法有关

C语言还规定了每种数据类型**必须能够表示的最小的取值范围**，对于固定大小的数据类型来说该范围和所有机器上它们的范围相同
![[Pasted image 20240803195327.png]]

### 2.2.2 无符号数的编码
假设一个整数数据类型有w位，位向量写作$\vec{x}$，或\[$x_{w-1}$, $x_{w-2}$, ..., $x_0$ \] ，表示向量中的每一位
**把$\vec{x}$看作一个二进制表示的数，就获得了$\vec{x}$的无符号表示，在这个编码中，每一位$x_i$都取值为0或1，取值为1意味着数值$2^i$应该被加进十进制表示的总数里

**定义：无符号数编码函数$B2U_w$
对于向量$\vec{x}$ = \[$x_{w-1}$, $x_{w-2}$, ..., $x_0$ \],有：
					$B2U_w$ ($\vec{x}$) = $\sum_{i=0}^{w-1} {x_{i}2^i}$ 
该函数将一个长度为w的01串映射为非负整数。

不难发现，**w位01串所能表示的值的范围是：
最小值为\[000...0\]，即整数值0
最大值为\[111...1\]，即整数值$UMax_w$ = $\sum_{i=0}^{w-1} {x_{i}2^i}$ = $2^w$-1

**重要性质：无符号数编码具有唯一性，即函数$B2U_w$是一个双射
因此我们可以定义无符号数到二进制函数$U2B_w$为其反函数

### 2.2.3 补码编码
**最常见的有符号数的计算机表示方式就是补码编码，用函数$B2T_w$表示：**
在该定义中，我们将**字的最高有效位**解释为**负权**：**最高有效位作为符号位，具有大小为$-2^{w-1}$的权重**

**定义：补码编码函数$B2T_w$
对于向量$\vec{x}$ = \[$x_{w-1}$, $x_{w-2}$, ..., $x_0$ \],有：
					$B2T_w$=$\sum_{i=0}^{w-2}{x_{i}2^i}-x_{w-1}2^{w-1}$
相当于为最高有效位$x_{w-1}$赋予权重$-2^{w-1}$，该符号位为1时表示的数为负数，否则为非负数

我们来考虑**w位补码所能表示的值的范围：
最小值是\[100...0\]，即把负权位置1，其他正权位置0，其数值为：
				$TMin_w$=$-2^{w-1}$
最大值是\[011...1\]，即把负权位置0，正权位都置1，其数值为：
				$TMax_w$=$2^{w-1}-1$
可见最小值即负下界的绝对值永远比最大值大1

**$B2T_w$是一个从位向量到一个位于$TMin_w$到$TMax_w$之间的数的映射
补码编码也具有唯一性，函数$B2U_w$是一个双射，定义函数$U2B_w$为其反函数，即补码到二进制映射函数

补码编码的另一个性质是**对于相同数目的位，其最大的无符号数值刚好比补码的最大值的两倍大一点：
$UMax_w$=$2TMax_{w}+1$
而UMax与补码编码的-1具有相同的位表示：各位上的数值均为1；两编码中的数值为0的表示也都相同，即各位上均为0

C标准并未规定一定要用补码编码表示有符号整数，但几乎所有机器都是这么做的。**为了提升程序的可移植性，我们不应该假设任何可表示的数值范围，也不应该假设除了补码编码以外的特殊的有符号数表示方法**

> [!NOTE] C标准库头文件<limits.h>和<stdint.h>
> 头文件<limits.h>定义了一组常量来限制编译器运行的这台机器的不同整型数据类型的取值范围，如INT_MAX、INT_MIN和UINT_MAX就描述了int和unsigned_int的取值范围
> 
> 而头文件<stdint.h>定义了一组数据类型，声明方法类似于intN_t和uintN_t，N是具体位数，例如int32_t就是32位有符号整数变量，这允许我们无歧义地生命一个范围固定的数据类型，这些数据类型还对应了一组宏，用于确保在各种编译方式下都能生成正确的格式字符串

### 2.2.Extra 其他特殊的有符号数表示方法
**1. 反码编码$B2O_w$：除了最高有效位的权重是$-(2^{w-1}-1)$外，其他都与补码编码相同，即
$$B2O_w(\vec{x})=\sum_{i=0}^{w-2}{x_{i}2^i}-x_{w-1}({2^{w-1}-1})$$

**2.原码编码$B2S_w$：最高有效位依然是符号位，它决定剩下的位应该取负权还是正权，即
$$B2S_w(\vec{x})=(-1)^{x_{w-1}}*(\sum_{i=0}^{w-2}{x_{i}2^i})$$

**这两种表示方法的一个奇怪特点是：对于0有两种不同表示形式，在反码和原码中，\[000...0]被称为+0，在反码中\[111...1]也是0，称为-0；原码中则是\[100...0]被称为-0**
在浮点数编码中会用到原码编码，而反码编码比较古早，现代机器基本都用补码编码

> [!NOTE] 使用程序理解补码编码
>![[Pasted image 20240803212918.png]]

### 2.2.4 有符号数与无符号数之间的转化
C语言允许不同数字数据类型之间的强制类型转换，那么当有符号数与无符号数之间进行强制类型转换时会发生什么？**对大多数C语言的实现来说，这个问题都是从位级角度来看的，而非数学角度**
考虑下面的代码
```
short int v = -12345;
unsigned short uv = (unsigned short) v;
cout << v << " and " << uv;
```
在补码机器上，其输出为
```
-12345 and 53191
```
我们看到，**强制类型转换的结果保持位值不变，只是改变了解释这些位的方式**，具体来说，-12345的补码表示与53191的无符号表示完全一样，**将short强制类型转换为unsigned short的过程中，位表示保持不变，数值发生改变**
**同理，对于其他所有的有符号数与无符号数的类型转换，其底层的位表示都是完全一样的，只是解释方法不同**。我们可以更数学地描述这个结论：

**定义$U2B_w$和$T2B_w$，它们分别将数值映射为无符号数和补码形式的位表示，即给出对应范围的数值，得到相应编码下的位表示
现在定义$T2U_w(x)=B2U_w(T2B_w(x))$，它在两个编码法则对应的范围之间进行映射

**性质：我们可以推出无符号数与补码的数值之间的关系，具体如下：
$$|x|+T2U_w(x)=2^w$$
例如，$T2U_{16}(-12345) = 53191$，而12345+53191=65536=$2^{16}$

通过以上例子，我们可以更一般地写出函数$T2U_w$的定义：
**定义：对满足$TMin_w\leq x\leq TMax_w$的x有：
$$ T2U_w(x)=\begin{cases}
x+2^w,\quad x<0\\
x,\quad x\geq 0
\end{cases}
$$

**推论：补码转换为无符号数
$$B2U_w(T2B_w(x))=T2U_w(x)=x+x_{w-1}2^w$$
这是通过计算$B2U_w(\vec{x})$与$B2T_w(\vec{x})$之差，将从0到w-2的位权抵消，只剩下$x_{w-1}2^w$，然后整理得到的。**($x_{w-1}$是第w位即最高有效位，x的位从0开始数)

简单来看，从补码转无符号数，**实际上就是把最高有效位的权重从$-2^{w-1}$变为了$2^{w-1}$，值增加了$2^w$**，因此需要在原来的基础上加$x_{w-1}2^w$，$x_{w-1}$是0的时候，即正数时两者没有区别。

**定义：无符号数转换为补码
对满足$0\leq u\leq UMax_w$的u有：
$$
U2T_w(u)=\begin {cases}
u,\quad u\leq TMax_w\\
u-2^w,\quad u>TMax_w
\end {cases}
$$
推论：
$$U2T_w(u)=-u_{w-1}2^w+u$$
### 2.2.5 C语言中的有符号数与无符号数
**C语言中，大多数数字都被默认为是有符号的**，例如当声明一个常量如12345或0x1A2B时，该常量被默认为有符号数；**若希望创建一个无符号常量，则必须加上后缀字符'u'或'U'**，例如12345U
**如前所述，尽管C标准并未精确规定，但在进行有符号数与无符号数之间的类型转换时，大多数系统遵循的原则是保持底层的位模式不变，即使用函数$T2U_w$

一个值得注意的类型转换发生在使用printf格式化输出时，**%d代表以有符号十进制格式输出数字，而%u是无符号十进制格式，%x是十六进制格式**。因此**使用不同的格式化方式输出一个数据类型的数据时也会根据以上规则进行转换后输出**

C语言中，当我们执行一个运算时，**如果一个运算数有符号而另一个数无符号**，那么**C语言会将有符号参数隐式转换为无符号数，并且假设两个数都非负来执行这个运算**，这对于关系运算符来说会产生非直观的结果
```
表达式  -1 < 0U 的结果是0（非）,因为-1先被隐式转换为大于0的无符号数T2U(-1)=2^32-1 [假设int为32位补码]
```

### 2.2.6 扩展一个数字的位表示
另一个常见的运算是**在不同字长的整数之间进行类型转换，要求保持数值不变**。
（从较大数据类型转换至较小数据类型不可能保持数值不变，因此这里讨论的是较小数据类型到较大的数据类型）
一个常见的**无符号数扩展方式**是在表示的开头添0，称为零扩展

**定义：无符号数的零扩展
定义宽度为w的位向量$\vec{u}=[u_{w-1}, u_{w-2}, ..., u_0]$和宽度为$w^{'}$的位向量$\vec{u}^{'}=[0, ..., 0, u_{w-1}, u_{w-2}, ..., u_0]$，其中$w<w^{'}$，则有：
$$
B2U_w(\vec{u})=B2U_{w^{'}}(\vec{u}^{'})
$$
即零扩展后的位模式的无符号编码相同

而如果希望**扩展补码编码的数字**，则需要用到以下符号扩展，在表示的开头添上相同的最高有效位$x_{w-1}$

**定义：补码数的符号扩展
定义宽度为w的位向量$\vec{x}=[x_{w-1}, x_{w-2}, ..., x_0]$和宽度为$w^{'}$的位向量$\vec{x}^{'}=[x_{w-1}, ..., x_{w-1}, x_{w-1}, x_{w-2}, ..., x_0]$，其中$w^{'}>w$，则有：
$$ B2T_w(\vec{x})=B2T_{w^{'}}(\vec{x^{'}})$$
即经过符号扩展后的位模式的补码编码相同

> [!NOTE] 符号扩展后补码编码相同的证明
> ![[Pasted image 20240804200234.png]]


通过以上两种扩展方式，我们实现了无符号数与补码数的字长扩展
另一个要考虑的问题是**不同字长与有无符号的数据转换的相对顺序可能会影响程序的行为**，例如：
```
short sx = -12345;
unsigned uy = sx;
printf("uy = %u:  ", uy);
show_bytes((byte_pointer) &uy, sizeof(unsigned));
```
该程序在一台大端法机器上的输出是：
```
uy = 4294954951:  ff ff cf c7
```
在show_bytes的输出中，先是ff ff，即在底层位模式前端零扩展补了0000 0000，然后保持该位模式不变，进行有符号数到无符号数的转换
不难发现，**在把short转换为unsigned的时候，先改变了字长（底层位模式），然后进行有符号数到无符号数的转换。**
```
即强制类型转换(unsigned)sx等价于(unsigned)(int)sx，先把short类型的sx扩展为int，再变为无符号数
```
**事实上，C语言标准就要求了这样先进行字长转换，再进行有无符号转换的规则**

### 2.2.7 截断数字
当我们**从一个较大的数据类型转换为一个较小的数据类型时**，我们说**将字长较大的数据类型截断为了字长较小的数据类型**，例如
```
int x = 53191;  short sx = (short)x;  //此时sx的值为-12345
int y = sx;  //此时y的值为-12345
```
这里把32位的int截断为16位的short，我们发现这个16位的位模式就是-12345的补码表示，而把有符号数sx扩展为更大的int值y时，进行了符号扩展，扩展最高有效位，依然得到-12345

**原理1：对无符号数的截断，当将一个w位的数截断为一个k位的数时，我们会丢弃高位的w-k个位，得到所求位向量：
令$\vec{x}=[x_{w-1}, x_{w-2}, ..., x_0]$，设$\vec{x^{'}}$为将其截断至k位后的结果：$\vec{x^{'}}=[x_{k-1}, x_{k-2}, ..., x_0]$。设$x=B2U_w(\vec{x})，x^{'}=B2U_k(\vec{x^{'}})$，则有：
$$ x^{'}=x\quad mod \quad  2^k $$

> [!NOTE] 证明如下
> ![[Pasted image 20240804203700.png]]
> 对于任何$i \ge k$，都有$2^i\quad mod \quad 2^k =0$，因此可得


**原理2：对补码数值的截断，与无符号数截断类似，丢弃高位的w-k个位，然后需要把剩下的最高位视为符号位
令$\vec{x}=[x_{w-1}, x_{w-2}, ..., x_0]$，设$\vec{x^{'}}$是将其截断至k位后的结果：$\vec{x^{'}}=[x_{k-1}, x_{k-2}, ..., x_0]$，设$x=B2U_w(\vec{x})，x^{'}=B2U_k(\vec{x^{'}})$，则有：
$$ x^{'}=U2T_k(x\quad mod \quad 2^k)$$
即：先把$\vec{x}$视为无符号数，使用对无符号数的截断后，再将得到的无符号数转换为补码编码的数**。
最后这步的效果就是把剩余最高有效位$x_{k-1}$的权重由$2^{k-1}$变为$-2^{k-1}$。

## 2.3 整数运算
**计算机运算具有有限性**，这也是有时两个正数相加会得到负数，或是x<y的结果与x-y<0的结果不同的原因。
### 2.3.1 无符号加法
我们知道，一个w位无符号数字最大值是$2^w-1$，这就意味着两个无符号整数相加的结果可能会膨胀到非常大的字长，相乘结果同理。**因此，一般的编程语言都将这些运算固定至一定精度**

**定义：为满足$0\leq x,y< 2^w$的整数x,y定义运算${+}_{w}^{u}$，代表截断至w位的无符号数(u)加法，它把结果视为一个无符号数：
对满足$0\leq x,y < 2^w$的x,y有：
$$ x{+}_{w}^{u}y=\begin {cases}
x+y,\quad x+y<2^w\quad 正常 \\
x+y-2^w,\quad 2^w\leq x+y<2^{w+1}\quad 溢出
\end {cases} $$**
截断至w位可以理解为一种形式的模运算：**溢出时，在不截断的情况下的第w+1位会等于1，截断至w位就意味着丢弃第w+1位，这会导致数值上减少了一个$2^w$；而不溢出的情况下第w+1位等于0，没有影响


> [!NOTE] 溢出
> 一个算数运算溢出，是指完整的整数结果不能放到数据类型的字长限制中去，它不会被报错，但可以被检测出来

**原理：检测无符号数加法是否发生溢出
对在范围$0\leq x,y\leq UMax_w$中的x和y，令$s=x{+}^{u}_{w}y$，则有：
当且仅当$s<x（或等价地 s<y）$时，有加法发生了溢出**

这是显然的，因为溢出时$s=x+y-2^W$,小于单独的x或y

**模数加法形成了阿贝尔群**，即它是可交换的，而且是可结合的，同时具有一个单位元0，每个元素有一个加法逆元使得逆元与其的加法结果为单位元0

**原理：无符号数求反
对满足$0\leq x<2^w$的任意x，其w位的无符号逆元${-}^{u}_{w}x$可由下式求得：
$$ {-}^{u}_{w}x=\begin {cases}
x,\quad x=0\\
2^w - x,\quad x>0
\end{cases}  $$**
对于x>0的情况，普通加法：$x+({-}^{u}_{w}x)=x+2^w-x=2^w$，而根据模数加法的法则，我们需要对结果减去$2^w$，最终得到0。

### 2.3.2 补码加法
对于补码编码，我们必须确定当结果太大（为正）或太小（为负）时的行为。
给定在范围$-2^{w-1}\leq x,y\leq 2^{w-1}-1$之内的整数值x和y，其和范围为$-2^w\leq x+y\leq 2^w-2$，**特别大或特别小的时候，我们需要w+1位才能准确表示**。
和之前一样，我们需要将表示**截断至w位**来避免数据扩张。这个结果不像模数加法一样符合数学直觉。
**定义$x{+}^{t}_{w}y$为x+y截断至w位的结果，并且将该结果视为补码数

**原理：补码加法
对满足$-2^{w-1}\leq x,y\leq 2^{w-1}-1$之内的的整数x和y，有：
$$ x{+}^{t}_{w}y=\begin {cases}
x+y-2^{w},\quad 2^{w-1}\leq x+y\quad \quad 正溢出\\
x+y,\quad -2^{w-1}\leq x+y<2^{w-1}\quad \quad 正常\\
x+y+2^{w},\quad x+y<-2^{w-1}\quad \quad 负溢出
\end{cases}  $$
正溢出即x+y超过$TMax_w=2^{w-1}-1$了，而负溢出则是超过$TMin_w=-2^{w-1}$**
可见**两个数的w位补码之和与无符号数之和具有完全相同的位级表示**，实际上，**大多数计算机使用同样的机器指令来执行无符号和有符号加法**

**推论：由于补码加法与无符号加法具有同样的位级表示，补码加法可以用如下步骤表示：
$$ x{+}^t_{w}y=U2T_w(T2U_w(x){+}^u_{w}T2U_w(y))$$
即：先把补码数x和y转换为无符号数，执行无符号加法后，将结果转换回补码数

利用$T2U_w$函数的最高有效位表示，上式可化为：
$$ \begin {align*}
x{+}^t_{w}y &= U2T_w[(x_{w-1}2^w+x+y+y_{w-1}2^w) \mod 2^w] \\
&= U2T_w[(x+y)\mod 2^w]
\end{align*}
$$
（$x_{w-1}2^w与y_{w-1}2^w \mod 2^w$的值均为0）
根据分类讨论，我们可以推出补码加法的性质，并且得到检测补码加法是否发生溢出的原理：

**原理：检测补码加法是否发生溢出
对满足$TMin_w\leq x,y\leq TMax_w$的x和y，令$s=x{+}_w^{t}y$，则有：
$$ 当且仅当 \quad \begin{align*}
&x>0,y>0\quad 而s\leq 0；\\
&x<0,y<0\quad 而s\geq 0时，补码加法发生溢出
\end{align*} $$**
（第一种情况即正溢出，第二种情况即负溢出）

### 2.3.3 补码的非
**补码加法也会形成一个阿贝尔群。
在$TMin_w\leq x\leq TMax_w$中的每个数字x，都具有${+}^t_{w}$下的加法逆元${-}^t_{w}x$，由下式
给出：
$$ {-}^{t}_{w}x=\begin {cases}
TMin_w,\quad x=TMin_w\\
-x,\quad x>TMin_w
\end{cases} $$
$（TMin_w + TMin_w = -2^w，在补码加法下的值为0）$

**计算一个位级表示的值的补码的非的方法
1.对每一位取反，再对结果加1。** 例如：

* $[\vec{x}] ：[0101]\quad 十进制值为5$
* $[\sim \vec{x}] :[1010]\quad 十进制值为-6$
* $[\sim \vec{x}+1] :[1011]\quad 十进制值为-5$
（取反也称求补）

**2.将位向量分为两部分，假设k是最靠右的'1'的位置，则x可写成：
$$ \vec{x}=[x_{w-1}, x_{w-2},...,x_{k+1},1, 0,...,0]$$
求非则是对左边大于k的部分的位依次求反：
$$ {-}^t_{w}\vec{x}=[\tilde{\quad}x_{w-1},\tilde{\quad}x_{w-2},...,\tilde{\quad}x_{k+1},1,0,...,0] $$** （**注意位置k上的1不求反**）例如：
* $\vec{x}：[1100]\quad 十进制值为-4$
* $-\vec{x}：[0100] \quad 十进制值为4$

### 2.3.4 无符号乘法
范围在$0\leq x,y\leq 2^w-1$的数x,y的最大值为$(2^w-1)^2=2^{2w}-2^{w-1}+1$，需要2w位才能准确地表示。如前所述，C语言中依然需要将乘积截断至w位

**原理：无符号数乘法${*}_{w}^{u}$
对满足$0\leq x,y\leq 2^w-1=UMax_w$的整数x,y有：
$$ x{*}_{w}^{u}y=(x* y)\mod 2^w $$
这是因为将一个无符号数模$2^w$等价于截断至w位

### 2.3.5 补码乘法
范围在$-2^{w-1}\leq x,y\leq 2^{w-1}-1$的整数x,y的乘积取值范围在$-2^{w-1}*(2^{w-1}-1)到(-2^{w-1})*(-2^{w-1})之间$
**将一个补码数乘积截断至w位，等价于先计算无符号数形式的x\*y mod $2^w$，再将其转换为补码数

**原理：补码乘法${*}^{t}_{w}$
对满足$TMin_w\leq x,y\leq TMax_w$的x和y有：
$$ x{*}^{t}_{w}y=U2T_w((x*y)\mod 2^w)$$

**和加法类似，无符号与补码乘法运算的位级表示都是一样的**
**原理：无符号和补码乘法的位级等价性
给定长度为w的位向量$\vec{x}和\vec{y}$，令整数
$$ \begin{align*}
&x=B2T_w(\vec{x}),y=B2T_w(\vec{y})\\
&x^{'}=B2U_w(\vec{x}),y^{'}=B2U_w(\vec{y})
\end{align*} $$
则有 
$$ T2B_w(x{*}^{t}_{w}y)=U2B_w(x{*}^{u}_{w}y) $$
这是因为：$x^{'}=x+x_{w-1}2^w,y^{'}=y+y_{w-1}2^w$
带入上式，由于取模运算符，所有带有权重$2^w$和$2^{2w}$的项均为0，进而可证上式成立。

### 2.3.6 乘以常数
在过去的大多数机器上，整数乘法的时钟周期相当高，而其他整数运算却很低。因此，编译器采用了**用移位和加法组合运算来代替乘以常数因子的运算**
先考虑**乘以2的幂的情况**，再进行推广

**原理：乘以2的幂
设x为位模式$[x_{w-1},x_{w-2},...,x_0]$表示的无符号整数，那么：
$$ \begin{align*}
&对于任何k\geq 0,\\
&x2^k的w+k位的无符号表示为：[x_{w-1},x_{w-2},\cdots,x_0,\mathop {\underbrace{0,\cdots,0}}\limits_{k个0}]\\
\end{align*} $$** 例如，位数w=4，k=2时，求$11*2^2$的无符号表示，就可以将11表示为\[1011]，$11*2^2$即为$[1011\underbrace{00}\limits_{k=2个0}$]，转换为十进制数即为44
这个性质可以通过移位的性质简单推导而来，但是要注意：
**当字长固定为w时，左移k位会导致高k位部分被丢弃，得到$[x_{w-k-1},x_{w-k-2},\cdots,\underbrace{0,\cdots,0}\limits_{k个0}]$
这和执行固定字长的无符号乘法是一致的，综上两种操作是等价的.
对于无符号数和补码数的乘法，以上结论都是成立的

**原理：利用加法和减法拆分数字，利用乘法结合律就可以将数乘运算变为加减法和移位的结合**
例如：
$$ \begin{align*}
&由于14=2^3+2^2+2^1，所以有\\
&x*14=x*(2^3+2^2+2^1)=(x<<3)+(x<<2)+(x<<1); \\
&或者由于14=2^4-2^2，所以有\\
&x*14=(x<<4)-(x<<1)\\
\end {align*}$$
**数字的拆分也很好获得，通过十进制转二进制，对2多次取模即可得到

### 2.3.7 除以2的幂
在过去的机器上，整数除法更是重量级，需要30+个时钟周期来完成
**除以2的幂也可以使用移位运算来实现，使用右移运算。**
无符号数与补码数区别在于**无符号数使用逻辑右移运算，而补码数使用算术右移运算**

**原理A：除以2的幂的无符号除法
设变量x和k具有无符号数值*x*和*k*，且0<*k*<w，则
$$ C语言表达式x>>k的结果为\lfloor x/2^k\rfloor （向下取整）$$
由于x和k是无符号数值，这里>>实际上是逻辑右移

**推导：除以2的幂的无符号除法
设x为由位模式$[x_{w-1},x_{w-2},\cdots,x_0]$表示的无符号整数，k的取值范围为$0\leq k<w$，设$x^{'}$为w-k位位模式$[x_{w-1},x_{w-2},\cdots,x_k]$表示的无符号数，而$x^{''}$为k位位模式$[x_{k-1},x_{k-2},\cdots,x_0]$表示的无符号数。
$$ \begin{align*}
&显然x=2^{k}x^{'}+x^{''}，且0\leq x^{''}<2^k\\
&因此可得：\lfloor x/2^k\rfloor =x^{'} 
\end{align*} $$
于是无符号除法就是对$[x_{w-1},x_{w-2},\cdots,x_0]$逻辑右移k位得到的位向量
$$ [\underbrace{0,\cdots,0}\limits_{k个0},x_{w-1},x_{w-2},\cdots,x_0]$$
的十进制值$x^{'}$。

对于除以2的幂的补码除法，情况会稍微复杂一些，为了保证最高有效位的不变，需要执行算数右移

**原理B：除以2的幂的补码除法
设C语言变量x和k分布具有补码值*x*和无符号值*k*，且$0\leq k<w$，则
$$ 当执行算数右移x>>k时，表达式的数值为\lfloor x/2^k\rfloor（向下取整）$$**
**推导：除以2的幂的补码除法（向下取整）
设x为位模式$[x_{w-1},x_{w-2},\cdots,x_0]$表示的补码整数，$0\leq k<w$，设$x^{'}$为w-k位$[x_{w-1},x_{w-2},\cdots,x_k]$表示的补码数，$x^{''}$为低k位$[x_{k-1},\cdots,x_0]$表示的无符号数，则有$x=2^kx^{'}+x^{''}$，由于$0\leq x^{''}<2^k$，故$x^{'}$就是$\lfloor x/2^k\rfloor$。而
$$ \begin{align*} 
&对\vec{x}算数右移k位所得位向量[\underbrace{x_{w-1},\cdots,x_{w-1}}\limits_{k个},x_{w-1},x_{w-2},\cdots,x_k]\\
&恰好就是将x^{'}扩展至w位所得的位表示\\
&即该向量就是\lfloor x/2^k\rfloor 的补码表示
\end {align*} $$

**偏置技术：除以2的补码除法（向上取整）
在进行移位操作之前，我们可以把原值进行一个==偏置==，该偏置用于将除法调整至向上取整
C 变量 x 和 k 分别有补码值 x 和无符号数值 k，$0\leq k<w$，则
$$ \begin{align*}
&当执行算数移位时，\\
&C语言表达式(x+(1<<k)-1)>>k的数值为\lceil x/2^k\rceil (向上取整)
\end{align*}$$**
一个简单的证明是：利用$\lceil x/y\rceil=\lfloor (x+y-1)/y\rfloor$
即**为x添加一个值为y-1的偏置量，就可以把向上取整的运算化为向下取整的运算了**，因此上式(1<<k)-1就是这样的偏置量
对于最高位为1的负数，

值得注意的是：与数乘不同，**除以2的幂不能推广到任意常数K**

---

## 2.4 浮点数
**浮点表示对形如$V=x*2^y$的有理数进行编码，用于执行==涉及非常大的数字(|V|>>0)、非常接近于0的数字以及作为实数运算近似值的运算==**
==IEEE浮点==标准是被广泛使用的一个标准。本节将介绍它的表示方法与数学属性等原则。

### 2.4.1 二进制小数
考虑含有小数值的二进制数字应该如何表示。
在十进制表示法中，小数采用如下定义：
$$ d_{m}d_{m-1}\cdots d_{1}d_{0}.d_{-1}d_{-2}\cdots d_{-n}$$
每个十进制数$d_i$取值范围为0~9，而数值d的定义则是
$$ d=\sum_{i=-n}^{m}10^i*d_I$$
数字权的定义与小数点有关，左侧是10的正幂，右侧则为负幂。

类似地，**考虑形如
$$ b_mb_{m-1}\cdots b_1b_0.b_{-1}b_{-2}\cdots b_{-n}$$
的表示法，$b_i$为二进制数字（位），取值为0或1，那么就可以把数值b定义为
$$ b=\sum_{i=-n}^{m}2^i*b_i$$
小数点决定2的正负幂的分界，小数点向左移动一位相当于该数除2，向右移动一位则相当于乘2**，例如$101.11_2$表示的值为$5\frac{3}{4}$，$10.111_2$则表示$2\frac{7}{8}$。
我们用形如$0.11\cdots1_2$的值代表刚好小于1的数，一般写作$1.0-\epsilon$。

**在编码长度有限的条件下**，和十进制表示法不能准确表示形如$\frac{1}{3}$这样的小数类似，**小数的二进制表示法只能准确表示那些能写为$x*2^y$的数，其他数只能被近似表示，提高二进制编码的长度可以提高表示的精度。**

### 2.4.2 IEEE浮点表示
十进制中，面对很大的数，我们使用形如$5*10^{100}$的科学计数法形式表示，类似地，我们希望**通过给定的x和y的值，来表示形如$x*2^y$的数

**IEEE浮点标准用$V=(-1)^{s}*M*2^E$的形式来表示一个数：
* 符号：s决定这个数的符号，取值0或1代表数是正数或负数，s=0时的符号位解释作为特殊情况处理
* 尾数：M是一个二进制小数，其范围为1~$2-\epsilon$，或0~$1-\epsilon$
* 阶码：E的作用是对浮点数加权，这个权重是2的E次幂（E可以为负）
**依此，将浮点数的位表示划分为三个字段：
* **一个单独的符号位s在最高位，它直接编码上式中的s值
* **一段k位的阶码字段$exp=e_{k-1}\cdots e_1e_0$，用于编码阶码E
* **一段n位的小数字段$frac=f_{n-1}\cdots f_1f_0$，用于编码尾数M，但编码出来的值也依赖于阶码字段的值是否等于0

**将浮点数的位表示的三个字段装进字中有两种最常见的格式：
* **32位表示的==单精度浮点格式(float)==：s、exp和frac字段分别占1位、k=8位和n=23位
* **64位表示的==双精度浮点格式(double)==：s、exp和frac字段分别占1位、k=11位和n=52位

给定位表示，**根据exp的值，被编码的值可以分成三种不同情况

**情况1：规格化的值（规格化：表示为二进制小数的科学计数法形式）
这种情况下，exp的位既不全为0，也不全为1(单精度8位下值为255，双精度11位下值为2047)**，是最普遍的情况。
此时，
* **阶码字段exp被解释为以==偏置==形式表示的==有符号整数==**。
也就是说，**阶码的值为$E=e-Bias$，其中e是位表示为$e_{k-1}e_{k-2}\cdots e_1e_0$的==无符号数==，而$Bias=2^{k-1}-1$，(k就是exp字段的位数)**
由此产生的$2^E$范围为-126~+127（单精度），-1022~+1023（双精度）
引入Bias的作用是**将无符号整数形式的阶码e转换为有符号整数的阶码E**，e的取值在0~$2^k-1$之间，减去Bias后，取值范围为$1-2^{k-1}$~$2^{k-1}$，

* **小数字段frac被解释为描述小数值f，其中$0\leq f<1$，f的二进制表示为$0.f_{n-1}f_{n-2}\cdots f_1f_0$，即二进制小数点在最高有效位$f_{n-1}$的左边。
在IEEE标准中，存储实际尾数时，==并没有存储尾数的最高有效位==，即符号位s，而是假定它总是1**
这是因为**我们总是可以通过==调整阶码E==，使得二进制小数表示为 $num*2^E$的形式，其中num为小数部分，它==以1为开头==，例如$1.110101_2$**（二进制小数的科学计数法）
例如：
```
对于11000000000000000000000，我们看到的是23位二进制表示法，但实际上，它开头的1被省略了，整个位表示的是1.11_2 
```
这么做使我们节省了存储最高有效位的空间，有更多的位能用来存储小数部分，提高了精度

**情况2：非规格化的值**
这种情况下，**exp部分的位全部为0**，此时：
阶码值==**E=1-Bias**==，而尾数的值为==**M=f==（==不包含隐含的开头的1==）**
（该定义考虑到随后非规格化值与规格化值之间的转换）

非规格化值的用途有：
**1. 它们提供了一种表示数值0的方法：使用规格化数时，由于M包含了隐含的1，$M\geq 1$，因此无法表示0。**
事实上，浮点表示中的0有两种情况：+0.0是符号位为0，阶码字段与小数位也都是0的值；-0.0则是符号位为1，阶码字段与小数位都为0。
**2. 非规格化数也用于表示那些非常接近于0.0的数，它们提供了一种称为==逐渐溢出==的属性，此时不再保证最高有效位是1，而是直接存储实际的小数值

**情况3：特殊值**
一种情况下，**阶码全部为1，小数值各位均为0**。该情况又分为两种子情况：**当s=0时，表示$+\infty$；当s=1时，表示$-\infty$。** 
还有一种情况，**阶码全部为1，而小数值各位并非全部为0，此时结果值称为==NaN==（不是一个数）。当运算的结果不是实数或无穷时，就会返回NaN，或用于表示未初始化数据时也会用到。

![[Pasted image 20240806202932.png]]

### 2.4.3 数字示例
不妨看到下面的数字示例：
![[Pasted image 20240806201530.png]]
此处浮点位数为6，图中显示了除了NaN外六位浮点数可以表示的所有值
我们可以看到，**可表示的数并不是均匀分布的——越靠近原点，这些数越稠密**。
再看下面的表格：
![[Pasted image 20240806202518.png]]
此处的分位是1-4-3，$Bias=2^{4-1}-1=7$
注意最大的非规格化数与最小的规格化数的转变：最大非规格化数为$\frac {7}{512}$，最小规格化为$\frac{8}{512}$，转变十分平滑，**这是因为我们将非规格化数的E定义为1-Bias，使得我们补偿了非规格化数尾数所不含有的隐含的最高有效位的1**
增大阶码后，我们得到了更大的规格化值，最大的规格化值的阶码$E=[1110]_2-2^3+1=7$，$f=1*2^{-1}+1*2^{-2}+1*2^{-3}=\frac {7}{8}$，得到V=240.0，所以超出240.0的值均溢出为$+\infty$.

观察可以发现，**如果我们将上图所示的浮点数的值的位表示视为无符号数，它们从上到下仍然是升序排列的**，和浮点数的序列完全一样。
这就是IEEE格式的一个设计目的：**它希望浮点数也能够使用和整数相同的排序函数来进行排序**。不过处理负数时由于它们有开头的1，且是降序排列的，需要进行一些处理，这会在后面介绍

下面是一些重要的单精度与双精度浮点数的值
![[Pasted image 20240807155632.png]]

> [!NOTE] 练习整数值转换为浮点数
> 以下原文可以作为示例：
> ![[Pasted image 20240807155930.png]]


### 2.4.4 舍入
表示方法限制了浮点数的范围与精度，所以**浮点运算只能近似地表示实数运算**。
对于值x，**我们希望能够找到最接近的可以用期望的浮点形式表示出来的匹配值$x^{'}$**，这就是==**舍入**==。
舍入的关键问题在于方向，例如值1.50应该向1还是2舍入？IEEE浮点格式定义了四种不同的舍入方式：**向偶数舍入、向0舍入、向上舍入、向下舍入**
* **向偶数舍入是向与该数之差的绝对值最小的数舍入，如果有两个数达到相同的最小绝对值，那么就向最低有效位是偶数的数舍入**（将数字向上或者向下舍入，使得结果的 最低有效数字是偶数）
* **向零舍入即向原点方向舍入，即数的绝对值向下取整的方向
* **向下舍入和向上舍入即向下取整与向上取整**
![[Pasted image 20240807161849.png]]

向偶数舍入的一个优势在于：**减少了一味地向上或向下舍入所累积的统计偏差**，因为它一半时间在向上舍入，另一半时间在向下舍入，而一直保持一种舍入方式会使舍入后的一组数的平均值偏高或偏低
**向偶数舍入还可以用于：
* **舍入到小数，例如可以将十进制数舍入到最接近的百分位：1.234999与1.235001都舍入为1.23。而1.2350000和1.2450000都舍入为1.24
* **二进制小数的舍入：我们把最低有效位值为0的二进制小数认为是偶数，值1认为是奇数。而二进制小数中，根据定义，$0.5_{10}=0.1_2$，$0.05_{10}=0.01_2，\cdots以此类推$，因此==只有当要舍入的位置为最靠近右边的值为1的位置的*前一位置*时，才需要向偶数舍入==
  即，只有数的位模式形如$XX\cdots X.YY\cdots Y100\cdots$，==最右边的Y是要舍入的位置==，X和Y表示任意数值的时候，该位模式的值才是在两个数正中间，需要进行向偶数舍入。**
  例如：对于$10.00011_2$，其位模式与上面所说的位模式不同，这代表靠近它的两个数一定有一个数与其之差最小；对于$10.00110_2$，舍入到==小数点后第二位==时，也不符合上述位要求，可以找到一个小数点后二位的二进制小数使得差的绝对值最小，不必向偶数舍入；$10.11100_2$舍入到小数点后第二位，此时满足要求，需要向偶数舍入
  
  而向偶数舍入的方法很简单：**找到恰大于或小于该数的，要舍入的位置上的值为0的数即可**，例如对于$10.11100_2$舍入到小数点后第二位，有$10.11000_2$和$11.00000_2$这两个数到它的距离相同，都为$0.0001_2$，此时根据偶数定义，应该选择舍入到$11.00_2$而非$10.11_2$
  我们可以发现，这种值的特性是：**假设最右边的1在小数点后第k位上，那么==恰大于或小于该数==的两个==到该数距离相等==的数，到该数的距离为$0.\underbrace{00\cdots 01_2}\limits_{k位}$，
  然后据此找到两个数里是偶数的那个即可

### 2.4.5 浮点运算

IEEE标准制定了一个规则来确定算术运算的结果：**把浮点数x和y先视为实数，运算$\bigodot$定义在实数上，计算产生的结果$Round(x\bigodot y)$是实数运算的精确结果进行舍入后的结果**。
实际实现中，设计者使用了一些小技巧来避免执行这种精确的运算，因为计算只需要精确到保证舍入结果正确就好了
对于一些特殊情况，IEEE也定义了合理的规则，例如定义1/-0产生$-\infty$，而1/+0产生$+\infty$。
IEEE标准所指定的浮点运算行为方法的一个优势在于**它可以独立于任何具体的硬件或软件实现，所以这里我们可以只看它的抽象数学属性，而不研究具体实际实现。**

我们知道实数的加法形成了阿贝尔群，但是在浮点运算中，我们必须考虑**舍入对加法的影响**
**定义$x{+}^ty$为$Round(x+y)$，即x+y的实数值经过舍入后得到的值，下面介绍它的性质：
* **运算${+}^t$是==可交换==的，即$x{+}^ty=y{+}^tx$
* **运算${+}^t$是==不可结合==的，因为在舍入过程中值会丢失**，例如(3.14+1e10)-1e10会丢失值3.14，而3.14+(1e10-1e10)则会保留3.14
* **大多数值在浮点加法${+}^t$下是==有逆元的==，$x{+}^t(-x)=0$，==除了NaN==，因为对于任意x都有$NaN{+}^tx=NaN$
* **浮点加法满足单调性属性：如果$a\geq b$，那么对于任何a，b以及除NaN外的x，都有$x+a\geq x+b$

最重要的且最容易犯错的就是**浮点加法不具有结合性**这个性质了
另一个重要的则是**浮点乘法$x{*}^ty=Round(x*y)$，它的性质有：
* **浮点乘法在乘法中是==封闭的==（尽管可能产生无穷大或NaN)
* **浮点乘法是==可交换的==，乘法单位元为1.0
* **浮点乘法==不具有分配性==，依然是因为舍入会导致丢失精度**，例如单浮点精度的情况下1e20*(1e20-1e20)结果是0，而1e20*1e20-1e20*1e20结果是NaN
* **浮点乘法满足单调性：对于非NaN的a，b和c，有：
  $$ \begin{align*}
  &a\geq b且c\geq 0 \Rightarrow a{*}^tc \geq b{*}^tc\\
  &a\geq b且c\leq 0 \Rightarrow a{*}^tc \leq b{*}^tc
  \end{align*} $$
  且我们还可以保证：
  $$ 只要a\neq NaN，就有a{*}^ta\geq 0$$
  
### 2.4.6 C语言中的浮点数

C语言提供的两种浮点数版本float和double在支持IEEE浮点格式的机器上对应于单精度与双精度浮点，且使用向偶数舍入的舍入方式。但**C标准并不要求机器使用IEEE浮点**，因此没有标准的方法来表示NaN和无穷大等特殊值

**当在int、float和double三者间进行强制类型转换时，程序改变数值和位模式的原则是：
* **从int转换到float，==数字不会溢出，但有可能被舍入==
* **从int和float转换成double，==可以保留精确数值==，因为double范围大
* **从double转换成float，==值可能溢出成无穷大或被舍入==
* **从float或double转换成int，值会==向零舍入，也可能会溢出==。C标准并未对溢出情况指定固定结果**，Intel兼容的微处理器指定位模式$[10\cdots 00](TMin_w)$为**整数不确定值**。**当浮点数到整数转换时无法找到一个合理的整数近似值，就会产生这样的值**。例如：(int)+1e10会得到-21489648，即这个整数不确定值

---


# Chapter 3. 程序的机器级表示

计算机执行==**机器代码**==，即**用字节序列编码低级的操作**。编译器则根据**编程语言**的规则、**目标机器**的指令集和**操作系统**遵循的惯例来生成机器代码。
**==汇编代码==** 则是机器代码的文本表示，给出程序中的每一条指令，然后编译器GCC调用汇编器与连接器，生成**可执行的机器代码**
本章我们近距离地观察机器代码以及汇编代码。
```使用高级语言编程提供的抽象级别、效率以及复用性都要高于汇编代码，但对机器代码的理解有助于我们了解与修复系统程序的漏洞，运用命令行工具编写代码也是一种热门的方式（见“计算机学习中缺失的一课”）```
本章中，我们详细学习一种特别的汇编语言，了解如何将C程序编译为这种形式的机器代码。表述基于x86-64，这是现代电脑中最常见处理器的机器语言

## 3.1 程序编码
假设一个C程序，有两个文件.p1.c和p2.c，使用命令行编译以下代码：
```
linux> gcc -Og -o p p1.c p2.c
```
（windows使用gitbash也可以运行，但是需要事先安装GCC C编译器并设置环境变量）
**命令gcc指的就是GCC C编译器**，它是Linux上默认的编译器。而**选项-Og告诉编译器使用会生成符合原始C代码整体结构的机器代码的==优化等级==**，这是因为如果使用更高的优化等级会使得代码严重变形（生成的机器代码与源代码之间的对应关系难以理解）。**更高级别的优化有选项-O1或-O2（我们常说的吸氧优化），它们的性能高，但不适合用来学习**

gcc命令调用了一整套程序来将源代码转化为可执行代码：
* 首先，**==C预处理器==扩展源代码，插入所有用==\#include==命令指定的文件，并扩展所有用==\#define==声明的宏**

* 其次，**==编译器==产生两个源文件p1.c和p2.c的==汇编代码==p1.s和p2.s**

* 然后，**==汇编器==将汇编代码转换成==二进制目标代码文件==p1.o和p2.o**。
（**==目标代码==** 是机器代码的一种形式，它包含所有指令的二进制表示，但还没有填入 **==全局值的地址==**）

* 最后，**==链接器==将两个目标代码文件与实现==库函数==（比如printf）的代码合并，并产生最后的可执行代码文件p，由命令行指示符-o p指定
==可执行代码==是机器代码的第二种形式，它是处理器执行的代码格式。**

### 3.1.2 机器级代码
对于机器级编程，有两种抽象模型非常重要：
* **==指令集体系结构或指令集架构ISA==**，它定义了机器级程序的格式和行为，包括处理器状态、指令的格式以及每条指令对状态的影响。**大多数ISA将程序的行为描述成好像每条指令都是按顺序执行的，一条结束后下一条开始**，而实际上处理器的硬件要更复杂一些：它们并发地执行许多指令，但采取措施保证整体行为与ISA所指定的顺序一致
* **==虚拟地址==**，机器级程序使用的内存地址是虚拟地址，**虚拟地址提供的内存模型看起来是一个非常大的字节数组**，存储器系统的实际实现则是**将多个硬件存储器和操作系统软件组合起来**（第九章的内容）

整个编译过程中，编译器生成汇编代码的工作占大多数，**汇编代码的表示很接近于机器代码，只是并非二进制格式，而是用可读性更好的文本格式表示**

机器代码与C代码差别很大，对它来说一些通常对程序员隐藏的**处理器状态**都是可见的，例如：
* **==程序计数器PC==**(在x86-64中表示为==%rip==)，**它给出将要执行的下一条指令在内存中的地址

* **==整数寄存器文件==**，它包含16个命名的位置，分布存储64位的值。**这些寄存器可以存储地址（对应于C的指针）或整数数据，有的也被用来记录某些重要的程序状态，其他的寄存器则用来保存临时数据**（比如局部变量，返回值等）

* **==条件码寄存器==保存着最近执行的算数或逻辑指令的状态信息，用于实现控制或数据流中的条件变化**，比如用来实现if和while语句

* **一组==向量寄存器==可以存放一个或多个整数或浮点数值

C语言提供了可以在内存中声明和分配各种数据类型的对象，但是**机器代码只是简单地将内存视为一个==很大的、按字节寻址的数组==：
* 对于聚合数据类型，例如数组和结构体，在机器代码中使用一组**连续的字节来表示
* 对于标量数据类型，汇编代码**不区分有符号或无符号整数和各种类型指针，甚至不区分指针和整数** 

**程序的内存包括：程序的可执行机器代码、操作系统需要的一些信息、用来管理过程调用和返回的运行时栈、用户分配的内存块（动态分配内存时用到的内存）
==程序内存用虚拟内存来寻址==。在任意给定时刻下，只有有限的一部分虚拟地址被认为是合法的**

> [!NOTE] 
例如，对于x86-64，表示其虚拟地址的64位字的高16位在目前的实现中必须被设置为0，这就导致一个地址实际上只能指定2^48=64TB范围内的一个字节。更典型的程序只会访问几兆或几千兆字节的数据

**操作系统负责管理虚拟地址空间，将虚拟地址翻译成实际处理器内存中的物理地址**
一条机器指令只执行一个非常基本的操作，编译器必须产生这些简单指令的序列来实现程序结构

### 3.2.2 代码示例
本书所给的代码产生于特定版本的GCC的特定命令行选项设置，因此我们自己编译时很有可能因为版本与设置的原因生成不同的代码。**示例的目的是展示如何查看汇编代码，并将其反向映射至高级编程语言中的结构**，我们需要掌握这部分的技术并应用于自己编译器产生的代码格式上

假设C语言代码文件test.c包含如下的函数定义：
```
long mult2(long, long);

void multstore(long x, long y, long *dest){
long t = mult2(x, y);
*dest = t;
}
```
我们在命令行输入以下命令，以gitbash为例
```
34382@Normist MINGW64 /d/shelllessontest
$ gcc -Og -S test.c

```
**这里-Og后面一个的选项选择了-S，它会在当前文件夹产生.s为后缀的汇编文件，-o则产生.exe后缀的可执行文件**
看到测试文件夹，成功生成了汇编文件：
![[Pasted image 20240808171050.png]]
![[Pasted image 20240808172212.png]]
我们的代码和原书有出入，以原书为准
它产生的汇编代码文件包含各种声明，（原书）单独挑出声明部分：
```
multstore:
	pushq	%rbx
	movq	%rdx, %rbx
	call	mult2
	movl	%rax, (%rbx)
	popq	%rbx
	ret
```
**上述代码中缩进的每一行都对于于一条机器指令**，例如：pushq指令表示应该将寄存器%rbx的内容压入程序栈中。这段代码除去了所有关于局部变量名或数据类型的信息
将选项 -S 改为选项-c，并使用gcc命令，我们会生成一个二进制目标代码文件test.o
```
34382@Normist MINGW64 /d/shelllessontest
$ gcc -Og -c test.c

```
![[Pasted image 20240808173950.png]]
二进制格式的文件无法直接被查看。在这个1368字节的文件中有一段14字节的序列，其十六进制表示为：
```
53 48 89 d3 e8 00 00 00 00 48 89 03 5b c3
```
这就是上面列出的汇编指令对应的目标代码。从这里我们可以看见，**机器执行的程序只是一个字节序列，是对一系列指令的编码。机器几乎完全不知道源代码的信息**

要查看机器代码文件的内容，可以借助==**反汇编器**==程序，**它根据机器代码生成一种类似汇编代码的格式**，可以通过以下命令带上'-d'调用：
```
34382@Normist MINGW64 /d/shelllessontest
$ objdump -d test.o
```
objdump == object dump，直接使用二进制文件的名字即可。生成的结果如下：
![[Pasted image 20240808185627.png]]
左边是前面给出的字节顺序排列的14个十六进制字节值，它们被分成了若干组。每组有1~5个字节，各是一条指令，右边是等价的汇编语言

**机器代码与其反汇编表示的特性有：
* **x86-64的指令长度从1到15个字节不等，常用或操作数较少的指令所需字节会比不常用或操作数较多的指令字节数多**
* 设计**指令格式**的方式是：==**从某个给定位置开始，可以将字节唯一地解码成机器指令**==，例如：只有指令pushq %rbx是以字节值53开头的
* **反汇编器基于机器代码文件中的字节序列来确定汇编代码，并不需要访问程序的汇编代码或源代码**
* **反汇编器的指令命名规则与GCC生成的汇编代码的命名规则有些不同**，例如GCC中push、mov指令结尾含q，在反汇编器中则不含；GCC中call与ret指令不含q，而反汇编器中含q。**后缀q是大小指示符，在大多数情况下可以省略**

**生成实际可执行的代码，需要对一组目标代码文件运行==链接器==，这组目标代码文件==必须含有一个main函数==**
假设在文件main.c中有以下函数：
```
#include <stdio,h>

void multstore(long, long, long*);

int main(){
long d;  multstore(2, 3, &d);
printf("2*3--> %ld\n", d);
return 0;
}
long mult2(long a, long b){
long s = a * b;
return s;
}
```
然后使用gcc的如下命令，将上面所述的test.c文件与其链接，通过以下命令生成可执行文件prog：
```
gcc -Og -o prog main.c test.c
```
**文件prog不仅包含两个过程的代码，还包含了用来启动和终止程序的代码与用来与操作系统交互的代码**。反汇编prog文件可得：
``` 
objdump -d prog
```
![[Pasted image 20240809135214.png]]
生成的代码与test.o反汇编产生的代码几乎完全一样，主要区别在于：
* 左侧列出的地址不同，这是因为**链接器将这段代码的地址移动到一段不同的地址范围中**。
* 第四行中，**链接器填上了callq指令调用函数mult2需要使用的地址**
（在test.o中，调用了未在文件中定义的函数mult2，而第四行代码是callq 9<multstore+0x9>，**0x9表示在multstore函数开始位置偏移9字节后的地址，mult2在该地址中被调用**。而在prog文件反汇编产生的代码中，mult2的地址40058b被给出来了）这说明**链接器的任务之一就是为函数调用找到匹配的函数的可执行代码的位置**
* prog文件反汇编出的代码比test.o多了第8和9行两行（==nop==），**出现在返回指令（retq）后面的指令对程序都没有影响**，插入这些指令的目的是**使得函数代码变成16字节，让存储器能更好地放置下一个代码块

### 3.2.3 关于格式的注解
GCC产生的汇编代码包含我们不需要关心的信息，且不提供任何程序或是它如何工作的描述，因此有些难读。例如在test.s的完整内容中：
![[Pasted image 20240809142803.png]]
**所有以' . '开头的行都是指导汇编器和链接器工作的==伪指令==，通常可以被忽略**
为了更清楚地说明汇编代码，我们用以下省略了大部分伪指令和包括解释性说明的形式表示汇编代码：
![[Pasted image 20240809143314.png]]

#### 3.2.3.Ex 旁注
我们之前所描述的GCC、OBJDUMP等工具默认使用的汇编代码格式称为**ATT格式**，还有另外一种汇编代码格式称为**Intel格式**，常见于微软的工具和Intel的00文档中
使用以下指令让GCC产生intel格式的汇编代码：
```
gcc -Og -S -masm=intel test.c
```
![[Pasted image 20240809144454.png]]
可见intel与ATT格式有如下的不同：
* Intel代码省略了指示大小的后缀q
* Intel代码省略了寄存器名字前面的'%'
* Intel代码用不同的方式来描述内存中的位置，例如QWORD PTR\[rbx]，而非(%rbx)
* 描述带有多个操作数的指令时，列出操作数的顺序相反

**对于单纯的C程序，有一些机器特性是访问不到的，例如每次处理器进行算术或逻辑运算时的PF奇偶标志。** 此时需要**在程序中插入几条==汇编代码指令
==**
**在C程序中插入汇编代码有两种方法：
* **1.编写完整的函数，放入一个==独立的==汇编代码文件中，让汇编器和链接器把该文件和用C语言书写的代码合并起来
* **2.使用GCC的==内联汇编==特性，它允许你在C代码中嵌入汇编指令。**
  GCC使用==**asm或__asm__关键字**== 实现，其基本语法是：
```
asm("assembly code":output operands:input operands:clobbered registers)
  "assembly code"是包含了汇编指令的字符串，可以使用多行字符串
  output operands是指定汇编代码输出变量的列表
  input operands是指定汇编代码输入变量的列表
  clobbered registers是指定在汇编代码中可能发生改变的寄存器的列表 
```

**汇编代码与机器类型强相关，为了可移植性的考虑，只应该在想要的特性只有唯一的方式被访问时才使用它**

## 3.3 数据格式
**Intel用术语“==字==”表示16位数据类型，因此32位数据类型称为“==双字==”，64位数据类型为“==四字==”**，下面是C语言数据类型在x84-64中的大小及其**汇编代码后缀**：
![[Pasted image 20240809152642.png]]
**==1字节=8位==**
C程序中还有一种特殊的10字节80位浮点格式long double，但并不建议使用这种可移植性与性能不高的数据类型
**大多数GCC生成的汇编代码指令都有一个字符的后缀，表面操作数的大小**。例如，数据传送指令mov的四个变种：movb（传送字节）、movw（传送字）、movl（传送双字）、movq（传送四字）。这里注意后缀' l '，它在这里用来表示双字，在数中也表示4字节整数和8字节双精度浮点数，**因为浮点数使用的是一组完全不同的指令和寄存器，所以这不会产生二义性**

## 3.4 访问信息
**一个x86-64的==中央处理单元（CPU）==包含一组16个存储64位值的==通用目的寄存器==，它们用来存储==整数数据与指针==。
16个寄存器的名字都以==%==结尾，如图：**
![[Pasted image 20240810193835.png]]
（由于历史问题，前排的取名规则并不像后排一样工整）
图中嵌套的方框代表着指令控制寄存器字节的位数：以第1行为例，从右往左看，%al、%ax、%eax、%rax依次增大，代表访问字节的权限：**字节级操作可以访问最低的字节；16位操作可以访问最低的2个字节；32位操作可以访问最低的4个字节；64位操作可以访问整个寄存器**

后面的章节中会有很多指令用于**复制和生成1、2、4和8字节值**。
**当这些指令以寄存器作为目标时，对于==生成小于8字节结果的指令==，剩下的字节遵循以下规则：**
* **生成==1字节和2字节==数字的指令会==保持剩下的字节不变==
* **生成==4字节==数字的指令==会把高位的4个字节置为0==

在程序中，不同寄存器扮演不同的角色，例如栈指针%rsp就是用来指明运行时栈的结束位置的。有一组标准的编程规范控制着**如何使用寄存器来管理栈、传递函数参数、从函数返回值、存储局部和临时数据**，后面会讲到。


> [!NOTE] 记住特殊含义的寄存器
> **寄存器%rax：该寄存器中存储的值，在程序返回后，即执行ret命令时，会作为返回值被返回
> 寄存器%rdi  %rsi  %rdx  %rcx是参数传入时，存储第1、2、3、4个参数的寄存器
> 寄存器%rsp作为栈指针，它存储栈顶的地址：当把数据压入栈中时，%rsp值会减少；从栈中弹出数据时，%rsp值会增加**


### 3.4.1 操作数指示符
**大多数指令有一个或多个==操作数==，指示出执行一个操作中要使用的==源数据值==，以及用来放置结果的==目的位置==。**
**==源数据值==可以以常数形式给出，或是从寄存器或内存中读出。而==结果==可以存放在寄存器或内存中。因此，各种不同的操作数可以分为三种类型：
* **1. ==立即数操作数==：用来表示常数值。** 在ATT格式的汇编代码中，立即数的书写方式是：**在'$'后面跟一个用==标准C表示法==表示的整数，例如\$-577或\$0x3a
* **2. ==寄存器操作数==：它表示某个寄存器的内容。** 8位/16位/32位/64位机器在16个寄存器的低位1字节/2字节/4字节/8字节中的一个作为操作数。
  **我们用$r_a$表示任意寄存器$a$，将寄存器集合视为一个数组$R$，用引用$R[r_a]$索引它的值
* **3. ==内存引用==：它根据计算出来的==有效地址==访问某个内存位置。**
  **我们将内存视为一个很大的字节数组，因此用符号$M_b[Addr]$表示对存储在内存中从地址$Addr$开始的$b$个字节值的引用，表述时也可能省略下标b

看到下面表格：格式是表示形式，操作数值就是操作数存储的值，计算方式就在图中。**M理解为整个内存，由地址标定位置；R是用于定位寄存器的数组，无其他含义**。
**==源操作数指定数据所来源的位置或源数据值，目的操作数指定数据要被写入的位置或写入的值==**。换而言之，**源操作数和目的操作数可以是数据值，也可以是指示位置的地址，==它们具体应该是什么取决于指令的格式和操作语义==**
![[Pasted image 20240810204755.png]]
如图所示，**有许多不同的==寻址模式==，允许不同形式的==内存引用==，即
表中最后一行使用$Imm(r_b, r_i, s)$表示的是最常用的形式，它有四个组成部分：==立即数偏移==$Imm$、==基址寄存器==$r_b$、==变址寄存器==$r_i$、==比例因子==$s$，==这里$s$必须是1、2、4或者8==。
基址寄存器和变址寄存器都必须是64位寄存器，有效地址的计算公式为：
$$ Imm+R[r_b]+R[r_i]*s$$
引用数组元素时，会用到这种通用形式。其他形式都是它的特殊情况，省略了某些部分**


> [!NOTE] 立即数偏移、基址寄存器、变址寄存器与比例系数
> 1. 立即数偏移：在寻址模式中，直接在指令中指定一个常量值，用来作为地址偏移的偏移量，通常是整数，加到地址上代表偏移得到最终地址
>  ................................................................................................................................................
> 2. 基址寄存器：用来存储内存地址的寄存器，在计算内存地址时作为==基准点==，常用于存储数据结构的==起始地址==，可以与偏移量结合访问结构中的不同元素
>.....................................................................................................................................................
> 3. 变址寄存器：用于计算内存地址的寄存器，它存储了相==对基址寄存器的偏移量==，与比例因子一同进行==乘法操作==后与基址寄存器相加即为实际偏移
> ......................................................................................................................................................
> 4. 比例因子：是一个通常为2的幂（1、2、4、8）的常量，用于调整变址寄存器的值。因为各种数据类型的大小字节数都为2的幂，此时想进行偏移访问一个数组中不同的元素，通过将偏移量乘以2的幂就可以快速地访问各元素，增加效率


> [!NOTE] 例题：熟悉操作数格式
> ![[Pasted image 20240810211333.png]]
> 题中给出了地址-值，寄存器-值两个表。查阅表3.3对应所有情况即可计算所有值：
> 对于操作数%rax，存储在寄存器中的值$R[r_a]$的R表示的只是寄存器集合，用于标定寄存器，其值就是题面给出的寄存器%rax存储的值0x100；
> 对于操作数0x104，它来自存储器，即内存。它的格式是表3.3中第3行，M就是题中左边的地址-值所示的内存，M\[Imm]就是题中0x104所存储的值0xAB；
> 对于操作数$\$0x108$，显然是表中第一行的立即数，其值就是$\$Imm$里的Imm，即0x108；
> 对于(%rax)，对应表中第四行的$(r_a)$。其值是$M[R[r_a]]$，即$M[0x100]$，查题目左表可得结果是0xFF；
> 对于4(%rax)，对应表中第五行的$Imm(r_b)$，其值是$M[Imm+R[r_b]]$，即$M[4+0x100]=M[0x104]=0xAB$；
> 其它同理查表3.3和题目给出的表即可，注意0xFC( , %rcx,4)是表中最后一行的普通格式$Imm(r_b, r_i, s)$缺省$r_b$所得，因此在计算公式中$R[r_b]=0$，然后按公式计算即得值为$M[0x100]=0xFF$

### 3.4.2 数据传送指令
最频繁使用的指令是**将数据从一个位置复制到另一个位置**的指令。我们会介绍不同的数据传送指令，**我们把许多不同的指令划分成==指令类==，每类指令执行相同操作，类间指令操作数大小不同**

下面是最简单形式的数据传送指令：**==MOV类==**
![[Pasted image 20240810214436.png]]
**这些指令把数据从源位置复制到目的位置，不做任何变化**，movb/movw/movl/movq的操作相同，区别在于它们操作的数据大小：分别是1/2/4/8字节
**对于一个MOV指令，需要提供一个源操作数和一个目的操作数。
源操作数指定的值是一个立即数，存储在寄存器或内存中；目的操作数指定一个位置，要么是一个寄存器或是一个内存地址**
同时，**像MOV这样的传送指令的两个操作数==不能都指向内存位置(寄存器不是内存位置！所以两个操作数可以都是寄存器的名字)==**
通过以上的限制，我们可以发现：**如果要实现将一个值从一个内存位置复制到另一个内存位置，需要两条指令：1. 将源值加载到寄存器中的指令； 2. 将该寄存器值写入目的位置的指令
指令指示寄存器的操作数可以是16个寄存器中任意一个寄存器的4层不同位级部分的标号。==寄存器部分的大小必须与MOV指令最后一个字符b/w/l/q所对应的数据大小相同==**
大部分情况下，**MOV指令只会更新目的操作数所指定的那部分寄存器字节或内存位置（但是movl指令会把该寄存器的高位4字节设置为0）

> [!NOTE] x82-64的惯例：
> 任何为寄存器生成32位值（4字节值）的指令都会把该寄存器高位部分置为0

以下是MOV指令源操作数和目的操作数的五种可能的类型：
```
1    movl $0x4050,%eax       .... 立即数-寄存器。4字节
2    movw %bp,%sp            .... 寄存器-寄存器。2字节
3    movb (%rdi,%rcx),%al    .... 内存位置（基址+变址偏移）-寄存器。
4    movb $-17,(%rsp)        .... 立即数-内存位置（基址）。1字节
5    movq %rax,-12(%rbq)     .... 寄存器-内存位置（基址+常数偏移量）
```

> [!NOTE] 注意
> **我们在表3-3看到的以$Imm(r_b,r_i,s)$及其各种缺省形式的表示方法，除了寄存器$r_a$不属于内存位置（值$R[r_a]$的数组是R，而不是M）之外，所寻的地址都是内存的地址（值的数组是内存空间M）（纯偏移量Imm得到的地址以整数标识，寄存器以寄存器代号标识，因此Imm也只能标识内存空间地址）**

还有一个之前没介绍但出现在图3-4的指令movabsq，**常规的movq指令只能以表示为==32位补码数字==的立即数作为源操作数，然后把它==按符号扩展==得到64位值。而movabsq指令能够以任意64位立即数值作为源操作数，==并且只能以寄存器作为目的操作数==**

还有两类数据移动指令，**它们用于==将较小的源值复制到较大的目的位置==时，对较小源值进行扩展**
![[Pasted image 20240811154625.png]]
**MOVZ类中的指令通过零扩展把目的位置中剩余的字节全部填充为0，而MOVS类中的指令通过符号扩展来填充：填充源操作数的最高位数字**
**==movzbl和movl一样，会把寄存器的高四字节置为0==**；而movsbl只会保持符号扩展的高字节
**==这两类传送指令的目的操作数都只能是寄存器，其中cltq指令更是只作用于%eax与%rax==**
注意：**没有把4字节源值零扩展到8字节目的的指令，它可以直接用movl代替，因为movl会自动把高4字节的位置全部置成0**

> [!NOTE] 数据传送改变目的寄存器的示例
> 我们知道，-1的十六进制表示是$FF\cdots F$（逆元通过$00\cdots 01$取反加1获得），64位机器其二进制位数是64位，十六进制位数为16。看到以下代码示例：
> ```
> 1  movabsq $0x0011223344556677,%rax   %rax=0011223344556677
> 2  movb       $-1,%al  (最低位的1字节8位)   %rax=00112233445566FF
> 3  movw       $-1,%ax (低位的2字节4位)   %rax=001122334455FFFF
> 4  movl         $-1,%eax (4字节16位，它会把其他位置成0)  %rax=00000000FFFFFFFF
> 5  movq       $-1,%rax  (全部的64位)        %rax=FFFFFFFFFFFFFFFF
> ```
>

### 3.4.3 数据传送示例

考虑以下函数：
```
long exchange(long *xp, long y)
{
long x = *xp;  //x是xp解引用后的值，即指针xp所指向的值
*xp = y;
return x;
}
```
生成的汇编代码：
```
long exchange(long *xp, long y)
xp in %rdi, y in %rsi
exchange:
	movq      (%rdi), %rax
	movq      %rsi, (%rdi)
	ret                     #return
```
在第二行我们看到，当函数过程开始执行时，参数xp（类型为指针）和y被存储在寄存器%rdi和%rsi中。

**==寄存器存储指针 == 寄存器存储了一个地址，这个地址指向了内存中的一个位置==**

然后，第一个movq指令的源操作数是(%rdi)，**==间接选址==，因为指针xp被存储进%rdi中了，相当于%rdi存储了一个地址，标注了xp所指向对象的位置。** 代码long x = \*xp; 的含义是为x赋上xp指向对象的值，**因此(%rdi)在内存中使用%rdi所储存的地址，找到了xp所指向的对象，然后将其存放到寄存器%rax里**
接着的第三个movq指令，从%rsi中得到了值y，然后目标位置是(%rdi)，即xp所指向的对象在内存中的位置。**将值y写入xp指向对象在内存中的位置，就是直接实现了操作\*xp=y**。

从这个例子我们可以看见：**存储指针的寄存器存储的本质上是地址，可以通过间接寻址在内存中找到其所指向的对象；并且==像x这样的局部变量通常保存在寄存器中，而不是内存中==，因为寄存器的访问更快**

### 3.4.4 压入和弹出栈数据
**有两个数据传送操作可以将数据压入==程序栈==中，和从程序栈中弹出数据，它们是push指令和pop指令**：
![[Pasted image 20240811171807.png]]

**栈是一种数据结构，“后进先出”地添加或删除值，在过程调用的处理中至关重要**。通过push和pop操作可以把数据压入栈中和弹出数据，它的性质是：**弹出的值永远是最近被压入而且仍然在栈中的值**
**栈可以用数组实现（算法基础课），具体来说就是总从数组的一端插入和删除元素，这一端就是==栈顶==**
x86-64中，**程序栈存放在==内存的某个区域中==，寄存器%rsp储存栈指针，即栈顶元素的地址
pushq与popq指令都只接受一个操作数：pushq指令接受压入数据的数据源；popq接受弹出数据的目的位置

将一个四字值压入栈中，首先需要把**栈指针减8字节（四字=8字节）**，然后将值写到新的栈顶地址，因此指令pushq %rbp 的行为类似于：
```
subq $8,%rsp     ......subq即减字节操作，将%rsp存储的地址减立即数8
movq %rbp,(%rsp) ......将%rbp中存储的值复制到%rsp存储的地址所指向的内存中的位置，即替换
```
不过上述两条指令在机器代码中一共需要8个字节来编码，而pushq只需要1个字节

将一个四字值弹出栈的操作包括：**从栈顶位置读出数据，然后将栈指针加8**，因此指令 popq %rax 的行为类似于：
```
movq (%rsp),%rax  ...将%rsp储存的地址所指向的内存位置存储的值复制到%rax
addq $8,%rsq      ...将%rsq加8字节，原来的四字被移除
```

**栈和程序代码，以及其他形式的程序数据==都放于同一内存中==，因此程序可以用标准的内存寻址方法访问栈内的任意位置**
例如：若栈顶元素是个四字值，那么指令 movq 8(%rsp),%rdx  会先把%rsp偏移8字节，到达栈内下一个四字值（弹出后会成为新的栈顶的四字）的开头，然后将接下来的8字节值从栈中复制到寄存器%rdx

## 3.5 算术和逻辑操作
下面是一些被表示成指令类的整数和逻辑操作：
![[Pasted image 20240811185716.png]]
**除了leaq指令之外，这些指令类都有各种带不同大小操作数的变种**，例如ADD类就有：addb、addw、addl和addq（字节加法、字加法、双字加法和四字加法）
下面对这些指令进行介绍：

### 3.5.1 加载有效地址
加载有效地址指令leaq实际上是movq指令的变形，**它的指令形式是：从内存读数据到寄存器，但实际上并没有引用内存**
**leaq指令的第一个操作数是==将有效地址写入到目的位置的操作数==，** 即 
leaq S,D 的效果是：$D\leftarrow \&S,\quad \&是取地址符$** 
也就是**将源数据的内存地址写入到目的位置（寄存器中），==目的操作数必须是一个寄存器**

leaq指令的作用在于：**为后面的内存引用产生指针(地址），还可以简洁地描述普通的算术操作**
例如，若寄存器%rdx的值为x，那么指令  leaq 7(%rdx,%rdx,4),%rax  就是：
7(%rdx,%rdx,4)按照计算，其值应该是M\[%rdx+4*%rdx+7]=M\[5x+7]，M是内存抽象的字节数组
**而由于leaq指令取的是地址，将地址存入目的操作数指示的位置，所以存入%rax的就是值5x+7，无需进行寻址**

作为leaq在编译出的代码中的一个应用示例，看到以下程序：
```
long scale(long x, long y, long z) {
long t = x + 4 * y + 12 * z;
return t;
}
```
其汇编代码：
```
long scale(long x, long y, long z)
x in %rdi, y in %rsi, z in %rdx
scale:
	leaq    (%rdi,%rsi,4),%rax     x + 4*y
	leaq    (%rdx,%rdx,3),%rdx     z + 2*z 
	leaq    (%rax,%rdx,4),%rax     (x + 4*y) + 4*(z + 2*z)
	ret
```
编译时，该函数的算术运算都是通过leaq指令实现的
**leaq指令能够执行加法和有限形式的乘法，在编译简单算术表达式时很有用

### 3.5.2 一元和二元操作
**第二组的操作：
![[Pasted image 20240812194610.png]]
是==一元操作==，它们只有一个操作数，它既是源，又是目的。** 例如，指令incq (%rsp) 会使得栈顶的8字节元素加1，其行为有点类似于C语言的++

**第三组的操作：
![[Pasted image 20240812202029.png]]
是==二元操作==，它们的第二个操作数既是源，又是目的。** 这种行为有点类似于c语言的复合赋值运算符-=等。**要注意，源操作数是第一个S，目的操作数是第二个D，S可以是立即数、内存位置或寄存器；D不能是立即数，可以是内存位置或寄存器。**
例如，指令subq %rax,%rdx  就是将寄存器%rdx中存储的值减去寄存器%rax中存储的值，再把所得的值赋给寄存器%rdx。宏观来看就是把%rdx存的值减去了一个%rax存的值
注意：**当第二个操作数为内存地址时，处理器的行为是：从内存中读取值，对该值执行操作，然后把结果写回内存**

### 3.5.3 移位操作
![[Pasted image 20240812203826.png]]
这一组是移位操作，**它们的第一项操作数是移位量，可以是一个==立即数或是存放在单字节寄存器%cl的值==。** 
x86-64中，**移位操作对w位长的数据值进行操作时，移位量是由%cl寄存器的低$m=\log_{2}(w)$位决定的，其他位会被省略。** 例如，当寄存器%cl存的值是0xFF时，执行指令salb时，$m=\log_{2}(2^3)=3$，即取其低3位，十进制值为7，因此该指令会左移七位。其他指令类似（**==1字节等于8位==**）

**SAL和SHL都是左移指令，它们完全一样，都是左移后把右边添上0；而SAR和SHR的右移方式就有算术和逻辑的差别了**

### 3.5.4 指令用于运算
上述指令，**既可以用于无符号运算，又可以用于补码运算。因为右移操作区分有符号数与无符号数，所以补码运算可以成为实现有符号整数运算的一种比较好的方法。**
以下列函数为例：
```
long arith(long x, long y, long z){
long t1 = x ^ y;
long t2 = z * 48;
long t3 = t1 & 0x0F0F0F0F;
long t4 = t2 - t3;
return t4;
}
```
其汇编代码是：
```
long arith(long x, long y, long z)
x in %rdi, y in %rai, z in %rdx
arith:
	xorq    %rsi,%rdi            t1 = x^y
	leaq    (%rdx,%rdx,2),%rax   3z
	salq    $4,%rax              t2=16*3z=48z
	andl    %252645135,%rdi      t3 = t1 & 0x0F0F0F0F
	subq    %rdi,%rax            返回值为 t2 - t3
	ret
```
存放返回值的寄存器%rax中的值由3z变为48z再变为t2-t3，存储了多个程序值。**通常编译器产生的代码，会用一个寄存器存放多个程序值，还会在寄存器之间传送程序值**

### 3.5.5 特殊的算术操作
**两个64位有符号或无符号整数相乘的乘积需要128位来表示，然后再进行截断。
x86-64指令集对128位16字节的数提供有限的运算，我们把16字节的数称为==八字==，下图是支持产生两个64位数字的全128位乘积和整数除法的指令：**
![[Pasted image 20240812215320.png]]
可以看到，**128位的精确表示是由==两个寄存器%rdx与%rax共同组成==的**

**imulq指令有两种不同的形式：
1. **双操作数形式的乘法，在图3-10中：
   ![[Pasted image 20240813181108.png]]
   ==它是有截断的==：从两个64位操作数中产生一个64位的乘积。类似于第二章所讲的${*}^{u或t}_{64}$
   
2. **单操作数形式的乘法，即上图3-12所展示的接受一个操作数的乘法指令**
（汇编器通过操作数的个数来确认使用哪个版本）

x86-64指令集提供了两条不同的单操作数乘法指令**imulq S 和mulq S**，**imulq提供有符号数的补码乘法，mulq提供无符号数乘法，==它们都计算两个64位值的全128位乘积==。
这两条指令都要求==一个参数必须在寄存器%rax中，而另一个参数由源操作数S给出==，它们的乘积存放在==寄存器%rdx的高64位和寄存器%rax的低64位中==。

假设我们有以下C代码：
```
#include <inttypes.h>   //使用64位的int类型命名，它*没有*提供128位int
typedef unsigned__int28 uint128_t

void store_uprod(uint128_t *dest, uint64_t x, uint64_t y){
*dest = x * (uint128_t)y;
}
```
**文件inttypes.拓展了标准C的定义，但是并没有提供128位的值。我们只能依靠==GCC提供的128位整数支持==，用名字==__int128==来声明128位整数**
这段代码的含义是：**将x和y相乘得到的128位表示的int乘积存入指针dest指向的16字节处**
它生成的汇编代码：
```
void store_uprod(uint128_t *dest , uint64_t x, uint64_t y) 
dest in %rdi, x in %rsi, y in %rdx     %rdi中存储地址，即指针dest
store_uprod:
	movq  %rsi,%rax   将x复制到%rax，作为高位乘法存储在%rax中的参数
	mulq  %rdx    用%rdx中的y乘以%rax中的x，此时低8字节在%rax，高8字节在%rdx
	movq  %rax,(%rdi)   将低8字节存储在dest所指向的内存地址开头
	movq  %rdx,8(%rdi)  将高8字节存储在（dest指向的内存地址+8字节）的地址
	ret
```
不难发现，**存储乘积需要两个movq指令：一个存储低8字节，另一个存储高8字节。因为这段代码生成的机器为==小端法==机器，高位字节存储在大地址（dest+8)**

.............................................................................................................

图3-10并没有列出除法或取模操作：
![[Pasted image 20240811185716.png]]这是因为**乘法和取模操作都是通过单操作数除法指令来实现的**：
![[Pasted image 20240813193108.png]]
类似于单操作数乘法，**单操作数除法指令idivl将寄存器%rdx存储的高64位和寄存器%rax存储的低64位值所共同表示的128位数作为==被除数==，而操作数S则作为==除数==**
==**指令将商存储在寄存器%rax中，将余数存储在寄存器%rdx中**==
对于大多数64位除法应用，其除数也常常是个64位值，它应该存放在寄存器%rax中
**对于无符号运算，存储在%rdx的高64位值应该全为0；而对于有符号运算，存储在%rdx的值应该各位全为%rax的符号位**。这个操作可以通过==**指令cqto**==实现，**该指令无需操作数：它隐含地读出%rax的符号位，并把其赋给%rdx的每一位**

以下列C程序作为除法实现的说明，它计算两个64位有符号数的商和余数：
```
void remdiv(long x, long *rp, long *qp, long *rp){
long q = x/y;
long y = x%y;
*qp = q;
*rp = r;
}
```
其生成的汇编代码如下：
```
void remdiv(long x, long y, long *qp, long *rp) 
x in %rdi , y in %rsi , qp in %rdx, rp in %rcx
remdiv:
	movq    %rdx,%r8   将指针qb存储的地址拷贝至寄存器%r8
	movq    %rdi,%rax  将被除数x移动到寄存器%rax
	cqto               将储存被除数高64位的%rdx设置为%rax的符号位，（这里是64位除法所以高64位仅作符号）
	idivq   %rsi       用y除x
	movq    %rax,(%r8) 将%rax中储存的商存储到指针qp所指向的内存地址
	movq    %rdx,(%rcx) 将%rdx中储存的余数存储到指针rp所指向的内存地址
	ret
```
因为除法操作需要用到寄存器%rdx，所以第一条指令就把参数qp复制到另一个寄存器%r8中了，然后把x移动到%rdx并进行高8字节的符号扩展。
**对于无符号除法divq，寄存器%rdx会被事先设置为全0**

## 3.6 控制
目前为止，我们的例子所考虑的都只是**直线代码**的行为，指令一条条顺序地执行。而对于要求有条件的执行，如条件、循环和分支语句，**需要根据数据测试的结果来决定操作执行的顺序。**
机器代码提供两种基本的低级机制来实现有条件的行为：**首先测试数据值，然后根据测试的结果来改变控制流或数据流

==**与数据相关的控制流**==是实现==**有条件行为**==的一般方法。通常，**C语言中的语句和机器代码的指令都是按照它们在程序中出现的次序来顺序执行的。**
**使用==jump指令==可以改变一组机器代码指令的执行顺序。==jump指令指定控制应该被传递到程序的某个其他部分，可能依赖于某个测试的结果==。

### 3.6.1 条件码
除了整数寄存器，**CPU还维护着一组==单个位==的==条件码寄存器==，它们描述了==最近的算术或逻辑操作==的属性**，可以通过检测这些寄存器去来执行条件分支指令
常用的条件码有：
* **CF：进位标志。最近的操作使最高位产生了进位**，可以用来检查无符号操作的溢出
* **ZF：零标志。最近的操作得出结果为0
* **SF：符号标志。最近的操作得出结果为==负数==
* **OF：溢出标志。最近的操作导致一个==补码溢出==（正溢出或负溢出）

例如，假设用一条ADD指令完成C表达式t = a + b的功能，t、a、b均是整型。那么条件码按下列表达式设置：
```
CF  (unsigned)t < (unsigned)a     无符号的溢出（进位）
ZF  (t == 0)                      零
SF  (t<0)                         负数
OF  (a<0 == b<0) && (t<0 != a<0)  有符号的溢出
```

还是看到图3-10：
![[Pasted image 20240811185716.png]]
**除了进行地址计算的指令leaq之外，所以列出的指令都会设置条件码：
对于逻辑操作，如XOR，进位标志和溢出标志会设置为0；对于移位操作，进位标志将设置为最后一个被移出的位，溢出标志被设置为0；指令INC与DEC会设置溢出标志与零标志，但不会改变溢出标志

除了以上指令外，还有两类指令类，**它们只设置条件码，而不更新目的寄存器**：
![[Pasted image 20240813212445.png]]
**CMP指令与图3-10的==SUB指令==的行为是一样的，都通过操作数之差实现。
如果两个操作数相等，CMP指令会把零标志设置为1，其他标志则可以用来确定两个操作数之间的大小关系（符号标志）

**TEST指令的行为与图3-10的==AND指令==是一样的，但是它们只设置条件码，而==不改变目的寄存器的值==。** 一个用法是使用两个相同的操作数 test %rax,%rax   这用来检测%rax是正数、负数还是0

### 3.6.2 访问条件码
**==条件码通常不会被直接读取==，常见的使用方法有：
* **1. 根据条件码的某种组合，将==一个字节==设置为0或1
* **2. 可以条件跳转到程序的某个其他部分
* **3. 可以有条件地传送数据

对于第一种情况，下图3-14的**SET类指令根据条件码的组合，将一个字节设置为0或1**，它们的区别仅在于考虑的条件码组合不同：
![[Pasted image 20240814194218.png]]
**指令的不同后缀指明了它们所考虑条件码组合的不同，==而不是操作数大小==：指令setl和setb 代表 小于时设置(set less) 和 低于时设置(set below)**
一条SET指令的目的操作数是==**低位单字节寄存器**==之一，或是==**一个字节的内存位置**==，**指令会把操作数所指示的单字节设置成0或1**
 *（低位单字节寄存器的名字见 3.4 访问信息 ）*
为了得到一个32位或64位结果，我们必须**对高位清零（把高位置0）**
**所有SET指令都符合一个描述：==根据 t = a - b设置好各种条件码，再对它们执行比较指令==。

对于 **==有符号比较==** ，假设a、b和t分别是变量a、b和t的==补码形式==表示的整数，$t=a{-}^{t}_{w} b$，w取决于a和b的大小，**根据这个计算结果设置各个条件码（==溢出标志OF、符号标志SF和零标志ZF==），利用条件码的运算表示测试结果**
例如：
sete指令，它代表“相等时设置”，当a\==b时，t=0，此时设置零标志ZF=0即可。
stel，代表“小于时设置”，它测试一个**有符号比较**，当没有发生溢出时（**OF=0**），我们有：当$a{-}^{t}_{w}b<0时，a<b$ ，因此**将符号标志SF设置成1代表小于情况**；当$a{-}^{t}_{w}b\geq 0时，a\geq b$，此时**把SF设置为0代表大于等于**；
如果发生溢出，**OF=1**，有
$$\begin{align*}
&当a{-}^{t}_{w}b> 0（负溢出）时出现a< b；\\
&当a{-}^{t}_{w}b< 0（正溢出）时出现a>b;\\
&当a=b时，无溢出
\end{align*} $$
此时**SF=0时，$a<b$；SF=1时，$a\geq b$**
**可见，可以使用OF和SF的比较符号异或^来提供a<b是否为真的测试。** 其他的有符号比较同理
综上所述：**==有符号比较的检测基于条件码SF^OF和ZF的各种组合==**

对于 **==无符号比较==** ，设a和b是变量a和b无符号形式表示的整数，**在执行计算t = a - b时，有当a-b<0时，==进位标志CF==会被设置为1，只需要考虑和零标志ZF的结合即可**
综上所述：**==无符号比较的检测基于条件码CF与ZF的组合==**


以一个计算C表达式 a < b的指令序列为例，这里a和b都是long类型：
```
int comp(data_t a, data_t b) 
a in %rdi , b in %rsi
comp:
	cmpq    %rsi,%rdi      比较a和b
	setl    %al            将寄存器%eax的低8位设置为0或1
	movzbl  %al,%eax       将%eax和%rax的其他部分清空，“把高位清零”
	ret
```
**注意cmpq指令的比较顺序：虽然参数是先%rsi(b)后%rdi(a)，但它执行的操作是a - b （后减前）**，并且更新标志寄存器
比较完成后，**setl指令将寄存器%eax的低位寄存器%al根据最近的一次操作（cmpq）的结果：是否出现“小于”，将%al设置为0或1**，然后movzbl将%eax的高3个字节和%rax的高4个字节置为0（%al占一个字节，%eax共四个字节，**movzbl将%al中的值零扩展为四个字节**，传输给%eax，同时由于生成了一个32位的值，根据惯例将整个寄存器%rax的高四字节置为0）

**某些底层的机器指令可能有多个名字，称为“==同义名==”**，例如：指令setg（表示“设置大于”）和指令setnle（表示“设置不小于等于”）指的就是同一条指令，**编译器和反汇编器会随意决定使用哪个名字**
**机器代码中，区分有符号和无符号值是很重要的。机器代码==不会把每个程序值与一个数据类型联系起来==，大多数情况对于有符号和无符号值都用的同一套指令**。这是因为很多算术操作对于无符号运算与补码运算的位级行为相同。因此，**需要用不同的指令来处理有符号和无符号操作**，比如不同版本的右移、乘除和条件码的不同组合。

### 3.6.3 跳转指令
正常情况下，指令按照出现顺序依次执行。**跳转指令会导致指令执行切换到程序中的一个全新的位置**。
**跳转指令的目的地通常使用一个==标号==来表示：**
```
	movq $0,%rax
	jmp  .L1
	movq (%rax),%rdx
 .L1:
	popq %rdx
```
这里jmp .L1代表跳转到标号.L1的位置开始执行，跳过了movq指令
**在产生目标代码文件时，汇编器会确定所有==带标号指令==的地址，并把==跳转目标==（目的指令的地址）编码为跳转指令的一部分**
下面是不同的跳转指令：
![[Pasted image 20240818191330.png]]
**jmp指令是==无条件跳转==**，它可以是***直接跳转*：跳转目标作为指令的一部分**；也可以是***间接跳转*：跳转目标是从寄存器或内存中读出得到的**
汇编语言中，**直接跳转是给出一个==标号==作为跳转目标**，例如上面例子中的“.L1"；**而间接跳转的写法是==‘\*’后面跟着一个操作数指示符==，使用内存操作数格式中的一种**
例如：
```
jmp *%rax          ......用寄存器%rax中的值作为跳转目标
jmp *(%rax)        ......用%rax中存储的地址，读取内存中的值作为跳转目标
```

**图3-15中的其他跳转指令都是==有条件的==：它们根据条件码的某种组合，来决定应该进行跳转还是不跳转，执行下一条指令。** 
**==有条件的跳转指令只能是*直接跳转*==**

### 3.6.4 跳转指令的编码
理解跳转指令的目标如何编码有利于理解链接和反汇编器的输出。
在汇编代码中，**跳转目标用符号标号书写，而汇编器和链接器会产生跳转目标的适当编码**
跳转指令的编码有几种形式，最常用的是==**PC相对的(PC-relative)**==，即：**它们会将==目标指令的地址==与==紧跟在跳转指令后面那条指令的地址==之间的==差==作为编码**，这些**地址偏移量**可以写成1、2或4个字节的值
另一种编码方法则是**给出“绝对”地址**：**用==4个字节==直接指定目标**。
汇编器与链接器会根据情况选择适当的目的编码

以下面的函数为例：
```
	movq  %rdi,%rax
	jmp   .L2
  .L3:
	sarq  %rax
  .L2:
	testq %rax,%rax
	jg    .L3
	rep; ret
```
该函数branch.c包含两个跳转：**jmp指令前向跳转到更高的地址，jg指令后向跳转到较低的地址**
该函数的反汇编代码如下：
```
	0:  48 89 f8                mov  %rdi,%rax
	3:  eb 03                   jmp  8 <loop+0x8>
	5:  48 d1 f8                sar  %rax
	8:  48 85 c0                test %rax,%rax
	b:  7f f8                   jg   5 <loop+0x5>
	d:  f3 c3                   repz retq
```
注释可见，第二行的跳转指令jmp的**跳转目标指明为==loop标签==后的0x8（加上8个字节的位置）**，第五行的跳转指令jg的跳转目标则是0x5
观察指令本身的字节编码，我们可以看见第二行的跳转指令jmp的**第二个字节**：
```
	3:  eb 03
```
是0x03，意味着**该跳转指令的目标指令编码为0x03**
同时看到**紧跟在该指令的后一条指令**：
```
	5:  48 d1 f8
```
它的地址是0x5，我们注意到**跳转指令的目标编码0x3加上后一条指令的地址0x5恰好就是跳转目标地址0x8**，即第四行指令的地址：
```
	8:  48 85 c0
```

类似地，在第五行的跳转指令中，第二个字节：
```
	b:  7f f8
```
是0xf8，补码编码代表十进制的-8，该指令的下一条指令：
```
	d:  f3 c3
```
地址为0xd，即十进制13，13与-8相加就得到了0x5，即目的指令的地址（第三行）
```
	5:  48 d1 f8
```

由上可见，**执行PC相对寻址时，程序计数器的值是==跳转指令后面的那条指令的地址==，而非跳转指令本身的地址**（惯例）

使用PC相对的跳转目标编码，可以使得指令编码很简洁，而且目标代码不需要改变就能移动到内存的不同位置

### 3.6.5 用条件控制来实现条件分支
**将条件表达式和语句从C语言翻译为机器代码，最常用的方式是==结合有条件和无条件跳转==。** 
下图给出了计算两数之差绝对值函数，同时**会增加两个计数器lt_cnt和ge_cnt**的C代码：
![[Pasted image 20240829110342.png]]
它产生的汇编代码为：
```
long absdiff_se(long x, long y) 
x in %rdi , y in %rsi
absdiff_se:
	cmpq  %rsi,%rdi             比较x:y
	jge   .L2                   如果x>=y，goto至x_ge_y
	addq  $1,lt_cnt(%rip)       递增lt_cnt
	movq  %rsi,%rax             
	subq  %rdi,%rax             y - x
	ret
.L2:
	addq  $1,ge_cnt(%rip)      递增ge_cnt
	movq  %rdi,%rax
	subq  %rsi,%rax            x - y
	ret
```
它首先用x比较y，设置条件码。然后根据x是否大于等于y决定是否跳转

我们可以看到，**absdiff_se对应的汇编代码控制流很类似于图b的goto代码：**
使用goto语句通常被认为是不良的编程风格。在goto代码中，第5行的goto语句会导致跳转到第9行的x_ge_y处，相当于完成图a函数的else部分。

对于C语言的条件分支if-else语句：
```
if (test-expr)
	than-statement
else
	else-statement
```
汇编实现通常会使用如下**goto语句**行为类似的**控制流**：（用C代码描述机器代码）
```
t = test-expr;
if (!t)
	goto false;
then-statement
goto done;
false:
	else-statement
done:
```
**汇编器为than-statement和else-statement产生各自的代码块，插入条件和无条件分支来执行正确的那个。**

### 3.6.6 用条件传送来实现条件分支
条件分支的传统实现是==**控制==：满足条件时沿一条路径执行，不满足则换一条路径**。但比较低效
另一种替代策略是==**数据的条件转移==：计算一个条件操作的==两种结果==,然后再根据条件是否满足从两个结果中选择一个**。这种策略仅适用于一些受限制的情况
当可以使用替代策略时，我们就可以用一条简单的==**条件传送指令**==来实现
![[Pasted image 20240829222311.png]]
每条指令都有两个操作数：源寄存器或内存地址S和**目的寄存器**R，**指令的结果取决于条件码的值，满足要求时才会被复制到目的寄存器中**

下面的例子就是可以使用条件传送指令编译的函数。
图a是一个计算参数x和y之差的绝对值的C函数，和3.6.5的区别在于它**没有任何增加计数器的行为，只是单纯地返回结果值**：
![[Pasted image 20240830002741.png]]
图a产生的汇编代码为：
```
long absdiff(long x, long y) 
x in %rdi , y in %rsi
absdiff:
	movq   %rsi,%rax
	subq   %rdi,%rax        %rax中的值rval = y - x
	movq   %rdi,%rdx        
	subq   %rsi,%rdx        %rdx中的值eval = x - y
	cmpq   %rsi,%rdi        用x比较y
	cmovge %rdx,%rax        如果x>=y，把%rax的值rval替换为eval，反之不替换
	ret                     return %rax的返回值
```


**基于条件数据传送的代码会比基于条件控制转移的代码性能要好**。
这涉及到后面两章的知识：**处理器通过使用==流水线==来获得高性能。** 在流水线中，一条指令的处理经过一系列的阶段，每个阶段执行所需操作的一小部分，把各阶段重叠连续执行。
**流水线的工作基于对能够==事先确定要执行的指令序列==的要求，只有这样才能确保流水线中充满了待执行指令。** 处理器采用非常精密的==**分支预测逻辑**==来猜测每条跳转指令是否会执行，只要其猜测比较可靠（成功率90%以上）就能实现这一点。
这就导致了当机器遇到==**分支**==时，**只有当分支条件求值完成之后才能决定分支往哪边走**。
当错误预测一个跳转时，**处理器会被要求丢弃所有已做完的工作，从正确位置重新执行**，所以会导致程序性能严重下降。

在上面的示例中，x<y的结果非常不可预测，成功率低至约50%，**在两种操作计算量相差不大的情况下，分支预测的错误导致的性能下降是决定函数性能的主要因素**。
我们可以通过以下方式来确定分支预测错误的处罚：
$$ \begin{align*}
&假设预测错误的概率是p，无预测错误情况下的执行时间为T_{OK}，预测错误的处罚时间为T_{MP}\\
&那么，执行代码的期望时间:\\
&\quad \quad \quad \quad \quad \quad T_{avg}(p)=(1-p)T_{OK}+p(T_{OK}+T_{MP})=T_{OK}+pT_{MP}\\
&那么，已知T_{avg}(p)和T_{OK}，就可以计算出T_{MP}了
\end {align*} $$

与条件跳转不同，**处理器无需预测测试的结果就可以执行条件传送——它只需读源值、检查条件码、决定是否覆盖目的寄存器就行**，~~而条件跳转要考虑的就多了~~
```
条件跳转：                                      条件传送：
  if(!test-expr)                                    v = then-expr;
     goto false;                                    ve= else-expr;
  v = then-expr;                                    t = test-expr;
  goto done;                                        if(!t) v = ve;
false:
  v = else-expr;
done:
本质上是空间换时间的一般思想的体现
```

**并不是所有条件表达式都可以用条件传送编译**。条件传送的性质是**无论测试结果test_expr如何，它都会对then-expr和else-expr求值。如果两个表达式的任意一个可能产生错误条件或副作用，条件传送就是非法的。** 例如：
```
long cread(long *xp){
return (xp ? *xp : 0);
}
```
如果使用条件传送，当指针xp为空时，依然会对\*xp进行求值，导致解引用一个空指针，产生错误。
**条件传送的效率当然也受到计算量的影响：当两个表达式的求值需要大量计算时，就不会提高代码的效率了**。事实上，编译器只在两个表达式都很容易计算时才使用条件传送，这也是为什么说条件传送只用于部分情况

### 3.6.7 循环
汇编中没有相应的指令直接实现C语言的循环结构，但是可以**用条件测试和跳转组合起来实现循环的效果**。我们由浅入深地研究循环模式的汇编实现。

#### 1. do-while循环
do-while语句的通用形式：
```
do
	body-statement
while(test-expr);
```
效果为**重复执行body-statement，再对test-expr求值，如果test-expr结果非0，继续循环。body-statement至少会被执行一次。**
这种形式可以被翻译为以下的goto语句：
```
loop:
	body-statement
	t = test-expr;
	if(t)
		goto loop;
```
这就把循环变成了**低级的测试和条件跳转的组合**，看到以下计算阶乘n!的例子：
![[Pasted image 20240830232431.png]]
比较简单，不赘述，它产生的汇编代码：
```
long fact_do(long n) 
n in %rdi
fact_do:
	movl    $1,%eax              将result设置为1
.L2:
	imulq   %rdi,%rax            将result *= n
	subq    $1,%rdi              n = n - 1
	cmpq    $1,%rdi              用n比1，如果n>1，执行下面的跳转语句
	jg      .L2
	rep;ret
```
注意第二行movl代码的目的寄存器，虽然是%eax，但是实际上它还会把%rax的高4字节设置为0，然后该寄存器会在第四行中被乘法改变值，并作为返回值返回。

#### 2. while循环
while循环语句的通用格式：
```
while(test-expr)
	body-statement
```
它对于test-expr的求值在执行body-statement之前，所以有可能并不会执行body-statement
while循环的实现，GCC主要有两种方法，它们只在实现初始测试的方法上有不同：
##### a.跳转到中间策略实现
**它执行一个==无条件跳转==，跳到循环结尾处的测试，从而先执行第一个初始测试**：
```
	goto test;
loop:
	body-statement
test:
	t = test-expr;
	if(t)
		goto loop;
```

##### b. guarded-do策略实现
**首先使用条件分支：如果初始条件不成立就跳过循环，这样就可以套用do-while循环的代码了。** 该策略常用于较高优化等级的编译，例如**GCC命令行选项使用-01时就可以调用这种策略**。
```
t = test-expr;  
if(!t)
	goto done;
do
	body-statement
	while(test-expr)
done:
```
用do-while加上最初的条件判断，就可以实现while循环了
把do-while循环也翻译成goto语句：
```
t = test-expr;
if (!t) 
	goto done; 
loop: 
	body-statement
	t = test-expr; 
	if (t) 
		goto loop; 
done:
```

#### 3. for循环
for循环的通用格式为：
```
for(init-expr; test-expr; update-expr)
	body-statement
```
这样的循环的行为可以使用while循环实现（但有特例，后文详叙）
```
init-expr;
while(test-expr){
	body-statement;
	update-expr;
}
```
先求值初始表达式init-expr，再对test-expr进行求值，为真执行循环体body-statement，然后更新初始表达式，执行update-expr；test-expr为假退出循环。

根据优化等级，使用while循环的两种方法进行翻译得到如下goto代码：
```
跳转到中间策略：
	init-expr; 
	goto test;
loop: 
	body-statement 
	update-expr; 
test:
	t = test-expr; 
	if (t)
		 goto loop;

guarded-do策略：
	init-expr;
	t = test-expr; 
	if (! t) 
		goto done; 
loop : 
	body-statement 
	update-expr;
	t = test-expr; 
	if (t) 
		goto loop; 
done:
```
汇编代码的翻译逻辑和goto代码模板是差不多的，取决于使用哪个优化等级。

### 3.6.8 switch语句
switch语句根据一个整数索引值进行==**多重分支**==
这种语句使用一种称为==**跳转表**==的**数据结构**，**跳转表是一个数组，表项i是一个==代码段的地址==，该代码段实现当==开关索引值==等于i时所采取的行为**。
与一连串的if-else语句相比，跳转表的优点在于**执行开关语句的时间与开关情况的数量无关：GCC根据开关情况的数量和开关情况值的稀疏程度来翻译开关语句——当==开关数量比较多（大于4个）且值的范围跨度比较小时，使用跳转表进行翻译==**
下面是一个C语言switch语句的示例：
![[Pasted image 20240902111644.png]]
图a的switch语句有一个特征：情况标号不连续（100-102-103..），并且有些情况没有break（102），同时**情况104和情况106是相同的**
图b则用**扩展的C语言**描述了该代码翻译为汇编代码的行为：
第5行的数组jt包含7个表项，每一个表项**代表一个代码块的地址，由==代码指针==指明**，代码指针**由标号加上‘&&’前缀组成**（注意它和**右值引用**是两个概念）。GCC作者定义这样的运算符来**创建一个指向==代码位置==的指针**。
这样，我们就可以通过jt数组的索引来获取代码位置的指针，进而移动到相应位置。注意，**再有break的情况，扩展C代码有"goto done"来跳转到最后，反之则没有**
索引jt数组时，编译器首先将n减去100，范围移动至0到6之间，创建新变量index。由于**补码的负数会被映射为无符号表示的大正数，我们可以直接令index为无符号数来简化分支**。这样一来，通过检测index是否>6就可以检测出索引是否在0~6内，不在则跳转到default情况，在则根据具体值跳转至对应代码位置。
注意图b的jt数组构成：对于情况104和106，它们的**操作相同**，这样的重复情况的处理方法是**让这两个索引位置上的元素相同，都是&&loc_D**

该示例的汇编代码如下：
```
void switch_eg(long x, long n, long *dest) 
x in %rdi, n in %rsi, dest in %rdx
switch_eg:
	subq    $100,%rsi                 index = n - 100
	cmpq    $6,%rsi                   比较6和index
	ja      .L8                       如果>6，跳转到默认情况
#	jmp     *.L4(,%rsi,8)             跳转到*jt[index]，这一行是switch语句的关键
.L3:
	leaq    (%rdi,%rdi,2),%rax        loc_A的操作。有break
	leaq    (%rdi,%rax,4),%rdi
	jmp     .L2                       相当于goto done
.L5:
	addq    $10,%rdi                  loc_B的操作，无break

.....后面的都是类似的实现，.L8是default部分的代码实现，这里不多赘述......
```
**执行switch语句的关键步骤是通过跳转表来访问代码位置**。在汇编代码中，该操作在第5行'#'处。**jmp指令的操作数带有前缀‘\*'，代表这是一个==间接跳转==：操作数指定一个内存位置，索引由寄存器%rsi给出（代码中%rsi保存着index的值）**
C代码中跳转表被声明为具有7个元素的数组，元素是指向代码位置的指针。如前所述，**跳转表对重复情况的处理就是==简单地对有相同行为的表项使用同样的代码标号==；对有缺失情况的处理就是==对缺失的表项使用默认default情况的代码标号==**
汇编代码中，跳转表的声明：
```
	.section    .rodata
	.align 8     对齐指令，让后面的数据在内存中从8字节对齐的地址开始存储
.L4:
	.quad    .L3         定义一个八字节常量，存储标签.L3的地址，下同
	.quad    .L8
	.quad    .L5
	.quad    .L6
	.quad    .L7
	.quad    .L8
	.quad    .L7
```

**声明部分表明：在叫做".rodata"(只读数据read-only) 的目标代码文件的段中，一个有一组7个的"四字"（8字节数），它们是与指定汇编代码标号对应的==指令地址==**
指令.quad用于**定义一个八字节常量值**，并且把其后跟着的标签的地址存储进该常量值中
**标签.L4则给出了这段数组的首地址，作为jmp指令跳转的基地址**

总之，使用跳转表是一种非常有效的实现多重分支的方法，只需要引用一次跳转表就可以访问多个不同位置。

## 3.7 过程
过程是软件中的一种很重要的**抽象**，它提供了一种封装代码的方式：**用一组指定的参数和一个可选的返回值实现了某种功能，隐藏了该行为的具体实现，同时提供清晰简洁的接口**来说明计算哪些值，过程会对程序状态产生说明影响，从而**使得它能在程序不同位置被调用**
过程有很多形式：**函数、方法、子例程、处理函数......** 它们有一些共有特性

为便于讨论，**假设过程P调用过程Q，Q执行后返回到P**，这些动作可能包含以下机制：
* 1. ==**传递控制==：进入过程Q时，程序计数器必须被设置为Q的代码的起始地址，在返回时，又需要被设置为P中调用Q的指令的后一条指令的地址**

* 2. ==**传递数据==：P必须能够向Q提供一个或多个参数，Q必须能够向P返回一个值

* 3. ==**分配和释放内存==：当Q在开始时需要为局部变量分配空间时，它在返回前必须释放这些存储空间**
 我们一步步地构建起不同的机制：先描述控制，再描述数据传递和内存管理。

### 3.7.1 运行时栈：管理过程的存储空间
C语言的==**过程调用机制**==的一个关键特性在于：**使用了==栈数据结构==提供的==后进先出==的内存管理原则**
不难发现，在过程P调用过程Q时，P以及P向上追溯的所有调用链都是被“暂时挂起”的，Q只需要为局部变量分配内存，并在返回时释放它们。因此，**程序可以用栈来管理它的过程所需的==存储空间==**。
**x86-64中，==栈向低地址方向增长==，栈指针%rsp指向栈顶元素（存储其地址）**，可以使用指令pushq或popq将数据存入栈中或弹出栈。**将栈指针适当减小，相当于让栈向低地址方向增长，这样可以为==没有指定初始值的数据==在栈上==分配空间==；同理，适当增加栈指针可以释放栈空间**。

**过程的==栈帧==：当过程需要的存储空间超过寄存器能够存放的大小时，就会在栈上分配空间。**
**运行时栈的通用结构：
* **1. 当前执行的过程的帧总是在栈顶**

* **2. 当过程P调用Q时，会把==返回地址==压入栈中，指明当Q返回时，要从P的哪个位置继续执行**。**返回地址是P的栈帧的一部分，因为它存放的是P相关的状态**

* **3. 当过程P调用Q时，Q的代码会扩展当前栈的边界，分配Q的栈帧所需的空间**。该空间可以用于保存寄存器的值、分配局部变量的空间、为Q所调用的过程设置参数......

* **4. 只通过寄存器，过程P最多可以向Q传递6个指针和整数值；如果P在调用Q之前在自己的栈帧中进行存储，就可以为Q提供更多参数**

* **5. 过程只分配自己所需要的栈帧部分：局部变量尽量保存在寄存器中，当寄存器可以储存一个过程的所有局部变量，且它不会调用其他任何过程时甚至不需要栈帧**
![[Pasted image 20240902211410.png]]

### 3.7.2 转移控制
**将控制从过程P转移到过程Q，只要简单地把==程序计数器PC==设置为Q的代码的起始位置，并且从Q返回时，处理器必须记录好它需要继续P的执行的代码位置**。
x86-64机器中，上述信息是使用 **指令call Q**来调用过程Q来记录的：**call指令会把==地址A==压入栈中，并将PC设置为Q的起始地址**
**压入的地址A称为==返回地址==，是==紧跟在call指令后的那条指令的地址==**。
**指令ret**则用于**将地址A从栈中弹出，并且把PC设置为A**
![[Pasted image 20240903145318.png]]
(OBJDUMP的这些指令会在结尾增加'q'的后缀)

call指令的作用在于**指明被调用过程起始的指令地址，这个调用可以是直接的，也可以是间接的。**
**汇编代码中，==直接调用==的目标是一个标号；而==间接调用==的目标是'\*'后面跟一个操作数指示符（见3.4.1节）**

以3.2.2节中的代码示例multstore和main函数的执行情况为例：
```
#include <stdio,h>
long mult2(long a, long b){
long s = a * b;
return s;
}

void multstore(long x, long y, long *dest){
long t = mult2(x, y);
*dest = t;
}

int main(){
long d;  multstore(2, 3, &d);
printf("2*3--> %ld\n", d);
return 0;
}
```

multstore和main生成的**反汇编代码**（节选）：
```
multstore:
0000000000400540 <multstore>:
	400540:  53            push  %rbx
	400541:  48 89 d3      mov   %rdx,%rbx
. . .
	40054d:  c3            retq

main:
	400563:  e8 d8 ff ff ff       callq  400540 <multstore>
	400568:  48 8b 54 24 08       mov    0x8(%rsp),%rdx
```
在main函数中，地址为0x400563的callq指令调用了函数multstore，该指令的返回地址为0x400568，**call将它压入栈中，并且跳转到函数multstore的第一条指令**；当执行到0x40054d处的ret指令时，**将地址0x400568从栈中弹出，存入==程序计数寄存器%rip==，继续main函数的执行**，如图：
![[Pasted image 20240903152515.png]]
可以看到栈顶指针寄存器rsp中地址的改变：先变低，再在ret执行后变回去

作为另一个示例，**下面是用参数值100调用函数top，同时top内又用参数95调用函数leaf，最后返回值**的代码执行过程，**注意它们PC寄存器、栈顶指针寄存器%rsp的地址及%rsp所存储的地址值、返回值寄存器%rax的值的变化**：
![[Pasted image 20240903154419.png]]

可以看见C语言及大多数程序语言标准的调用和返回机制与栈后进先出的内存管理方法是相吻合的。

### 3.7.3 数据传送
当调用一个过程时，除了控制的传递之外，还可能有**把数据作为参数进行传递，或者从过程中返回一个值**的行为。x86-64中，**大部分过程间的数据传送都是通过==寄存器==实现的**，上面3.7.2最后的例子就体现了这一点。
当过程P调用过程Q时，**P的代码必须首先把参数复制到合适的寄存器中**；当从过程Q返回到过程P时，**返回值储存在寄存器%rax中并能被P的代码访问。**

x86-64中，**最多可以通过寄存器传递6个整型（整数、指针..）参数，注意寄存器的名字取决于要传递的数据类型的大小，用于传递函数参数的寄存器如下**:
![[Pasted image 20240903160934.png]]
机器根据**参数在参数列表中的顺序**来分配寄存器。可以通过完整寄存器的适当部分来访问小于64位的参数，上图操作数大小就说明了可以用哪些部分访问最多几位的参数。

**当函数有大于6个的整型参数时，==超出6个的部分==就要通过==栈==来传递。** 
假设过程P调用过程Q，有$n>6$个整型参数，那么**P的代码分配的栈帧必须要能容纳第7到n号参数的存储空间**，把第1到6号参数复制到对应寄存器，其他放到栈上
**使用栈传递参数时，==所有的数据大小都会向8字节的倍数对齐**==，参数传递完成后就可以执行call指令把控制传递给过程Q了。
**“所有数据大小都会向8字节的倍数对齐”的含义是：==通过栈进行参数传递，无论数据大小是多少，它们都会占用8字节的空间==**

以下面的C代码为例：
```
void proc(long a1, long *a1p, int a2, int *a2p, short a3, short *a3p, char a4, char *a4p) {
*a1p += a1; 
*a2p += a2;
*a3p += a3; 
*a4p += a4;
}
```
它有8个参数，第7和第8个参数通过栈传递，**栈传递的参数地址可以通过栈指针寄存器%rsp所保存的地址(%rsp)得到**，因此该函数生成的汇编代码：
```
参数的传递存储过程如下：
寄存器：
a1  in  %rdi    (64位)
a1p in  %rsi    (64位)
a2  in  %edx    (32位)
a2p in  %rcx    (64位)
a3  in  %r8w    (16位)
a3p in  %r9     (64位)
栈：
a4  at  %rsp+8  (8位)    注意：所有的数据大小都向8字节的倍数对齐，因此是偏移8字节
a4p ai  %rsp+16 (64位)   同理，a4p大小也向8字节对齐，偏移16字节得到
proc:
	movq    16(%rsp),%rax            将a4p(指针值，即一个地址)移动到寄存器%rax备用
	addq    %rdi,(%rsi)              *a1p += a1
	addl    %edx,(%rcx)              *a2p += a2
	...... 下面都类似，使用对应的add指令储存到(存储对应指针的寄存器名) ......
	movl    8(%rsp),%edx             获取a4，它从内存中读入4字节到%edx
	addb    %dl,(%rax)               但8位的a4只占1字节，使用%edx的低位寄存器%dl
	ret
```

![[Pasted image 20240903164648.png]]
**栈帧是在内存中的，所以要用(%rsp)的形式通过栈顶指针储存的内存地址进行帧内元素的访问**

### 3.7.4 栈上的局部存储
以下情况中，**局部数据必须存放在内存中：**
* **1. 寄存器不足以存放所有本地数据**
* **2. 对一个局部变量使用取地址符‘&’，因此必须为它产生一个地址
* **3. 某些局部变量是数组或结构体，必须能被通过数组或结构引用访问到**

**过程通过减少栈指针来在栈上分配空间，分配的结果作为栈帧的一部分，标为==局部变量==**

以以下C代码为例：
![[Pasted image 20240903170338.png]]
函数swap_add交换两个指针指向的值，并且返回这两个值之和。函数caller则创建了**局部变量arg1和arg2**，把它们的地址（指针）传递给swap_add

下面是函数caller的汇编代码：
```
caller:
	subq      $16,%rsp      首先将栈指针减去16，即在栈上分配了16字节的空间，用于存储两个值（8字节对齐导致每个值无论大小都占8字节空间）
	movq      $534,(%rsp)   把值534存储到相对栈指针偏移量为0的地方arg1
	movq      $1057,8(%rsp) 把值1057存储到相对栈指针偏移量为8的地方arg2
	leaq      8(%rsp),%rsi  计算内存地址&arg2，存到%rsi中
	movq      %rsp,%rdi     arg1和栈指针无偏移，栈指针存储的地址就是&arg1，存到%rdi
	call      swap_add      调用swap_add(&arg1, &arg2)
	movq      (%rsp),%rdx   获取arg1
	subq      8(%rsp),%rdx  计算diff = arg1 - arg2
	imulq     %rdx,%rax     计算sum * diff，%rax存储函数swap_add的返回值sum
	addq      $16,%rsp      把栈指针加回16，释放分配的空间
	ret
```
所有代码的含义见右侧注释。可见运行时栈提供的对局部存储的分配与释放机制是通过栈指针的加减实现的。

### 3.7.5 寄存器中的局部存储空间
**寄存器组是唯一==被所有过程共享==的资源**，尽管**在给定时刻只有一个过程是活动的**，我们仍然需要保证**当一个过程（调用者）调用另一个过程（被调用者）时，被调用者不会覆盖调用者==稍后==会使用的寄存器值**。
为此，x86-64采用了一组统一的**寄存器使用惯例**，所有过程和程序库都必须遵循。

惯例中，**寄存器==%rbx、%rbp和$r12~%r15==被划分为==被调用者保存寄存器==**。当过程P调用过程Q时，**Q必须保存这些寄存器的值，保证它们的值在Q返回到P时与Q被调用时是一样的**。
过程Q保持一个寄存器的值不变的方法，**要么是根本不去改变它，要么就是把原始值==压入栈中==，按自己的需求改变寄存器值，在返回前==把原始值从栈中弹出==，压入寄存器**。这部分的值会在**栈帧**中创建标号为”**保存的寄存器**“的一部分，即3.7.1节的图3-25的这一部分：
![[Pasted image 20240905141310.png]]
**该惯例保证了==调用者==能够安全地把值存放在==被调用者保存寄存器==中，在调用被调用者后依然能继续使用它们**。

另外，**所有其他的寄存器（除了栈指针%rsp），都被分为==调用者保存寄存器==**。**所有的函数都能修改调用者保存寄存器**，可以这么理解”调用者保存“：因为所有函数都能修改这些寄存器的值，所以**如果调用者在这些寄存器中有局部数据存储，那就应该另外保存它们**。

以下面的代码为例，函数P两次调用函数Q：
```
long P(long x, long y){
	long u = Q(y);
	long v = Q(x);
	return u+v;
}
```
在第一次调用时，传递参数y的同时过程P还需要保存x的值以供使用；在第二次调用时，过程P则需要保存Q(y)的值以供返回。它生成的汇编代码：
```
long P(long x, long y) 
x in %rdi , y in %rsi
P：
	pushq  %rbp         将寄存器rbp的值压入栈中存储，腾出空间存x
	pushq  %rbx         将寄存器rbx的值压入栈中存储，腾出空间存Q(y)，被调用者寄存器
	subq   $8,%rsp      ”8字节对齐“，在栈上创建8字节的存储空间，保证数值安全存储
	movq   %rdi,%rbp    存储x入rbp
	movq   %rsi,%rdi    把y移动到第一个参数位置
	call   Q            调用Q(y)
	movq   %rax,%rbx    把rax中的返回值存入rbx
	movq   %rbp,%rdi    把x重新移回第一个参数位置
	call   Q            调用Q(x)，返回值在%rax中
	addq   %rbx,%rax    Q(y)+Q(x)，存入%rax中
	addq   $8,%rsp      释放栈上的临时空间，为弹出数值做准备
	popq   %rbx         后进先出，将后压入栈中的%rbx的原值弹回%rbx
	popq   %rbp         同理把%rbp的原值弹回去
	ret
```
最后的弹出顺序与压入顺序相反，subq指令在栈上分配额外的内存空间，保证安全存储的同时让栈有额外空间能使用。这说明了栈的后进先出原则。

### 3.7.6 递归过程
前面的寄存器和栈的惯例使得x86-64过程能够**递归地调用它们自身**：**每个过程调用在栈中都有它自己的==私有空间==，因此==多个未完成调用的局部变量不会相互影响==**。而且栈的性质为此提供了策略：在过程被调用时分配局部存储，返回时释放存储

下面是一个递归求阶乘函数的C代码：
```
long rfact(long n){
	long result;
	if(n <= 1)
		result = 1;
	else
		result = n * rfact(n-1);
	return result;
}
```
来看看汇编代码是怎么翻译的：
```
long rfact(long n) 
n in %rdi
rfact:
	pushq    %rbx          把rbx寄存器的原值压入栈中储存
	movq     %rdi,%rbx     把n储存入 被调用者寄存器rbx
	movl     $1,%eax       把rax低位寄存器储存的返回值设置为1
	cmpq     $1,%rdi       用n比较1
	jle      .L35          若n<=1，跳转到结束
	leaq     -1(%rdi),%rdi 计算n-1，覆盖n
	call     rfact         *递归调用rfact(n-1)*
	imulq    %rbx,%rax     result = result*n
.L35:
	popq     %rbx          弹出%rbx的原值
	ret
```
从这个例子可以看出，**递归调用一个函数本身与调用其他函数是一样的**，栈规则提供了一种机制：**每次函数调用都有它自己==私有的状态信息储存空间（保存返回位置和被调用者保存寄存器的值）==，并且可以提供局部变量的存储（栈分配和释放的顺序可以与函数调用顺序匹配**。
这种机制可以适用于更复杂的情况，例如P调用Q，Q调用P这样的**相互递归调用**

## 3.8 数组分配和访问
C语言中的数组是一种**将标量数据聚集成更大数据类型的方式**，实现数组的方法很简单，且容易翻译为机器代码。**C语言允许产生指向数组中元素的指针（迭代器）并进行运算，在机器代码中，它们会被翻译为地址计算**

### 3.8.1 基本原则
对于数据类型T和整数常量N，数组声明为
```
T A[N]
```
数组的起始位置表示为$x_A$。这个声明产生两个效果：
**首先，在内存中分配一个L\*N个字节的==连续区域==，L是数据类型T的大小（单位为字节）**；**其次，它引入==标识符A==，可以用A作为指向数组开头的指针，指针值就是$x_A$。**
可以用0~N-1的整数索引来访问数组的元素，**数组元素i会被存放在地址为$x_A+L*i$的地方**

x86-64的**内存引用指令**可以简化数组的访问。例如：假设E是一个int型数组，我们想计算E\[i]，E的地址存放在寄存器%rdx，而i存放在寄存器%rcx。
那么地址$x_E+4i$就可以用指令计算为：
```
movl    (%rdx, %rcx, 4), %eax
```
并且存入寄存器eax中，**第三项的==伸缩因子==只能取1、2、4和8，但是足够覆盖所有基本简单数据类型**

### 3.8.2 指针运算
C语言允许对指针进行计算，**计算出来的值会根据该指针引用的数据类型大小进行==伸缩==：如果p是一个指向类型为T的数据的指针，其值为$x_P$，那么表达式$p+i$的值为$x_P+ L*i$，L是数据类型T的大小**
单操作数操作符'&'和'\*'可以**产生指针和间接引用指针**，Expr与\* &Expr是等价的
可以对数组和指针应用**下标操作**：**A\[i]等同于表达式\*(A+i)**

假设整型数组E的起始地址和整数索引i分别存放在寄存器%rdx与%rcx中，下面是关于E的表达式及汇编代码实现——如果结果是数据，存放在%eax中；如果是指针，存放在%rax中：
![[Pasted image 20240905162601.png]]
返回类型为地址（8字节）的表达式所用指令为'q'结尾；为int（4字节）的表达式指令则为'l'结尾
最后一个式子表明**可以计算同一个数据结构中的两个指针之差，结果类型为long，值等于==两个地址之差除以该数据类型的大小==**

### 3.8.3 嵌套数组
当我们创建**数组的数组**时，数组分配和引用的一般规则也成立。例如声明：
```
int A[5][3];
```
等价于声明：
```
typedef int row3_t[3]
row3_t A[5];
```
这里数据类型row3_t被定义为一个储存3个整数的数组，数组A包含5个这样的元素，每个元素需要12字节来储存这3个整数，整个数组大小为4\*5\*3=60字节
数组A也能被视为一个5行3列的二维数组，引用从A\[0]\[0]到A\[4]\[2]。**数组元素在内存中按照==行优先==的顺序排列：第0行的所有元素就是A\[0]**：
![[Pasted image 20240905164316.png]]
访问多维数组的元素，**编译器会以数组起始为基地址，可能需要进行伸缩的偏移量为索引，产生计算所希望的元素的偏移量，然后使用某种==MOV指令==**。通常，对于如下声明的数组：
```
T D[R][C]
```
它的数组元素D\[i]\[j]的内存地址为：
$$ \&D[i][j] = x_0 + L(C*i+j) $$
L是数据类型T以字节为单位的大小

例如，考虑前面的5\*3的整型数组A，假设$x_A、i和j$分别储存在寄存器%rdi、%rsi和%rdx中，可以使用以下代码将数组元素A\[i]\[j]复制到寄存器%eax中：
```
A in % rdx, n %rsi, and j in %rdx
	leaq    (%rsi, %rsi, 2), %rax         计算3i
	leaq    (%rdi, %rax, 4), %rax         计算x_A+12i
	movl    (%rax, %rdx, 4), %eax         读取M[x_A+12i+4j]，储存到%eax
```
这段代码计算地址的方式就是$x_A+4(3i+j)=x_A+12i+4j$。

### 3.8.4 定长数组
C语言编译器能够**优化定长多维数组上的操作代码**，当优化等级设置为-01时GCC采用的优化：
假设我们用如下方式将数据类型fix_matrix声明为16\*16的整型数组：
```
#define N 16
typedef int fix_matrix[N][N];
```
（**当程序要用一个常数作为数组的维度或缓冲区的大小时，最好通过\#define声明来将该常数与一个名字联系，并在之后只使用这个名字代替常数，这样便于修改**）
那么下面的C代码：
```
int fix_prod_ele(fix_matrix A, fix_matrix B, long i, long k){
	long j;
	int result = 0;

	for(j = 0; j < N; j ++)
		result += A[i][j] * B[k][k];
	return result;
}
```
该代码计算矩阵A的行i与B的列k的内积，GCC产生的代码所做的优化如下面的代码：
```
int fix_prod_ele_opt(fix_matrix A, fix_matrix B, long i, long k){
	int *Aptr = &A[i][0];
	int *Bptr = &B[0][k];
	int *Bend = &B[N][k];
	int result = 0;
	do{
		result += *Aptr * *Bptr;
		Aptr ++;
		Bptr += N
	} while (Bptr != bend);
	return result;
}
```
该函数**去掉了整数索引j，并把所有的数组引用都转换为了==指针间接引用==** ：
* 生成指针Aptr，指向A的**行i中的连续元素**
* 生成指针Bptr，指向B的**列k中的连续元素**
* 生成指针Bend，作为循环结束的标志指针
这样优化的优势在于**通过把索引计算转换为对指针的计算，减少了对数组元素位置的计算量（只需要+=就行），而且使用指针操作更好地利用了CPU的缓存机制**，**==指针算术操作比索引操作更高效==**

生成的汇编代码：
```
int fix_prod_ele_opt (fix_matrix A, fix_matrix B, long i, long k) A in %rdi, B in %rsi, i in %rdx , k in %rcx
fix_prod_ele_opt:
	salq    $6,%rdx             计算64*i
	addq    %rdx,%rdi           计算Aptr=x_A + 64i = &A[i][0]
	leaq    (%rsi,%rcx,4),%rcx  Bptr=x_B+4k=&B[0][k]
	leaq    1024(%rcx),%rsi     计算Bend
	movl    $0,%eax             result初始值为0
.L7:
	movl    (%rdi),%edx         读取*Aptr
	imull   (%rcx),%edx         *Aptr * *Bptr
	addl    %edx,%eax           结果加到result中
	addq    $4,$rdi             Aptr++
	addq    $64,%rcx            Bptr+=N
	cmpq    %rsi,%rcx          比较Bptr与Bend
	jnq     .L7                条件跳转，不等于时跳转
	rep; ret
```

### 3.8.5 变长数组
C语言最开始只支持**大小在编译时就能确定的多维数组**，程序员需要使用变长数组时只能用`malloc`或`calloc`函数为数组分配存储空间；同时显式编码，**用行优先索引将多维数组映射至一维数组**，即前面的：
$$ \&D[i][j]=x_0 +L(C*i+j)$$

在ISOC99中，引入了**允许数组的维度是==表达式==，在数组被分配的时候计算出来**的功能，即我们可以把一个数组声明为：
```
int A[expr1][expr2];
```
它可以作为一个**局部变量**或一个**函数的参数**，在遇到该声明时**通过对表达式expr1和expr2求值来确定数组维度**，例如：
```
int var_ele(long n, int A[n][n], long i, long j){
	return A[i][j];
}
```
这里**参数n必须在A\[n]\[n]之前，因为这样才可以计算出数组的维度**
GCC为该代码生成的汇编代码为：
```
int var _ele (long n, int A [n] [n], long i, long j) 
n in %rdi, A in %rsi, i in %rdx, j in %rcx
var_ele:
	imulq   %rdx,%rdi            计算n*i
	leaq    (%rsi,%rdi,4),%rax   计算x_A+4(n*i)
	movl    (%rax,%rcx,4),%eax   读取M[x_A+4(n*i)+4j]
	ret
```
与定长数组的区别在于，**由于n是参数，所以编译器使用了乘法指令imulq来计算n\*i，而非直接leaq计算**。尽管leaq指令一系列的移位与加法比起乘法指令性能要高上许多，但**动态的版本必须使用乘法指令来对i伸缩n倍**

当**在循环中使用变长数组**时，编译器可以利用**访问模式的规律性**对索引的计算进行优化，以下面计算n\*n矩阵A和B第i行和j列点积的C代码为例：
```
int var_prod_ele(long n, int A[n][n], int B[n][n], long i, long k){
	long j;
	int result = 0;

	for(j = 0; j < n; j++)
		result += A[i][j] * B[i][j];

	return result;
}
```
优化后模式的C代码：
```
int var_prod_ele_opt(long n, int A[n] [n], int B[n] [n], long i, long k) {
	int *Arow = A[i];
	int *Bptr = &B[0][k];
	int result= 0; long j; 
	for (j = 0; j < n; j++) { 
		result+= Arow[j] * *Bptr; 
		Bptr += n; }

	return result; 
```
代码**保留了循环变量j来判断循环是否结束以及进行索引**，其他与定长数组的代码相差不大。这并非定长与变长数组的差别造成的不同，而更多是编译器选择的结果
这里的规律性和定长数组差不多，都体现在**Bptr每次更新的步长**上
汇编代码：
```
Registers: n in %rdi, Arow in %rsi, Bptr in %rcx，4n in %r9, result in %eax, j in %edx
.L24:
	movl    (%tsi,%rdx,4),%r8d    读取Arow[j]
	imull   (%rcx),%r8d           用*Bptr乘Arow[j]
	addl    %r8d,%eax             加到result中
	addq    $1,%rdx               j ++
	addq    %r9,%rcx              Bptr+=n
	cmpq    %rdi,%rdx             用j去比较n
	jnq     .L24                  如果j!=n,跳转到.L24
	ret
```
使用了寄存器%r9储存了4n这个值，%rdi储存n值，方便指针运算使用。可见**GCC在优化过程中识别出来程序访问多维数组元素的==步长==，然后生成基于指针（定长数组）或数组（变长数组）的乘法以提高性能**

## 3.9 异质的数据结构
C语言提供了两种**将==不同类型的对象==组合到一个数据类型的机制**：**结构，使用`struct`声明，允许将多个对象集合到一个单位**；**联合，使用`union`声明，允许用几种不同类型来==引用==一个对象**

### 3.9.1 结构：分用同一块内存
`struct`声明创建一个数据类型，将可能不同类型的对象聚合到一个对象中，用**名字**来引用结构的各个组成部分。
类似数组，**结构的所有组成部分也都存放在内存中一段==连续区域==内，指向结构的指针就是==结构第一个字节的地址==**
编译器维护关于每个结构类型的信息，指示每个**字段**的**字节偏移**，以这些偏移作为**内存引用指令中的位移**，进而产生对结构元素的引用

C语言不像cpp和java，**在结构体中没有可调用的==方法==**，而是简单地写为接受一个结构体指针的函数：
```
long area(struct rect *rp)
```

考虑下面的结构声明：
```
struct rec {
	int i;
	int j;
	int a[2];
	int *p;
};
```
它包括四个==**字段**==：两个4字节int，一个由int组成的两个元素的数组和一个8字节整型指针，总共4+4+4\*2+8=24字节：
![[Pasted image 20240908130811.png]]
**数组a是嵌入到该结构中的**
为了访问结构的字段，编译器产生的代码要对结构的地址加上适当**偏移**，例如当我们想将struct rec\*类型的变量r中的元素r->i复制到r->j时：
```
	r in %rdi
	movl    (%rdi),%eax       从内存中获得r->i (元素i在结构体中位于偏移量0的位置)
	movl    %eax,4(%rdi)      4(%rdi)是r->j在内存中的位置，偏移量为4，把i复制到j处
```
可见，要产生一个**指向结构体内部的指针**，只需要**将结构的==首地址==加上该字段的==偏移量==即可**
例如，指针&(r->a\[1])就是结构首地址加上偏移量4+4+4\*1=12得到的
**结构的各个字段的选取==完全是在编译时处理的==，机器代码并不包含字段的声明或其名字的信息**

### 3.9.2 联合：共用同一块内存
联合提供了**允许以多种类型来引用一个对象**的方式，其语法和结构的差不多，但是是**用不同的字段来引用相同的内存块**
考虑以下声明：
```
union U3{
	char c;
	int i[2];
	double v;
};
```
以及相似的结构声明:
```
struct S3{
	char c;
	int i[2];
	double v;
};
```
联合和结构在x86-64机器上的字段偏移量完整大小表示则如下：
![[Pasted image 20240908133302.png]]
我们发现，联合体U3的**所有数据成员引用的都是数据结构的首地址**，并且**联合的总大小等于它的==最大字段==的大小**

#### 1. 用联合节省空间
联合的本质是**绕过C语言类型系统提供的安全措施**，因此可能会引发一些错误
一种应用场合是**我们事先知道一个数据结构中的两个不同字段的使用互斥**，这时单独把这两个字段设置为联合就可以减少分配空间的总量。
一个例子是二叉树的内部节点：如果把每个内部结点声明为struct，那么每个结构会有指向左右儿子的指针，因为**两个指针只会被用到一个**，这样会浪费一个指针的字节
此时声明为联合就节省了空间：
```
union node_u {
	struct {
		union node_u *left;
		union node_u *right; } internal;

	double node_data;
}
```
用`n->node_data`获得节点的数据，而用`n->internal.left`或`n->internal.right`来得到该节点左右儿子的地址
但是这也有一个弊端：**无法确定一个给定节点是叶子节点（树最底层的没有儿子的节点）还是内部节点**。
通常的解决办法是**引入一个==枚举类型==，定义为联合中可能的不同选择情况，把标签字段和联合定义到一个结构中去：**
```
typedef enum {N_LEAF, N_INTERNAL} nodetype_t;
// enum定义枚举类型：给一组相关的常量命名，这里常量N_LEAF和N_INTERNAL代表叶节点和内部结点，分别被默认赋值为0和1，可以在代码中标志状态

struct node_t {
	nodetype_t type;  //标签字段的定义
	union {
		struct {
			struct node_t *left;
			struct node_t *right;
			}internal;
		double node_data;
	} info;
};
```
这里type字段需要4字节，info.internal.left和info.internal.right各需要8字节（16字节），或者联合体info内部的info.node_data需要8字节。而且后面会知道**type和联合的元素之间需要4字节的填充**，一共需要4+16\*1+4=24字节。
这种情况下，使用联合带来的节省较少，但是对于**字段较多的数据结构**，这样的节省还是比较吸引人的

#### 2. 用联合访问不同数据类型的位模式
当将一个`double`类型的值d强制类型转换为`unsigned long`类型的值u时，u会是d的整数表示，除了`d=0.0`的情况以外，它们的位模式都会有很大不同
考虑以下代码：
```
unsigned long double2bits(double d){
	union {
		double d;
		unsigned long u;
		} temp;
	temp.d = d;
	return temp.u;
};
```
这里使用联合储存d和u，**它们共享的是同一块内存，因此当我们在`temp.d = d;`中储存了传入的d后，==它的位模式就被存储在内存的这块区域了==**
在返回值中，我们返回`temp.u`，由于u和d是同一块内存，**u包含了d的二进制位表示**，所以**返回的`temp.u`实际上是d在内存中的二进制位模式的unsigned long形式，==没有被取整等机制损失位表示==**
总而言之，**使用联合访问数据类型的位模式的技巧来自==联合中的成员共享同一块内存地址**==，在强制类型转换会损失信息的情况下，这种方法能有效地得到其最初始的底层位模式

**当用联合把不同大小的数据类型结合在一起时，==字节的顺序==就很重要了**：
```
double uu2double(unsigned word0, unsigned word1){
	union {
		double d;
		unsigned u[2];} temp;

	temp.u[0] = word0;
	temp.u[1] = word1;
	return temp.d;
}
```
这个函数**将传入参数的底层位表示结合在一起，拼出一个double值d。**
而**当机器采用小端法时，参数word0由于在==u\[0]==中存储，==位于低位==，是d的低位4字节位表示；而word1则是高位4字节位表示；如果是大端法机器，则word1是低位，word2是高位**

### 3.9.3 数据对齐
许多计算机系统对**基本数据类型的合法地址**做出了限制，**要求某种类型对象的地址必须是某个值K（通常为2、4或8）的倍数**。
这样的==**对齐限制**==有利于**简化**形成处理器和内存系统之间的**接口的硬件设计**，比如：如果一个处理器总是从内存中取8个字节，那么如果我们能保证某数据类型的地址对齐为8个字节，就可以只通过一次内存访问来读写值了，不必再执行多次

对齐数据以提高内存系统的性能，对其原则是**任何K字节的基本对象的地址必须是K的倍数**，这条原则导出了如下的对齐：
![[Pasted image 20240908150929.png]]
**确保每种数据类型都按照指定方式来组织和分配，即每种类型的对象都满足它的对齐限制就能保证对齐的实施了。**
在汇编代码中，放入以下命令就可**指明全局数据需要按什么方式对齐**：
```
.align 8     #按8字节方式对齐
```
这保证了**该命令后面的数据的==起始地址==是8的倍数，既然起始地址是8的倍数，后面的元素的大小自然遵守8字节对齐**
在包含结构的代码中，编译器可能会**在字段的分配中插入==间隙==**，以保证每个结构元素都满足编译器的对齐需求和结构体的首地址需求：
```
struct S1{
	int i;
	char c;
	int j;
};
```
如果只按照各个成员的大小分配内存：
![[Pasted image 20240908152125.png]]
这不满足字段i和j的4字节对齐要求，因此需要在c和j之间插入一个3字节间隙：
![[Pasted image 20240908152231.png]]
这保证了p->i和p->j满足地址的4字节对齐要求。

同理，编译器有时会**在结构的末尾加入一些==填充==**，以满足对齐要求：
```
struct S2{
	int i;
	int j;
	char c;
};
```
这个结构体按照9=4+4+1字节的方式分配内存是可以满足对齐需求的，但是如果生成该结构的数组：
```
struct S2 d[4];
```
由于一个S2占9字节的话，无法保证对d的每个元素都完成对齐（多了个1），此时**编译器为结构分配一些“浪费的空间”，这些==填充==保证了数组元素的对齐：**
![[Pasted image 20240908152742.png]]
这样一来d的四个元素的首地址为$x_d、x_d+12、x_d+24和x_d+36$，满足对齐要求

## 3.10 在机器级程序中结合控制与数据
本节的重点在于**数据和控制的交互方式**，首先我们需要深入理解指针的概念，并一步步学习后面的内容
### 3.10.1 理解指针
指针作为C语言的核心特色，**以一种统一的方式对不同数据结构中的元素产生引用**，我们重点介绍一些指针和它们映射到机器代码中的关键原则：
- **每个指针都对应一种类型，表明该指针指向哪一类对象。** 通常，如果对象类型为T，则指针类型为T\*，一个特殊的是void\*类型代表的**通用指针**，它可以**被显式强制类型转换或赋值操作那样的隐式强制类型转换转换为有类型指针**。***指针类型并不是机器代码的一部分，只是C语言提供的抽象***
- 每个指针都有一个代表某指定类型对象的地址的值，NULL则表示没有指向任何地方

- 指针使用 **‘&’取地址运算符** 创建，可以应用到**左值类的C表达式**上，例如变量以及数据结构的元素。**机器指令leaq设计用于计算内存引用地址，取地址运算符的机器代码实现往往就是用它来计算表达式的值**

- 解引用操作符'\*'用于间接引用指针，其结果是一个类型与该指针一致的值。**间接引用是通过内存引用实现的，要么是存储到一个指定地址，要么是从指定地址读取**

- **数组的名字可以像指针变量一样引用，但不可修改**。数组引用a\[i]和指针引用以及间接引用\*(a+3)的效果是一样的。**数组引用与指针运算都需要用对象的大小进行偏移量的伸缩**：对于指针值p，p+i得到的地址计算为$p+L*i$，L是与p相关联的数据类型的大小
- **将指针从一种类型强制转换到另一种类型，只改变其类型而不改变其值**。但是注意，这样的强制类型转换的一个效果是**会改变指针运算的伸缩，即上面的L**

- **指针也可以指向函数**，这提供了很强大的存储并向代码传递引用的功能：这些引用可以被程序的其他部分调用
  例如，`int fun(int x, int *p)`这个函数，我们可以声明一个这样的指针fp：`int (*fp)(int, int*)`
  然后令`fp = fun`
  我们就可以直接用该指针调用函数了：
  ```
  int y = 1;   int result = fp(3, &y);
  ```
  **一个函数指针的值是==该函数的机器代码表示中的第一条指令的地址==**

### 3.10.2 应用：使用GDB调试器
GNU的调试器GDB提供了很多有用的特性，支持机器级程序的运行时评估与分析
GDB允许我们观察正在运行的程序并控制程序的执行，使我们能研究程序的行为
对于文件prog，我们使用下面的指令运行GDB：
```
34382@Normist MINGW64 /d/codecode
$ gdb prog
```
下面是一些常用的GDB指令：
![[Pasted image 20240908165953.png]]
通常的方法是**在程序相应位置设置断点**，可以在程序的**函数入口后**设置断点：
```
break func_name  #在func_name函数的入口处设置断点 
```
或者在希望的行号处设置断点：
```
break prog.c:42   #在文件prog.c的42行处设置断点
```
或者在满足条件的时候设下断点：
```
break prog.c:42 if expr  #当expr为真时设置断点
```

gdb有一个拓展ddd，提供了调试的图形用户界面，但是并不支持windows操作系统使用，因为gdb看不懂microsoft编译器的调试信息？
![[Pasted image 20240909194202.png]]
事实上，这句话对于gdb调试器本身也适用：gdb在windows上虽然可以使用，**但功能和表现可能不如unix系统中强大**， 老老实实用visual studio吧
### 3.10.3 内存越界引用和缓冲区溢出
C语言**对于数组引用不进行任何边界检查**，并且**局部变量和状态信息**（比如已保存的寄存器值和返回地址）**都存放在栈中**，这就导致**对越界的数组元素进行写操作会破坏存储在栈中的状态信息，当程序使用这样的状态试图重新加载寄存器或ret时**，就会产生严重的错误

缓冲区指的是**一个用于临时存储数据的内存区域，包括栈缓冲区和堆缓冲区**
一种常见的状态破坏就是**缓冲区溢出：通常在栈中分配一个字符数组来保存一个字符串，当字符串长度超过了为数组分配的空间，就会发生溢出**
以下面的代码为例：
```
//该函数从标准输入中读入一行，把读入的内容放到指针s指明的位置
char *get(char *s) {
	int c;
	char *dest = s;
	while ((c = getchar()) != '\n' && c != EOF)  //EOF代表end of file，即输入文件的末尾
		*dest ++ = c;
	if (c == EOF && dest == s)
		return NULL;  //如果c是文件末尾且dest没动，说明没有读入任何字符

	*dest++ = '\0';  //在最后加一个空字符
	return s;
}
```
但是该函数有一个问题：**它没有确保是否为保存整个字符串分配了足够的空间**，这就导致在下面的echo函数中：
```
void echo() {
	char buf[8];
	gets(buf);
	puts(buf);
}
```
缓冲区buf只给了8个字符，而去掉末尾的空字符，只需7个以上的字符就会导致写越界
GCC生成的echo汇编代码如下：
```
echo:
	subq    $24,%rsp      在栈中分配24字节的空间
	movq    %rsp,%rdi     把%rsp（栈顶指针）复制到%rdi，作为调用gets的那个指针参数s
	call    gets          调用gets函数
	movq    %rsp,%rdi     继续把%rsp的地址作为puts的参数
	call    puts
	addq    $24,%rsp      释放存储空间
	ret
```
可见，在movq指令中，%rsp被复制到%rdi，作为函数调用时的参数——那个字符指针使用。而栈分配的24字节中，buf数组在栈顶，（理应）只占8字节的空间，剩下的16字节是处于对齐要求而分配的未使用的栈空间。**当用户输入超过7字符时，就会开始破坏栈上不属于buf数组的空间：**
![[Pasted image 20240909203220.png]]
字符数在23个之前都没有严重的后果，顶多就是破坏了未使用的空间；但是之后就会**破坏返回指针的值和更多可能的状态信息**，这导致**靠返回指针值进行返回的ret指令可能会跳转到一个意想不到的位置**
![[Pasted image 20240909203420.png]]
这得研究机器代码才能看得出来
很多常用的库函数，例如strcpy、strcat和sprintf，**都不需要告诉它们目标缓冲区的大小而产生字节序列**，这时就很容易导致缓冲区溢出错误

缓冲区溢出的一个更大的问题在于**会让程序执行它本来不愿意执行的函数**，则也是最常见的计算机网络攻击系统安全的方法：**输入给程序一个字符串，包含一些可执行代码的字节编码，称为==攻击编码==，然后让一些字节用一个指向攻击代码的指针覆盖掉返回地址，这样执行ret命令后就会跳转到执行攻击代码了**
攻击代码会使用系统来调用一个shell程序，为攻击者提供一组操作系统函数；或是执行一些未授权任务来修复栈，假装正常地调用ret返回给调用者

> [!NOTE] 蠕虫和病毒
> 蠕虫worm和病毒virus都试图在计算机中传播自己的代码段：**蠕虫可以自己独立运行并把自己的等效副本传递给其他机器；病毒则能把自己添加到包括操作系统的其他程序中，但不能独立运行**

### 3.10.4 对抗缓冲区溢出攻击
现代的编译器和操作系统实现了很多机制来避免遭受缓冲区溢出攻击，下面介绍一些Linux上最新GCC版本所提供的机制：
#### 1. 栈随机化
为了在系统中插入攻击代码，攻击者往往**既要插入代码，又要插入指向这段代码的指针，该指针需要知道代码字符串放置的栈地址**。因此在过去栈地址非常固定容易预测的情况下很棘手：只要攻击者确定了一个常见的Web服务器所使用的栈空间，就可以设计出**在许多机器上都能实施**的攻击，这被称为**安全单一化**
为了对抗这种攻击，**栈随机化的思想使得栈的位置在程序每次运行时都有变化，从而使得即使很多机器都运行同样的代码，它们的栈空间都是不同的**

实现栈随机化的方式是：**程序开始时，在栈上分配一段0~n字节之间的==随机大小的空间==，程序并不使用这段空间，它们的作用就是改变后续的栈位置**。这样的n必须足够大到使得足够多的栈地址变化，又要注意不要太大导致空间浪费
不妨像这样`printf("%p\n", &local)`输出局部变量的地址看看，**它会在一定范围内改变**

栈随机化时**地址空间布局随机化（ASLR)** 技术中的一种，每次程序运行时，其不同部分都会被加载到内存的不同区域
然而，攻击者可以使用蛮力克服随机化：反复使用不同的地址进行攻击。一种常见的做法是**在实际的攻击代码前插入一段很长的==nop==指令，它对程序计数器+1，使其指向下一条指令**。只要能猜中这段序列的某个地址，程序就会经过该序列到达攻击代码。这样的序列被称为==**空操作雪橇**==，即**程序会滑过这段没有意义的序列到达攻击代码**
其实就是硬生生枚举多个起始地址，但是64位系统8的$2^{24}$次枚举还是非常困难的，可见**ASLR技术虽然无法提供完全的安全保障，但大大降低了病毒或蠕虫的传播速度**

#### 2. 栈破坏检测
计算机的第二道防线是**能够检测到栈何时被破坏**，**C语言不提供有效的方法来防止对数组的越界写，但我们可以在发生越界写，造成有害后果之前尝试检测到它**
GCC在产生的代码中加入了一种==**栈保护者**==机制来检测缓冲区越界，思想是**在栈帧中任何局部缓冲区与栈状态之间存储一个特殊的==金丝雀值（哨兵值）==，该值在每次程序运行时==随机产生==，攻击者没有简单的办法提前知道它是什么**
在恢复寄存器状态和从函数返回之前，**程序检查该金丝雀值是否被该函数的某个操作或该函数调用的某个函数的某个操作改变，如果是的，则程序异常中止**
我们可以使用命令行选项`-fno-stack-protector`来允许GCC使用栈保护者。以上面的`echo`函数为例，使用该选项产生的汇编代码：
```
echo:
	subq    $24,%rsp
	movq    %fs:40,%rax        从内存中读出一个金丝雀值
	movq    %rax,8(%rsp)       把该值存储在栈中相对%rsp偏移8字节的位置
	xorl    %eax,%eax          归零寄存器
	-----  和原代码相同部分↓
	movq    %rsp,%rdi     把%rsp（栈顶指针）复制到%rdi，作为调用gets的那个指针参数s
	call    gets          调用gets函数
	movq    %rsp,%rdi     继续把%rsp的地址作为puts的参数
	call    puts
	------  和原代码相同部分↑
	movq    8(%rsp),%rax       把金丝雀值存回%rax
	xorq    %fs:40,%rax        把金丝雀值与原来从内存取出的值进行比较
	je      .L9                若相等，则可以退出了
	call    __stack_chk_fail   若不等，报错堆栈破坏！
.L9:
	addq    $24,%rsp      释放存储空间
	ret
```
这段汇编代码中，指令参数`%fs:40`指明**金丝雀值是用==段寻址==从内存中读入的**（段寻址值在现代操作系统中其实不怎么使用了）。**而==指向一个只读区域的段寄存器==`%fs`将金丝雀值放在一个特殊的段中，标志为“只读”从而不让它被修改**，然后像上面一样在返回前进行金丝雀值的检测即可
这样的栈保护机制只带来很小的性能损失，并且**GCC只在函数中有局部char类型缓冲区时才插入这样的代码**

#### 3. 限制可执行代码区域
该方法用于**消除攻击者向系统中插入可执行代码的能力**。一种方法是**限制哪些内存区域能够存放可执行代码：在典型的程序中，只有==保存编译器产生的代码的这部分内存==才需要是可执行的，其他部分可以被限制为只允许读和写，而不允许==执行（把内存的内容看作机器级代码）==**。
**虚拟内存空间**在逻辑上被分成了==**页**==，**每页2048或4096个字节**。以前的x86体系结构**将读和执行访问控制合并为了1位的标志**，导致可读的页也是可执行的。**栈必须可读又可写，这就导致以前的栈上字节也都是可执行的**。而虽然限制了一些页可读而不可写，但这也会限制一些部分的字节不可执行，带来严重的性能损失。
后来，AMD为其64位处理器的内存保护引入了 **'NX（不执行）'位**，把读和执行访问模式分开，这样就可以**让栈的读和可执行分开，单独检查其可执行性，效率上没有损失了**


### 3.10.5 支持变长栈帧
目前为止的代码中，**编译器能够预先确定需要为栈帧分配多少空间**；但有些函数**需要的局部存储是会变长的**，例如当函数调用`alloca`时就会**在栈上分配任意字节数量的存储**；又或者是代码声明了一个**局部变长数组**时
下面的代码给出一个包含变长数组的例子
```
long vframe(long n, long idx, long *q) {
	long i;
	long *p[n];  \\指针数组
	p[0] = &i;
	for(i = 1; i < n; i++)
		p[i] = q;
	return *p[idx];
}
```
该函数声明了n个指针的局部数组P，其中n由第一个参数给出。这会**在栈上分配8n个字节**，n的值随每次调用函数参数的不同而改变；同时函数还声明了一个对局部变量i的地址引用，该变量必须存储在栈中

为了管理**变长栈帧**。x86-64代码**使用寄存器==%rbp==作为==帧指针==（和栈顶指针%rsp区分开），也称为==基指针Base Pointer==**，以下面vframe函数的部分汇编代码为例说明其行为：
```
long vframe(long n, long idx , long *q )
n in %rdi, idx in %rsi, q in % rdx 
只展示部分代码
vframe:
	pushq    %rbp                 把%rbp的原值压入栈中储存
	movq     %rsp,%rbp            把此时的栈顶指针值移动给基指针
	subq     $16, %rsp            为i分配空间，后8字节未使用，此时记%rsp=s_1
	leaq     22(,%rdi,8),%rax     计算8n+22
	andq     $-16,%rax          -16=00010000,这里将8n+22向下舍入到最接近的16的倍数
	subq     %rax,%rsp           所以分配空间时，当n为奇数分配8n+8;n为偶数分配8n+16
	leaq     7(%rsp),%rax          对照节末的图：此时记%rsp=s_2
	shrq     $3,%rax              运算结束后就在栈上分配好了8n的字节并放置数组p在这
	leaq     0(,%rax,8),%r8        设置%r8来存储&p[0]
	movq     %r8,%rcx              把&p[0]转到%rcx中存储
	......
	省略的代码用于初始化循环变量
.L3：                              循环：
	movq     %rdx,(%rcx,%rax,8)    将q存入p[i]
	addq     $1,%rax               递增i
	movq     %rax,-8(%rbp)         把i存入相对%rbp在栈中偏移8字节的位置
.L2:
	movq     -8(%rbp),%rax         将i从栈中固定位置取出
	cmpq     %rdi,%rax             用i比n
	jl       .L3                   若i<n，则回到循环
	......
	省略的代码用于函数退出
	leave                          恢复%rbp和%rsp到最初的样子
	ret
```
这段代码先把%rbp之前的值保存到栈中，因为 **%rbp是一个被调用者保存寄存器**，然后在函数指向过程中，让%rbp的值**一直为指向保存原值到栈中时栈指针指向的地址 $s_1=16(\%rbp)$**，有了这个固定的位置后，**用==固定长度的局部变量（比如i）==相对于%rbp的==偏移量==来引用该局部变量，而==不取决于栈顶指针的值==**
换句话说就是栈顶指针会改变，那就寻求一个固定的不改变的栈内指针

最后恢复两个寄存器的leave指令等价于：
```
	movq     %rbp,%rsp
	popq     %rbp
```
把使用帧指针和不使用帧指针的代码混用是没问题的，只需要所有函数都将%rbp当初被调用者保存寄存器来处理就行
![[Pasted image 20240912212325.png]]


## 3.11 浮点代码
处理器的**浮点体系结构**影响对浮点数据操作的程序如何被映射到机器上，它决定：
- 如何存储和访问浮点值，通常通过某种**寄存器操作**完成
- 对浮点数据操作的指令
- 向函数**传递浮点数参数**和从函数**返回浮点数结果**的规则
- 函数调用过程中保存寄存器的规则。比如调用者保存和被调用者保存寄存器的指定

我们的讲述基于**AVX浮点体系结构**，当给定命令行参数`-mavx2`时，GCC会生成AVX2代码，即第二代版本的AVX。和整数操作一样，**我们所使用的ATT格式和在Intel的说明文档中使用的Intel格式有些许不同，比如列出指令操作数的顺序**
如下图所示，**AVX浮点体系结构允许数据存储在16个==YMM寄存器==中，名字为%ymm0 ~ %ymm15**
每个YMM寄存器的大小都为**256位(32字节)**，并且**当对标量数据**（也就是单个的基本数据类型int、float...）**操作时，这些寄存器只保存浮点数，而且只使用低32位（对于float）或者低64位（对于double），每个==XMM寄存器==是对应YMM寄存器的低128位（16字节）**：
![[Pasted image 20240912221427.png]]
汇编器使用它们的名字来引用它。

### 3.11.1 浮点传送和转换操作
下面是一组**在内存和XMM寄存器之间；以及从一个XMM寄存器到另一个XMM寄存器 不做任何转换 的==传送浮点数指令==**，**引用内存的指令称为==标量指令==：它们只对单个而不是一组封装好的数据进行操作**
数据要么保存在内存中，用$M_{32}$或$M_{64}$表示；要么**保存在XMM寄存器**中，用$X$表示：
![[Pasted image 20240912222037.png]]
GCC**只用标量传送操作在内存和XMM寄存器或XMM之间传送数据**，表末的`vmovaps`和`vmovapd`指令在XMM寄存器之间传送数据，这种情况下**程序复制整个寄存器还是只复制寄存器低位的值没有性能和功能区别**，因此也将其包括在标量指令中。
指令中的`a`代表aligned对齐的，也就是说**当读写内存时，地址要满足16字节对齐，否则会导致异常；而在两个寄存器间传送时，不会出现错误对齐情况**

下面则是**在浮点数和整数数据类型之间；以及在不同浮点格式之间进行转换的指令集合**：
![[Pasted image 20240912222955.png]]
图3-47的指令将一个从XMM寄存器或内存中读出的浮点值转换为整数，**并将结果写入一个通用寄存器，例如%rax、%rbx等**，浮点数转换为整数时，指令会进行**截断：把值向0舍入**

图3-48则是三操作数格式的指令，由两个源和一个目的组成：**第一个操作数读于内存或一个==通用目的寄存器==；第二个操作数只对结果的高位字节有影响，==在目的为XMM寄存器时可以忽略==，直接使用和第三个操作数一样的名字即可；第三个操作数则是目的XMM寄存器**
从%rax读出一个长整数，转换为双精度数并存入%xmm1的低字节中：
```
vcvtsi2sdq %rax,%xmm1.%xmm1
```

在GCC当前版本生成的代码中，**在两种不同浮点格式之间进行转换需要单独说明**，例如，**将%xmm0的低位4字节保存的单精度值转换为双精度值**，有一个
```
vcvtss2sd %xmm0,%xmm0,%xmm0
```
的指令可以用来实现它，但是GCC生成的代码实际上是：
```
vunpcklps    %xmm0,%xmm0,%xmm0
vcvtps2pd    %xmm0,%xmm0
```
这里`vunpcklps`指令**通常用于交叉放置来自两个XMM寄存器的值，将它们存储到第三个寄存器中：**
即，若一个源寄存器的内容为字$[s_3,s_2,s_1,s_0]$，另一个源寄存器为$[d_3,d_2,d_1,d_0]$，那么目的寄存器中的值就为$[s_1,d_1,s_0,d_0]$
而`vcvtps2pd`指令**将源XMM寄存器中的==两个低位上的单精度值==扩展成目的XMM寄存器中的两个双精度值**
即，若源寄存器的值为$[s_1,d_1,s_0,d_0]$，那么目的寄存器的值为$[ds_0,dd_0]$，这里$ds_0$和$dd_0$为将$s_0$和$d_0$转换为双精度值后的结果

那么**这两条指令用于同一个寄存器时，就是将该寄存器的低位4字节中的单精度值转换为双精度值，再将其副本保存回去**
同理双精度转换为单精度，GCC会生成：
```
vmovddup    %xmm0,%xmm0
vcvtpd2psx  %xmm0,%xmm0
```
这里`vmovddup`指令**将寄存器保存的两个双精度值全部变为低位的那个双精度值，存放到目的寄存器**，即将$[x_1,x_0] \rightarrow [x_0,x_0]$
而`vcvtpd2psx`指令**将寄存器保存的两个双精度值转换为单精度，存放在目的寄存器的低位的一半位置上，然后将高位的另一半位置的位模式设置为0**，即将$[x_0,x_0]\rightarrow [0.0, 0.0, x_0,x_0]$
当然也有一条单独的指令:
```
vcvtsd2ss  %xmm0,%xmm0,%xmm0
```
GCC选用两条指令而不用那条简便的指令，没有什么明显的意义，这么做没什么好处但它就是这么做了

提供示例函数与汇编代码以供练习阅读：
![[Pasted image 20240913115357.png]]

### 3.11.2 过程中的浮点代码
x86-64中，**XMM寄存器用于向函数传递浮点参数，以及从函数返回浮点值**，它们有如下规则：
- XMM寄存器%xmm0~%xmm7**最多可以传递8个浮点参数**，按参数列出的顺序依次存入这八个寄存器中。**大于8个的浮点参数通过栈传递**
- **函数使用寄存器==%xmm0==来返回浮点值**
- **所有的XMM寄存器都是==调用者保存寄存器==**，被调用者不需要保存就能覆盖它们

即XMM寄存器无需考虑指针和整数的储存，它们被储存于通用寄存器。**不同类型存入寄存器的顺序是按照该参数在所有相同类型的参数中的位次选择的**

### 3.11.3 浮点运算操作
下面是一组**执行算术运算的标量AVX2浮点指令**，每条指令有一个或两个源操作数和一个目的操作数，**第一个源操作数可以是XMM寄存器或内存位置，第二源操作数和目的操作数都必须是XMM寄存器**：
![[Pasted image 20240913125839.png]]
可以看见每条指令按照针对单精度还是双精度，最后两个后缀有所区别
以下面的浮点函数为例：
```
double funct(double a, float x, double b, int i){
	return a*x - b/i;
}
```
生成的汇编代码：
```
double funct(double a, float x, double b, int i)
a in %xmm0, x in %xmm1, b in %xmm2, i in %edi
funct: 
	vunpcklps    %xmm1,%xmm1,%xmm1 
	vcvtps2pd    %xmm1,%xmm1             和3.11.1所说的一样，进行x向双精度的转换
	vmulsd       %xmm0,%xmm1,%xmm0       用转换后的x乘a
	vcvtsi2sd    %edi,%xmm1,%xmm1        把i转换为双精度
	vdivsd       %xmm1,%xmm2,%xmm2       计算b/i
	vsubsd       %xmm2,%xmm0,%xmm0       计算a*x - b/i并存到%xmm0返回
	ret
```

### 3.11.4 定义和使用浮点常数
和整数运算操作不同，**AVX浮点操作不能以==立即数值==作为操作数，编译器必须为所有常量值分配和初始化存储空间，然后把这些值从内存读入**
以下面的摄氏度转换函数为例：
```
double cel2fahr(double temp){
	return 1.8 * temp + 32.0;
}
```
生成的汇编代码为：
```
double cel2fahr (double temp)
temp in %xmm0
cel2fahr:
	vmulsd    .LC2(%rip),%xmm0,%xmm0   用1.8乘temp，常数定义在后面
	vaddsd    .LC3(%rip),%xmm0,%xmm0   加上32.0
.LC2:
	.long     3435973837               这是1.8位表示的低4字节的十进制值
	.long     1073532108               这是1.8位表示的高4字节的十进制值
.LC3:
	.long     0                        这时32.0位表示的低4字节的十进制值
	.long     1077936728               这时32.0位表示的高4字节的十进制值
```
本机器采用小端法，因此在.LC2和.LC3中先输出低4字节的十进制值。每一个都是**通过`.long`声明的**
在运算时，从高位字节抽取指数字段，然后将抽取的字段减去，剩下的便是两个小数位，将小数位连接起来得到小数字段的值，然后乘上2的指数字段值的幂，加上隐含的1即可得到结果。

### 3.11.5 在浮点代码中使用位级操作
有时GCC生成的代码会在XMM寄存器上执行位级操作得到结果，下面是一些相关的指令：
![[Pasted image 20240913132928.png]]
这些操作**都作用于封装好的数据，即更新整个目的XMM寄存器，对两个==源寄存器的所有位==执行指定的位级操作**

### 3.11.5 浮点比较操作
下面是两条用于**比较浮点数值**的指令：
![[Pasted image 20240913133240.png]]
类似于CMP(cmpq...)指令，**它们都比较两个操作数，并且设置条件码指示它们的相对值**，参数$S_2$必须在XMM寄存器中，而$S_1$则可以在XMM寄存器或内存中
**浮点比较指令会设置三个条件码：==零标志位ZF、进位标志位CF和奇偶标志位PF==**，对于奇偶标志位PF，**它当最近的一次算术或逻辑运算产生的值的最低位字节有偶数个1（偶校检）时被设置**。
但在浮点比较中，**当两个操作数的任意一个为NaN时，上面三个标志位也会被设置，因此可以检查比较是否失败。** 这种情况称为**无序的**，主要通过奇偶标志位可以检查，通常`jp`指令就根据浮点比较得到一个无序结果来进行条件跳转
总的来说，条件码设置如下：
![[Pasted image 20240913161619.png]]


---
# Chapter 4. 处理器体系结构
目前为止，我们看到的计算机系统仅限于机器语言程序级别。在它的深层次，我们知道处理器必须执行一系列指令，每条指令执行一个简单操作。**指令被编码为由一个或多个字节序列组成的二进制格式**，一个处理器支持的指令及其字节级编码称为它的**指令集体系结构ISA**，不同处理器族有不同的ISA，因此*当一个程序被编译成在一种机器上运行后，它就不能在另一种机器上运行了*。
而在同一个处理器家族上，不同型号的处理器在ISA级别上却保持着兼容，这是因为ISA在编译器编写者与处理器设计人员之间提供了一个概念抽象层：**编译器编写者只需要知道允许哪些指令以及其编码方式，而处理器设计人员则必须建造出执行这些指令的处理器**

本章介绍的内容关于处理器硬件的设计，研究一个硬件系统执行某种ISA指令的方式。我们从**定义一个自己的指令集体系结构Y86-64**开始

## 4.1 Y86-64指令集体系结构
$$ 定义一个指令集体系结构=定义\begin {cases}
各种状态单元\\
指令集\\指令集的编码\\一组编程规范和异常事件处理
\end {cases}$$
### 4.1.1 程序员可见的状态

“**程序的本质就是状态机+系统调用**”，更底层来说，状态是什么？

下图展示了程序**可以访问和修改的部分**，Y86-64程序中的每条指令都会**读取或修改处理器状态的某些部分**，这称为==**程序员可见状态**==，这里“程序员”指的是汇编代码的生产者或编译器。
![[Pasted image 20240913171356.png]]
处理器实现中，只要我们**保证机器级程序能够访问这些程序员可见状态**，就不需要完全按照ISA暗示的方式来表示和组织该处理器状态。
（即，只要确保机器能够根据指令集架构（ISA）规定的规则，访问和操作程序员所能直接看到的那些状态信息，就可以按照自己的方式实现处理器，而无需严格按照ISA的方式）

我们的Y86-64的状态类似于x86-64，有除了%r15以外的15个程序寄存器，每个程序寄存器存储一个64位的字。其中%rsp被入栈出栈，调用和返回指令作为栈指针，除此以外的寄存器无特殊含义和固定值。还包括三个一位的条件码ZF、SF和OF。
- **程序计数器PC存放当前正在执行指令的地址。**
- **内存从概念来说就是一个很大的保存着程序和数据的字节数组。** Y86-64程序用**虚拟地址**来引用内存位置，**硬件和操作系统软件联合起来将虚拟地址翻译为物理地址，指明数据的实际存储位置**。
- 程序状态的最后一个部分是**状态码Stat**，用于**表明程序执行的总体状态，会指示是正常运行还是出现了某种异常**，用于异常检测和处理
### 4.1.2 Y86-64指令
Y86-64 ISA中各个指令简单描述如下，**只包含8字节整数操作**，这个指令集就是我们希望实现的：
![[Pasted image 20240913180901.png]]
该图的左边是**指令的汇编代码**表示，右边则是**字节编码，数值是十六进制表示的**
它相当于x86-64的一个子集：只包括8字节整数操作（也就是1字），寻址方式和操作较少
下面是它的一些细节：
- 在movq指令中，我们**第一个字母表明了源的类型：立即数（i）、寄存器（r）和内存（m），第二个字母表明了目的的类型是r或m**。而在地址计算中，我们不支持**有第二个变址寄存器以及任何寄存器值的伸缩（数乘）**，且和x86-64一样不允许内存直接传送到内存
- `OPq`指令代表4个整数操作指令`addq`,`subq`,`andq`和`xorq`。它们只对寄存器数据操作（在x86-64中它们可以对内存数据操作），且设置条件码`ZF`,`SF`和`OF`
- `jXX`指令代表和x86-64一样的7个跳转指令`jmp`,`jle`,`jl`,`je`,`jne`,`jge`,`jg`
- `convXX`指令代表6个条件传送指令，`cmovle`,`cmovl`,`cmove`,`cmovne`,`cmovge`,`cmovg`，格式和`movq`指令一样，只是会要求条件码满足一定关系才进行传送
- `call`指令**将返回地址入栈，然后跳到目的地址**；`ret`指令从这样的调用中返回
- `halt`指令**停止指令的执行**，x86-64有一个相同指令`hlt`，但因为它**会导致整个系统暂停运行而不允许使用**。在我们的Y86-64中，它会**导致处理器停止**并把**状态码**设置为`HLT`

### 4.1.3 指令编码
图4-2的右边是指令的字节编码，可以看到每条指令需要1~10个字节。
在指令的字节编码中，**第一个字节用于表明指令的类型：它分为两个4位的部分，高4位是==代码部分==，低4位是==功能部分==**。
代码值的范围为0~0xB，功能值只在一组相关指令共用同一个代码时有用。
下面是整数操作和条件传送的具体编码：

![[Pasted image 20240914194415.png]]
可以看见**相同种类的指令的第一个字节上的数相同；无条件指令如`addq`,`jmp`和`rrmovq`的第二个字节上的功能代码都为0**

我们令Y86-64的寄存器编号与x86-64相同，它们都有一个范围在0~0xE之间的**寄存器标识符**：
![[Pasted image 20240914194715.png]]
需要操作数的指令编码往往会更长。它们可能有附加的**寄存器指示符字节**，用于指定一个或两个寄存器，在图4-2中称为`rA`或`rB`，用于指定**数据源和目的的寄存器**:
![[Pasted image 20240913180901.png]]
**在只需要一个寄存器的指令中，它们将不需要的那个寄存器设置为`0xF`**；如果指令不需要寄存器，则整个寄存器指示符字段只有一个0xF

有的指令则需要一个**附加的常数字，即上图最后的那些位置**，作为 **`irmovq`的立即数数据、`rmmovq`和`mrmovq`的地址指示符的偏移量或分支和调用指令的目的地址**（我们用的是绝对地址，而非IA32那样的相对寻址），而且所有整数采用小端法编码
在x86-64中，这些常数字可以是1、2、4或8字节的，在我们的Y86-64中就简单地将它们都编码为8字节

例如，用十六进制表示指令`rmmovq %rsp,0x123456789abcd(%rdx)`，从上面的指令集字节编码与寄存器编码，我们可以这么写：
$$ \underbrace{40}_{指令编码}\quad \underbrace{42}_{两个基址寄存器编号}\quad \underbrace{cd \quad ab\quad 89\quad 67\quad 45\quad 23\quad 01\quad 00}_{偏移量编码}$$
其**偏移量0x123456789abcd**放在8字节的**常数字**中，首先进行0填充变为8字节，形成字节序列`00 01 23 45 67 89 ab cd`，**因为是小端法机器，需要把顺序反过来存储**

**指令集**的一个重要性质就是**字节编码必须有唯一的解释，必须是唯一的指令序列的编码，否则不合法**。这是处理器可以**无二义性地**执行目标代码程序的保证，但是**我们需要知道一段代码序列的起始位置才可以准确地确定出如何将序列划分为单独的指令**，这也是一个需要处理的问题

### 4.1.4 Y86-64异常
前面提到Y86-64具有一个**描述程序执行的总体情况的状态码`Stat`**，这个状态码可能的值及其名字、含义如下：
![[Pasted image 20240914202520.png]]
非法地址的报错基于当对地址读或向地址写时，我们会确定一个确切的地址限定范围，超出该范围的读写就会报错
对于Y86-64，遇到这些异常时，我们简单地令处理器停止执行指令；在更完整的设计中，处理器通常会调用一个**异常处理程序**，它被配置为不同结构以用于处理不同类型的异常

### 4.1.5 Y86-64程序

示例求和程序：
```c
long sum(long *start, long count) {
	long sum = 0;
	while (count) {
		sum += *start;
		start++; //注意是指针++，地址向前移动一个字节
		count--;
	}
	return sum;
}
```
x86-64和我们的Y86-64生成的该程序的汇编代码分别为：
```x86-64
long sum(long *start, long count)
start in %rdi, count in %rsi

sum:
	movl   $0, %eax      sum=0
	jmp    .L2           进入测试（判断循环）
.L3:
	addq   (%rdi), %rax  将start指向的值加到sum的寄存器
	addq   $8, %rdi      将start（指针）前进一个字节，即start++
	subq   $q, %rsi      将count减去1
.L2:
	testq  %rsi, %rsi   将%rsi中的值与自己求与，若值非0,结果非0,设置ZF=0；值为0,ZF=1
	jne    .L3          若ZF = 0,跳转.L3，循环
	rep; ret
```

而我们的Y86汇编代码如下：
```y86-64
long sum(long *start, long count)
start in %rdi, count in %rsi

sum:
	irmovq   $8, %r8      常数8
	irmovq   $1, %r9      常数1
	xorq     %rax, %rax   与自己进行异或，相当于把该寄存器的值设置为0,sum=0
	andq     %rsi, %rsi   count首先与自己求与，值不会改变，但是会根据是否为0设置标志位CC
	jmp      test         跳转到test部分进行测试（判断循环）
loop:
	mrmovq   (%rdi), %r10  获取start指针指向的值，存到r10
	addq     %r10, %rax    把该值加入sum
	addq     %r8, %rdi     start指针加一字节
	subq     %r9, %rsi     count值减1
test:
	jne      loop          subq会设置零标志位，jne在ZF=1时才跳转，所以ZF=0，即为0时退出
	ret
```

y86-64的代码和汇编器生成的x86-64代码大体相同，但是有以下不同点：
- y86-64还没有定义使用立即数的版本，因此只能将常数加载到寄存器，再使用寄存器中的值进行有常数的计算
- y86-64中将start的值先从内存取到寄存器，再从寄存器加到sum所在的寄存器中；而x86-64直接从内存加到寄存器中
- y86-64因为是手工编写的，考虑到subq会设置零标志位，因此无需再进行testq了，于是将这部分优化掉了

利用上述sum函数进行求和的完整的y86-64程序汇编如下：
```y86-64
#程序从地址0开始执行
	.pos 0
	irmovq   stack, %rsp   # 设置栈指针
	call     main       # 启动主程序
	halt       # 终止程序

# 声明四个元素的数组：
	.align 8
array:
	.quad   0x000d000d000d
	.quad   0x00c000c000c0
	.quad   0x0b000b000b00
	.quad   0xa000a000a000

main:
	irmovq  array, %rdi
	irmovq  $4, %rsi      # 将
	
	参数存入寄存器，以供调用
	call    sum
	ret                  # 调用sum(array, 4)

# 下面就是之前sum函数的汇编
long sum(long *start, long count)
start in %rdi, count in %rsi

sum:
	irmovq   $8, %r8      常数8
	irmovq   $1, %r9      常数1
	xorq     %rax, %rax   与自己进行异或，相当于把该寄存器的值设置为0,sum=0
	andq     %rsi, %rsi   count首先与自己求与，值不会改变，但是会根据是否为0设置标志位CC
	jmp      test         跳转到test部分进行测试（判断循环）
loop:
	mrmovq   (%rdi), %r10  获取start指针指向的值，存到r10
	addq     %r10, %rax    把该值加入sum
	addq     %r8, %rdi     start指针加一字节
	subq     %r9, %rsi     count值减1
test:
	jne      loop          subq会设置零标志位，jne在ZF=1时才跳转，所以ZF=0，即为0时退出
	ret

# 栈从这里开始，并且向低地址增长：
	.pos  0x200
stack:
```
代码中，以“.”开头的词都是**汇编器伪指令**，用于告诉汇编器调整地址，以便在相应位置产生代码或插入一些数据
例如，在第二行中出现的`.pos 0`伪指令告诉汇编器应该从地址0处开始生成代码，这个地址是所有y86-64程序的起点
程序开头设置了栈指针的值，它是`stack` 标志的地址（程序末尾），同时，在`stack`标志的上方还使用`.pos 0x200`指明了这个标志开始的地址，栈会从这个地址开始，往低地址处增长


### 4.1.6 Y86-64指令详情

大多数y86-64指令修改程序状态的方式都比较直接，定义它们想要达到的结果不算困难。但是，要注意下面这两个特殊的指令组合

- `pushq`指令的行为是**将栈指针减8,并把一个寄存器值写入内存中**，在这个定义的基础上，执行指令`push %rsp`（push栈指针寄存器的值）的行为是不确定的，需要自己额外定义。通常有两种形式，代表减8和写内存两个操作的不同优先级：
   - 压入`%rsp`的初始值
   - 压入`%rsp`减去8后的值
因为C编译器正常情况下并不会产生这条指令，我们想要验证我们自己的机器上的优先级是哪种，就得编写汇编代码来验证，也很简单，先存一次`%rsp`的初始值，然后对`%rsp`进行一次`pushq`，再让它与初始值存储的寄存器`subq`即可，观察得到的结果是0还是8

- 类似的，`popq`指令的行为则是**读取一个内存中的值，然后将栈指针加8**，`popq %rsp`的行为也需要特别规定，可能是下面两种：
   - 将`%rsp`置为从内存中读出的值
   - 将`%rsp`置为从内存中读出的值再加8的值

## 4.2 逻辑设计和硬件控制语言HCL

硬件设计中使用电子电路来计算对位进行运算的函数，各种存储单位中也使用电子电路来存储位
大部分现代电路技术使用信号线上的高低电压来表示不同的位值：逻辑1使用1.0伏特左右的高电压表示，逻辑0使用0.0伏特左右的低电压表示

实现一个数字系统，需要实现三个主要的组成部分：**计算对位操作的==组合逻辑==、存储器的==存储单元==、控制存储器单元更新的==时钟信号==**
这一节介绍的内容包括这些组成部分的概述。以及**硬件控制语言HCL**，利用HCL进行不同处理器设计的控制逻辑介绍

### 4.2.1 逻辑门

**逻辑门是数字电路的基本单元**，它们产生的输出等于对其接受的输入位值经过某个布尔函数的变换后得到的位值
下面是三种布尔函数：`AND` 、` OR` 和`NOT` 的标准符号：
![[Pasted image 20250314204933.png]]
三种布尔函数对应于符号`&&`、`||`和`!`，要注意的是，**逻辑门只对单个位进行操作，而不是整个字**，因此使用的符号不是位运算符`&`/`|`/`~`
当然它们也可以扩展到n路运算，不过在这里我们依然写作二元运算符

逻辑门总是活动的：一旦一个门的输入变化了，在很短的时间内其输出也会相应变化

### 4.2.2 组合电路和HCL布尔表达式

将多个逻辑门组合成一个网，就可以构建一个计算块，称为**组合电路**，它需要有以下限制：
- 每个逻辑门的**输入**必须是以下几种情况：
     - 一个**系统输入（主输入）**
     - 某个**存储器单元的输出**
     - 某个**逻辑门的输出**
- **两个及以上的逻辑门的输出不能连接在一起**，不然线上的信号就会发生矛盾，电压不合法或电路故障
- **逻辑门组成的网不能有环路**，闭合回路会导致网络计算的函数有歧义

下面是一个简单组合电路的例子：
![[Pasted image 20250315203144.png]]
该电路接受两个输入a和b，输出唯一值eq：当a和b都是1或都是0时，输出才是1
写成HCL即：
$$ bool\quad eq = (a \quad\&\&\quad b)\quad ||\quad (!a\quad \&\&\quad !b)$$
这种写法类似于c, 但是我们不把它看成执行了一次计算并将结果放入内存中的某个位置，而是**简单地给表达式一个等于号左侧的名字**

下面是另一个简单但有用的组合电路，称为**多路复用器**：
![[Pasted image 20250315204418.png]]
**多路复用器MUX根据输入控制信号（s）的值，在一组不同的数据信号（a和b）之中选出一个**，在这里，当s的值为1时，多路复用器的输出等于输入a；当s的值为0时，多路复用器的输出等于输入b
写成HCL表达式即为：
$$ bool\quad out = (s\quad\&\&\quad a) || (!s\quad \&\&\quad b )

$$

HCL表达式表明了组合逻辑电路和C语言中的逻辑表达式之间的对应关系，但是它们之间还是存在不同之处：
- 组合电路的输出会持续响应输入的变化，而C表达式只在程序执行过程中被遇到时才进行求值
- C表达式的参数可以是任意整数，但组合电路逻辑门输入只有0和1
- C表达式具有的短路特性在组合逻辑门中不存在，不可能因为操作结果可以由第一个输入确定就不对第二个输入求值

### 4.2.3 字级的组合电路和HCL整数表达式

将逻辑门组合为大的网，可构造出能够计算更加复杂的函数的组合电路，通常是**能够对数据字进行操作的电路**，其中的位级信号代表一个整数，或一些控制模式
例如，处理器设计就包含很多4位到64位的字，他们代表整数、地址、指令代码和寄存器标识符

执行字级计算的组合电路，根据输入的字的各个位，使用逻辑门来计算输出字的各个位
例如下面这个组合电路用于检测两个64位字a和b是否相等：
![[Pasted image 20250316125755.png]]
它依次检测字a和b的每个位上的信号，当每一对对应位置的位都相等时（分别使用AND门连接），输出才为1

HCL中，**将所有字级的信号都声明为`int`**，而不指明字的大小，以简化表达。在全功能的硬件描述语言中，字则可以被声明为有特定的位数
HCL允许比较字是否相等，对于上面的测试电路，其表示为：
$$ bool \quad Eq = \quad (A\quad == \quad B)
$$
此处参数A和B均为`int`型变量
绘制字级电路时，**使用中等粗度的线条表示携带字的每个位的线路，使用虚线表示布尔信号的结果**

#### 字级组合电路中的多路复用器

下图展示可一个字级的多路复用器：
![[Pasted image 20250316165250.png]]
其中，输入信号s是用于控制输出模式的信号，输出值是一个64位的字，根据s的值选择性地输出输入值的其中一个。值得注意的是，该电路并不是64个[图11](### 4.2.2 组合电路和HCL布尔表达式)的单纯累加，而是**只产生一次`!s`，此后在每个位处复用这个信号**，从而减少了非门的使用

处理器中含有多种多路复用器，用于根据某些控制条件，从多个源中选出一个字进行输出。HCL使用**情况表达式**来描述**多路复用函数**，通用格式如下：
$$\begin{cases}
select_1\quad :\quad expr_1;\\
select_{2}\quad :\quad expr_2;\\
\vdots \\
select_3\quad :\quad expr_3;
\end{cases}
$$
该表达式包含多种情况，每种情况`i`具有一个**布尔表达式$select_i$：表明什么时候需要选择这种情况**，和一个**整数表达式$expr_i$：表明得到的值是什么**
需要注意的是，它并不完全和c语言的`switch`语句相同：**HCL情况表达式不要求不同的选择表达式$select_i$互斥**
这些选择表达式是顺序求值的，**第一个求值结果为1的选择表达式$select_{first}$将会被选中**。例如图4-13的字级多路复用器表示为HCL就是：
```
word Out = [
	s: A;
	1: B;
];
```
这段代码的第二个选择表达式中的`select`部分就是1，这是一种指定默认的表示方法：若前面的情况都没有被选中，那么就选择这个select为1的情况，因此几乎所有的表达式都以其结尾

在HCL语言中，可以让多个`case`条件“重叠”，这让代码更直观；然而实际做成硬件时，**同一条总线上绝不能同时驱动两个值**，所以综合工具会自动把这些重叠条件变成**互斥**的控制信号，并且按书写顺序赋予“优先级”，保证 **只有最先满足的那个条件** 对输出起作用

选择表达式可以是任意的布尔表达式，可以有任意多种情况，因此情况表达式可以描述更加复杂的选择标准+更多输入信号的块，例如输入三个字A、B、C且输出最小值
```
void Min3 = [
	A <= B && A <= C : A;
	B <= A && B <= C : B;
	1                : C;
]
```

更复杂的组合逻辑电路可以在字级数据上执行更多不同类型的操作，其中**算术/逻辑单元ALU**是一类非常重要的组合电路：
![[Pasted image 20250516174014.png]]
这样的电路接受三个输入：标号为A的输入Y、标号为B的输入X和一个控制输入0/1/2/...
控制输入设置电路对数据输入执行不同的算术或逻辑操作，这张图展示了加减与和乘方运算四个控制输入
（注意减法运算是B-A，而不是A-B，这是为了和`subq`指令的参数顺序一致）

### 4.2.4 集合关系

处理器的设计中，经常需要**将一个信号与许多可能匹配的信号进行比较操作**，用于**检测正在处理的某个指令代码是否属于同一类指令代码**
例如，假设希望从一个两位信号`code`中选择其高位和低位来为一个四路复用器MUX4产生两个信号s1和s0：
![[Pasted image 20250516193101.png]]
这里可以使用相等测试来产生信号s1和s0：
```
bool s1 = (code == 2 || code == 3);
bool s2 = (code == 1 || code == 3);
```

更加简洁的形式是使用集合：
```
bool s1 = code in { 2, 3 };
bool s2 = code in { 1, 3 };
```
判断集合关系的通用形式为：
$$ iexpr\quad in\quad \{iexpr_1, iexpr_2, \cdots, iexpr_i\}$$
其中iexpr均为整数表达式

### 4.2.5 存储器和时钟

组合电路本身是**不存储任何信息的**，它只是简单地响应输入信号，产生等于输入信号的某个函数的输出信号而已
**时序电路：输出不仅取决于当前的输入信号，还取决于之前的输入信号（即历史状态）的数字电路**

为了产生时序电路，我们必须引入按位存储信息的设备以存储历史状态。
存储设备由同一个**时钟**控制，时钟是一个**周期性信号**，它用于**决定什么时候将新值加载至设备中**，考虑以下两种存储设备：
- **时钟寄存器（即“寄存器”）**：存储单个位或字，时钟信号控制寄存器加载输入值
- **随机访问存储器（即“内存”）**：存储多个字，使用地址来选择对特定字的读写。
随机访问存储器使用的场景很多，例如处理器的虚拟内存系统允许用户在一个很大的地址空间内访问任意的字；寄存器文件中**寄存器标识符作为地址**访问其中存储的字等

> [!WARNING] "寄存器"
> 硬件和机器级编程中的“寄存器”一词在含义上是有细微差别的：
> - 硬件中，寄存器直接将输入和输出线连接到电路的其他部分
> - 机器级编程中，寄存器代表**CPU中少量的可寻址的字**，地址就是寄存器ID，**字通常存储在寄存器文件中**
> 因此，在需要避免歧义时，我们会区分**硬件寄存器**和**程序寄存器**

硬件寄存器的工作模式如下：
![[Pasted image 20250516201021.png]]
大部分时候，寄存器保持在稳定状态`x`，**寄存器的输出就是其当前的状态**，信号沿着寄存器前面的组合逻辑传播，当产生一个新的寄存器输入`y`时，若时钟电位为**低电位**，此时寄存器的**输出保持不变**；而时钟电位为**高电位**时，**输入信号`y`加载入寄存器**，`y`成为寄存器的**下一个状态**

**寄存器文件**是**由多个寄存器连接组合而成的**。通常用于 CPU 中的**运算单元和控制单元之间**，用来临时存储计算中的中间结果、操作数以及其他控制信息。
一个典型的寄存器文件结构如下：
![[Pasted image 20250516202533.png]]
寄存器文件具有**两个读端口**A和B，以及**一个写端口**W，这样的**多端口随机访问存储器允许同时进行多个读和写操作**，例如上图的寄存器文件中，电路可以读两个程序寄存器的值，并更新第三个寄存器的状态
在每一个端口中，都**需要输入地址**，用于指定字的位置：
- 两个读端口A和B向寄存器文件输入地址`srcA`和`srcB`，向外输出地址对应的数据`valA`和`valB`，也就是**向寄存器文件申请读出地址的值**
- 一个写端口向寄存器文件输入地址`dstW`，还向寄存器文件输入数据`valW`，意为**向地址`dstW`处写数据`valW`**

**寄存器文件不是组合电路，因为它有内部存储**，但从寄存器文件中读数据就好像是一个以地址为输入，数据为输出的组合逻辑块
这里的“地址输入”指的都是寄存器的ID，例如，将`srcA`设置为`3`，之后寄存器`%rbx`的值就会以`valA`输出给请求者

同理，向寄存器文件写入字也是由时钟信号控制的：将值`valW`加载入寄存器文件，并且给出目标地址`dstW`，该值就会被写到地址对应的寄存器中，在`dstW = 0xF`的情况下不会写任何程序寄存器

如果同时读和写同一个程序寄存器会怎么样？
读写竞争问题往往通过硬件的设计解决，例如控制读优先或写优先，在现代的 CPU 设计中，现代处理器采用**流水线**技术，读写冲突会通过流水线的调度机制来解决，根据检测得到的数据依赖性进行调度

处理器还有一个随机访问存储器用于**存储程序数据**：
![[Pasted image 20250516221049.png]]
该内存有一个地址输入，一个写的数据输入以及一个读的数据输出，它的操作和寄存器文件是一样的
如果地址超出了范围，`error`信号会设置为1，否则为0。`error`信号是由**组合逻辑**产生的，因为只需要检查边界条件而无需保存状态
另外，处理器还包括一个只读存储器，用于读指令
上述两个存储器往往被合并为一个双端口存储器，一个端口用来读指令，另一个用于读或写数据

## 4.3 Y86-64的顺序实现

在前面几节介绍的实现Y86-64处理器所需部件的基础上，我们首先描述一个**SEQ：顺序的处理器**。
**在每个时钟周期上，SEQ会执行处理一条完整指令所需的所有步骤**
但是这样的时钟周期时间会很长，时钟周期频率过低了。因此，**SEQ只是实现最终目的的第一步**，我们最终的目的是实现高效的、流水线化的处理器

### 4.3.1 将处理组织成“阶段”

通常处理一条指令包括其中的很多操作，为了让处理器充分利用硬件，我们需要将这些操作组织成某个特殊的**阶段序列**，将其置于这样一个**框架**下：即使指令的动作差异很大，但是**所有的指令都遵循统一的序列**，每一步的**具体处理都取决于正在执行的指令**
简略来说，各个阶段（内）执行的操作概述如下：
- **取指阶段**：根据PC存储的当前指令的地址，获得下一条指令的地址
  从内存读取**指令字节**，**地址为PC的值**，从指令字节中抽取指示**指令指示符字节的两个4位部分**，称为**指令代码icode**和**指令功能ifun**。其中，可能取出的指令指示符字节存在两种情况：
	- 寄存器指示符字节：指明一个或两个**寄存器操作数指示符rA和rB**
	- **四字节常数字valC**：按顺序方式计算得到的当前指令的**下一条指令的地址valP**，计算方式是PC的值加上已取出指令的长度：**valP = PC值 + 已取出指令的长度**
- **译码阶段**：将取指阶段获取的指令转换为 CPU 能够理解并执行的操作
  从寄存器文件中读入至多两个操作数，得到值valA和（或）valB，读取的寄存器通常是取指阶段的寄存器指示符rA和rB字段指明的寄存器，也有些指令读寄存器%rsp
- **执行阶段**：执行指令指明的操作
  执行阶段中，
	- 算术/逻辑单元ALU要么根据**指令功能ifun**的值执行相应操作，**计算内存引用的有效地址**；
	- 要么**增减栈指针**
	- 也可能**设置条件码**
  对于传送指令，在该阶段会检验由条件码和由`ifun`给出的传送条件，若条件成立，更新目标寄存器；对于跳转指令，该阶段会决定是否应该选择分支
- **访存阶段**：将数据写入内存，或者从内存读出数据valM
- **写回阶段**：将至多两个结果写到寄存器文件中
- **更新PC**：将程序计数器的值设置为下一条指令的地址

处理器会无限循环地执行上述阶段，在我们简化的实现中，当发生任何异常时，处理器会立刻停止：执行`halt`指令或非法指令/读写非法地址时产生异常。
而在实际的更完整的实现中，当发生异常时，处理器会进入异常处理模式，根据异常类型执行相应代码

执行一条指令需要进行很多处理：**执行指令所表明的操作、计算地址、更新栈指针、确定下一条指令的地址**等等，但是这些流程比较相似
我们的期望是使得硬件数量尽量少，将其映射至一个二维集成电路芯片表面时保持简单而一致的结构，因为在硬件上复制逻辑块的成本比软件的代码重复成本要高得多
一个降低复杂度的方法是**让不同的指令共享尽量多的硬件**，例如处理器设计只含有一个算术/逻辑单元，根据所执行指令的不同类型而不同地使用这个单元

因此，我们的挑战就是将每条不同指令所需要的计算放入到这样一个统一框架中，示例代码如下所示，跟踪示例来介绍不同指令的行为：
![[Pasted image 20250519133038.png]]

另外，由于涉及到具体的指令集编码，我们将在4.1.2节中已经给出的Y86-64指令集表格 回顾一下：
![[Pasted image 20240913180901.png]]


#### OPq（整数和逻辑运算）、rrmovq（寄存器-寄存器传送）、irmovq（立即数-寄存器传送）类型指令
![[Pasted image 20250519134109.png]]

在y86-64的指令集中，`addq`、`subq`、`andq`和`xorq`都具有相同的icode值，可以使用相同的步骤处理它们，只需要让ALU根据指令ifun中编码的具体操作来计算即可
##### 整数操作指令
根据4-18图展示的通用模式：
- 取指阶段：由于不需要常数字，每个整数操作指令的大小固定为2字节，因此当前整数操作指令的下一条指令起始位置的地址valP = PC + 2
- 译码阶段：读取两个操作数，R\[rA]和R\[rB]代表相应寄存器rA和rB中存储的值
- 执行阶段：译码阶段读取的两个操作数与功能指示符ifun一起提供给算术逻辑单元ALU，计算结果valE = valB OP valA，此时还会设置标志CC
- 写回阶段：将计算得到的valE写到目标寄存器rB中
- 更新PC：将取指阶段得到的valP覆盖PC的值

##### 移动指令
执行移动指令的操作和整数操作指令相差不大，不过它不需要取第二个寄存器操作数valB
因此，在输入ALU时，将第二个输入参数设置为0，这样一来，计算结果valE = valA，即rA寄存器的值。在写回阶段将rB寄存器的值覆盖为valE，即rA寄存器的值，这就完成了移动

注意的是取指阶段，在寄存器移动rrmovq中，下一条指令的地址值valP = PC + 2
而在立即数移动irmovq中，由于第一个参数输入必须是常数值valC，它是8个字节的，因此总体指令是一个10字节的长指令格式， valP = PC + 10
而且valC的读取是$M_8[PC+2]$，代表从PC存储的地址后两个字节处开始，向后读8个字节
同理rA和rB的读取$M_1[PC+1]$就代表从PC存储地址后一个字节处开始向后读1个字节

#### pushq和popq指令
![[Pasted image 20250520224744.png]]

##### pushq



## 这下真该看了


---

# Chapter 5. 优化程序性能
很多情况下，程序运行的速度是我们需要考虑的重要因素，编写高效的程序需要做到：1. 选择适当的算法和数据结构； 2. 编写出**编译器能够有效优化**以转换为高效可执行代码的源代码
对于第二点，由于C语言的一些特性，例如执行指针运算和强制类型转换的能力，使得编译器很难对它进行优化，因此需要我们以一种**编译器更容易产生高效代码的方式**来编写程序。

还有一种方法是对于运算量很大的计算，我们将一个任务分成多份以**并行计算**，这会在12章中讲到

## 5.1 优化编译器 的能力和局限性
现代编译器使用复杂的算法来确定一个程序中计算的是什么值，以及它们被如何使用。之后利用一些机会来简化表达式：**在几个不同的地方使用同一个计算，以及降低一个给定的计算必须被执行的次数**
gcc在内的大多数编译器向用户提供了一些对它们所使用优化的控制。最简单的就是**优化级别**的指定：例如，调用gcc时命令行选项`-Og`使用一组基本的优化，命令行选项`-O1`、`-O2`或更高则会使用更大量的优化
但是**更高的优化等级会带来增加程序规模，导致标准调试工具难以对其进行测试等副作用**，大多数项目最多接受`-O2`等级的优化
我们限制优化级别`-O1`来展现不同的函数编写方法会如何影响编译器产生代码的效率。编译器对程序只使用安全地优化，保证优化后得到的程序与未优化版本的行为相同，例如
```c
void twiddle1(long *xp, long *yp){
	*xp += *yp;
	*xp += *yp;
}
和
void twiddle2(long *xp, long *yp) {
	*xp += 2 * *yp;
}
```
看上去似乎行为相同：都将指针yp指向的值两次加到指针xp指向的位置，而且`twiddle2`的效率更高，因为只要求读\*xp，读\*yp和写\*xp三次内存访问，而`twiddle1`需要6次
但是考虑xp=yp的情况，此时twiddle1中的yp在进行第一次加法赋值后的值也变为了原来的两倍，在第二次加法赋值后，xp指向对象的值变为了原来的四倍；而twiddle2中的xp只变成了原来的三倍

**两个指针可能指向同一个内存位置的情况称为==内存别名使用==，在安全的优化中编译器必须假设不同的指针会指向相同的内存位置**。
再比如，下面的语句：
```c
x = 1000; y = 3000;
*q = y; *p = x;
t1 = *q;
```
在假设指针p和q是否指向同一个内存位置的时候，t1的值会发生改变
**内存别名使用是一个主要的妨碍优化的因素：如果编译器无法确定两个指针是否指向同一位置，就必须考虑到多种假设，从而被限制可能的优化策略**

另一个妨碍优化的因素是**函数调用**，看到下面的示例：
```c
long counter = 0;
long f() {
return counter++;
}

long func1() {
	return f()+f()+f()+f()
}
long func2() {
	return 4*f();
}
```
对于函数func1和func2来说，前者调用f()的次数明显比后者多，如果f()的返回值一定，那么编译器会倾向于生成func2风格的代码
然而，函数f()**修改了全局程序状态的一部分，改变调用次数会改变程序的行为**，这就导致了func1和func2的行为并不一致。
**大部分编译器不会判断函数可能没有副作用的可能性，它们会一律假设为最糟的情况，保持所有的函数调用不变**
gcc编译器就优化能力来说是可以的，但是它不会对程序进行更加激进的优化。因此使用gcc的程序员必须以一种简化编译器生成高效代码任务的方式来编写源程序

## 5.2 表示程序性能
引入度量标准：**每元素的周期数CPE**，来表示程序性能并指导我们改进代码
处理器活动的顺序是由**时钟**控制的：**时钟提供某个频率的规律信号**，通常用**千兆赫兹GHz**（十亿周期每秒）来表示，时钟周期是时钟频率的倒数，用纳秒($10^{-9}s$)或皮秒($10^{-12}s$)为单位。但是使用“多少个时钟周期”的衡量表示的是**执行了多少条指令**，更有助于理解

下面的示例代码计算了一个长度为n的向量的前置和：
$$ \begin{align}
&对于向量\vec{a}=(a_0,a_1,\cdots, a_{n-1}),\\
&前置和\vec{p}=(p_0,p_1,\cdots,p_{n-1}):=\begin{cases}
p_0=a_0 \\
p_i=p_{i-1}+a_i,\quad 1\leq i<n \end{cases}
\end{align}$$
```c
void psum1(float a[], float p[], long n) {
	long i; p[0] = a[0];
	for(i = 1; i < n; i ++)
	p[i] = p[i-1] + a[i];
}
```
算法上来说，这是一个利用了前缀和进行快速计算的小技巧的代码，再看到下面同行为的函数：
```c
void psum2(float a[], float p[], long n) {
	long i; p[0] = a[0];
	for(i = 1; i < n-1; i += 2){
		float mid_val = p[i-1] + a[i];
		p[i] = mid_val;
		p[i+1] = mid_val + a[i+1];
		}
	if (i < n)
		p[i] = p[i-1] + a[i];
}
```
该函数使用了**循环展开**的技术，它减小了循环的次数，这会在后面说到
这样一个过程所需时间可以用一个**关于被处理元素个数的线性函数**来表示，其实就是时间复杂度的计算。通过最小二乘拟合可以得到下面的计算：
![[Pasted image 20240915213554.png]]
$$ T_{psum1}=368+9.0n, T_{psum2}=368+6.0n$$
虽然都是线性时间复杂度，但是psum2的系数更小，**在n较大，算法时间复杂度相同的时候其系数就是主要决定因素**，这些系数称为**每元素的周期数CPE**的有效值，即：
$$ CPE_{psum_1}=9.0 \leq CPE_{psum2}=6.0$$
**我们更倾向于研究每个元素的周期数，而不是每次循环的周期数**，这是因为**循环展开技术可以使我们以更少的循环完成计算**，我们更应该关注给定数据量的情况下程序的运行速度如何

## 5.3 程序示例
我们用下面这个**向量数据结构**来说明程序是如何被系统地转换成更有效的代码的：
![[Pasted image 20240915215306.png]]
**向量由头部和数据数组两个内存块组成，头部结构的声明如下：**
```
typedef struct {
	long len;
	data_t *data;
}vec_rec, *vec_ptr;
```
`data_t`表示**基本元素的数据类型：我们要度量代码对于整数和浮点数数据的性能，为此会用不同的类型来声明编译和运行程序**，例如使用`typedef long data_t`的形式来改变data_t
我们还会分配`len`个长度的`data_t`类型数组，来存放实际的向量元素
一些生成向量、访问向量元素以及确定向量长度的基本过程如下：
```c
vec_ptr new_vec(long len) {
	//为头结构体分配空间
	vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
	data_t *data = NULL;
	if (!result)
		return NULL;    //result指针为空说明无法分配空间
	result->len = len;
	//为数组分配空间
	if (len > 0){
		data = (data_t *)calloc(len, sizeof(data_t));
		if (!data) {
			free((void *)result);
			return NULL;  
	//如果data指针为空，说明分配未成功，记得释放掉为头结构体分配内存时生成的指针再返回空
		}}
	result->data = data;
	return result;
}
```
这是创建一个长度为len的向量并返回一个指向它的指针的过程
下面是访问向量第index个元素，并返回是否成功访问的结果的函数。
```c
int get_vec_element(vec_ptr v, long index, data_t *dest) {
	if(index < 0 || index >= v->len)
		return 0;
	return 1;
}
```
还有获得向量长度的函数：
```c
long vec_length(vec_ptr v){
	return v->len;
}
```
可以看到向量访问程序`get_vec_element`对向量引用进行了**边界检查**，它降低了程序出错的机会，但也会减缓程序的执行


作为一个优化示例，看到下面的代码：**将所有的元素通过某种待定的运算合并为一个值，然后在编译时使用宏来进行不同的定义，使得该代码可以重编译为执行的不同运算**
下面的宏声明执行对向量元素的求和
```
#define IDENT 0
#define OP +
```

下面的宏声明执行对向量元素求乘积：
```
#define IDENT 1
#define OP *
```

下面是代码主体，在需要运算符和初始值的位置使用了宏：
```c
void combine1(vec_ptr v, data_t *dest){
	long i;
	*dest = IDENT;  //初始值

	for(i = 0; i < vec_length(v); i ++){
		data_t val;
		get_vec_element(v, i, &val);
		*dest = *dest OP val;  //执行的操作
	}
}
```
这段代码在后面的讲解中会被写成一系列不同的形式以评估性能的变化
我们会在一个具有 Intel Core i7 Haswell处理器的**参考机**上测量这些函数的CPE性能，性能是相对于该机器而定的，在其他机器和编译器的组合上不一定相同，但是也会有相似的结果
作为一个起点，下表是该`combine1`函数的CPE度量值：
![[Pasted image 20240916183105.png]]
原书将这些数据原封不动地搬了过来，使用很多CPE数看起来没那么规整，因为影响因素比较复杂。可以看见是根据OP、IDENT这两个宏的不同组合分类的。
可以看见，未经优化的代码就是直接对源代码的机器代码翻译，效率通常较低，使用-O1优化后就会显著地提升程序性能，**我们至少要习惯使用-O1级别的优化**
总之，接下来我们使用-O1和-O2级别的优化来生成和测量程序

## 5.4 消除循环的低效率
在过程`combine1`中的for循环中，调用了函数`vec_length`作为其测试条件，所以在翻译成机器级程序时，根据3.6.7节可知**每次迭代都需要为`vec_length`求值；而我们知道向量长度，即`vec_length`的返回值并不会随迭代次数而改变，因此我们只需要计算一次`vec_length`就行**
下面就是根据该思想修改的版本：
```
void combine2(vec_ptr v, data_t *dest) {
	long i;
	long length = vec_length(v);
	*dest = IDENT;
	for (i = 0; i < length; i ++) {
		data_t val;
		get_vec_element(v, i, &val);
		*dest = *dest OP val;
	}
}
```
也就是直接先把固定的长度求出来，以免每次都要调用求长函数。该过程与combine1的性能比较如下：
![[Pasted image 20240916184752.png]]
这样的优化称为**代码移动：识别要执行多次（循环中）但计算结果不会改变的计算，将计算移动到不会被多次求值的部分中去**
虽说编译器会试着进行代码移动，但它还是会非常小心地假设函数是会有副作用的而不去移动它。因此，**程序员往往需要帮助编译器显式地完成代码移动**

看到下面这个典型的例子：
![[Pasted image 20240916185733.png]]
两个函数都试图将A到Z范围内的大写字母转换为小写，但是对于`lower1`，**它每次循环都要调用一次`strlen`，这个函数本身的实现又要求遍历一遍字符串，所以整体运行时间是字符串长度n的二次方$n^2$**
而`lower2`使用了代码移动，性能明显优于`lower1`：
![[Pasted image 20240916190012.png]]
这直接将二次时间复杂度变为了线性，性能提升非常明显。但不幸的是，编译器并无法一一考虑到所有可能遇到的情况下这都不会出错，所以它会干脆不进行这样的优化
~~小小的代码片段带来的性能损失会有如此之大~~

## 5.5 减少过程调用
**过程调用会带来开销，并且妨碍大多数形式的程序优化**。在`combine2`的代码中，我们看见每次循环迭代都会调用`get_vec_element`来获得下一个向量元素，这个函数会把向量索引i与循环边界多次比较，带来效率的损失。
根据我们的简单分析，对于`combine2`来说所有的引用都是合法的，无需进行过多的边界检查，所以作为替代，假设为我们的抽象数据类型增加一个**返回数组起始地址的函数**`get_vec_start`，我们就可以不必调用函数来访问元素，而是直接访问数组：
```
data_t *get_vec_start(vec_ptr v) {
	return v->data;
}

void combine3(vec_ptr v, data_t *dest) {
	long i;
	long length = vec_length(v);
	data_t *data = get_vec_start(v);
	*dest = IDENT;
	for(i = 0; i < length; i ++) {
		*dest = *dest OP data[i];
	}
}
```
然而令人吃惊的是，**性能并没有明显的提升，甚至对于整数求和还略有下降**，这说明循环的过程中的其他操作形成了瓶颈，对性能的限制超过了调用`get_vec_element`的边界检查
![[Pasted image 20240916201708.png]]

## 5.6 消除不必要的内存引用
我们检查一下`combine3`的汇编代码，针对浮点数的求积：
```
Inner loop of combine3 . data_t = double, OP=* 
dest in %rbx, data+i in %rdx , data+length in %rax
.L17:
	vmovsd    (%rbx),%xmm0        从dest指向的内存中读取初始值，存入%xmm0
	vmulsd    (%rdx),%xmm0,%xmm0  用data[i]去乘上这个值
	vmovsd    %xmm0,(%rbx)        储存乘后的值到dest指向的内存地址
	addq      $8,%rdx             计算data + i
	cmpq      %rax,%rdx           与data+length比较
	jne       .L17                若data+i != data+length，进行跳转
```
可以发现，**combine3的代码会把计算的值累计在dest指针指向的内存位置**，而我们每次迭代的时候，都要**把这个数值取出存入`%xmm0`，然后用`data[i]`乘了之后再存回`(%rbx)`**，这样就造成了**没有必要的内存读写**
因此，我们考虑优化这种不必要的内存读写，**引入一个临时变量来存储累计计算出来的值，再循环结束后才把这个临时变量的值存放在dest指向的内存位置中**，这样只需要一次读：
```
void combine4(vec_ptr v, data_t *dest) {
	long i;
	long length = vec_length(v);
	data_t *data = get_vec_start(v);
	data_t acc = IDENT;

	for(i = 0; i < length; i++) {
		acc = acc OP data[i];}
	*dest = acc;
}
```
这个代码为`acc`变量**单独申请了一个寄存器储存值**，于是只需要在寄存器之间进行运算，无需多次访问内存，从而空间换时间获得了显著的性能提升：
![[Pasted image 20240916210151.png]]

编译器当然又不能自动地进行这样的转换了，因为它没办法判断程序员是什么目的而生成中间变量，只能选择保守地不断读和写内存

## 5.7 理解现代处理器
目前为止，我们的优化都不依赖于目标机器的任何特性，而是简单地降低了调用过程的开销以及妨碍优化的因素。为了进一步提高性能，**必须考虑利用处理器==微体系结构==的优化，即处理器用来执行指令的底层系统设计**
因此这需要我们理解现代处理器的微体系结构，
处理器的实际操作与观察机器级程序所察觉到的大相径庭：**在代码层次上看上去似乎是一次执行一条指令，但在实际的处理器中，是同时对多条指令进行求值的，这就是==指令级并行==**。现代微处理器的一个功绩就是使用复杂的硬件结构来使得多条指令并行的同时又呈现出一种简单的顺序执行指令的表象。
我们需要足够了解这种指令级并行的实现方法，我们会发现两种下界描述了程序的最大性能：
- **延迟界限：在下一条指令开始前，当前指令必须结束。当代码中的数据相关==限制了处理器利用指令级并行的能力==时，就是延迟界限限制了程序性能**
- **吞吐量界限：刻画处理器功能单元的==原始计算能力==，是程序性能的终极限制**

### 5.7.1 整体操作
下图是现代微处理器的一个极简化示意图，不太严格地基于当时的Intel处理器结构：
![[Pasted image 20240916212656.png]]
这些处理器称为==**超标量==，可以在每个时钟周期执行多个操作**；而且是**乱序的：指令执行的顺序不必和它们在机器级指令中的顺序一致**
整个设计由**指令控制单元ICU和执行单元EU**两部分组成，**前者负责从内存中读出指令序列，并根据它们生成一组针对程序数据的基本操作；后者负责执行这些操作**

指令控制单元ICU从**指令高速缓存**中读取指令，这是一个特殊的高速存储器，包含最近访问的指令。通常**ICU会在当前正在执行的指令之前很早取到下一条指令**，这样才有足够时间进行指令译码并发给EU，但是程序遇到分支时就会有跳转和下一条指令两种可能。
为此，现代处理器采取**分支预测技术**来**猜测是否会选择分支以及分支的目标地址是什么**：使用**投机执行技术**，处理器取出位于它**预测的分支会跳到的地方的指令**，并且对指令进行译码，这些操作甚至**在确定分支预测是否正确之前就开始执行**了。而若确定**预测错误，则会将状态重新设置到分支点的状态，开始取出和执行另一个方向的指令**
指令译码就是接受实际的程序指令并转换为一组基本操作（微操作），但是如何译码是底层的机密细节，但我们可以不需要知道这些也能优化自己的程序
在x86的典型实现中，**一条只对寄存器操作的指令会被转换为一个操作；而一条具有一个或多个内存引用的指令会产生多个操作：把内存引用和算术运算分开，译码为三个操作：1.从内存中加载一个值到处理器中；2.将加载的值与寄存器中的值进行运算；3.将结果存回内存**

在上图中，“**取指控制**”的块包含分支预测的功能，用于确定该取出什么指令；执行单元EU接受取指单元的多个操作，分派到一组**功能单元**中执行实际的不同类型的操作
读写内存则是由**加载和存储单元**实现的：**加载单元处理从内存读数据到处理器的操作，由一个加法器完成地址计算；存储单元处理从处理器写数据到内存的操作，也有一个地址计算的加法器。** 在上图中，它们通过**数据高速缓存**来访问内存，它**存储最近访问的数据值**

使用投机执行对操作求值的最终结果不会放到寄存器或数据内存中，除非处理器确定应该实际执行它们。**分支操作会被送到EU以确定预测结果是否正确**，如果预测错误就会指出正确的分支目的并且丢弃计算结果，**在新的位置取指**。这就导致了很大的**性能开销**
上图还说明**有不同的功能单元来执行不同操作**：算术运算的单元执行整型和浮点数操作及其不同组合的运算，还有一些用于加载、地址运算和存储、分支等。**基础的加法、位级操作被归类为整数运算**，乘除法则需要更多资源，下面是每个单元的功能分布：
![[Pasted image 20240917184643.png]]
这样的组合可以同时执行多个同类型操作，这些资源对程序获得最大性能有很大影响

ICU中的**退役单元**则用来**记录正在进行的处理，并且确保它遵守机器级程序的顺序语义**，上图中退役单元中的**寄存器文件**就包含整数、浮点数和最近的 SSE 和 AVX 寄存器
指令译码时，**关于指令的信息被放在一个先进先出的==队列==中**，它会一直保持在队列中直到：要么分支点被确认为正确，此时指令可以**退役**了，并且**执行对程序寄存器的更新**；要么确认为预测错误，这条指令被**清空**，丢弃所有计算结果
因此，**只有退役时才会发生对程序寄存器的更新**

控制操作数在执行单元间进行传送的最常见机制是**寄存器重命名**：当一条**更新寄存器r的指令**被译码时，**产生标记t**，得到一个**指向该操作结果的唯一标识符**，条目$(r,t)$被加入一张**维护寄存器r与更新该寄存器的操作表示t之间的关联**的**重命名表**中，在随后为该指令译码时，发送到执行单元的操作会**包含标记t作为操作数源的值**。当**某个执行单元完成第一个操作时生成结果$(v,t)$指明该标记为t的操作产生值v，所有等待t作为源的操作都能使用v作为源值**，这样就可以实现从一个操作直接到另一个操作的**数据转发**，而不必写到寄存器文件后再读出来
**重命名表只包含有未进行写操作的寄存器条目**，这样只要一个指令需要寄存器r时，就可以直接从寄存器文件中获取这个操作数，这样一来就可以**在不更新寄存器的情况下也能进行预测**

### 5.7.2 功能单元的性能
下图是因特尔i7参考机的一些算术性能，这些时间对于其他处理器也具有代表性。
![[Pasted image 20240920194501.png]]
**延迟：完成运算的总时间；发射时间：两个连续的同类型的运算之间需要的最小时钟周期数；容量：能够执行该运算的功能单元的数量**
可以看见，整数运算到浮点数运算的延迟是增加的；加法和乘法运算的发射时间都为1，也就是说每个时钟周期，处理器都可以开始一条新的这样的运算
很短的发射时间是通过**流水线**实现的，把功能单元实现为一系列的**阶段**，每个阶段完成一部分运算，**这要求算术运算是连续的，在逻辑上是独立的**。发射时间为1的功能单元称为**完全流水线化的**，例如除法器就不是，**除法器的发射时间等于延迟**，意味着**在开始一条新的运算之前，它需要完成整个除法**，而且延迟和发射时间在一个范围内，这是因为对有些除数和被除数来说执行步骤需要更多。**容量大于1的运算是因为有多个参考单元**
另一种发射时间的表达是指明该功能单元的**最大吞吐量**，它是**发射时间的倒数**，也就是一时钟周期的两连续同类型运算的执行次数，**对于容量C，发射时间I的操作来说，处理器可能获得的吞吐量为C/I个操作**，比如该参考机每时钟周期可以执行两个乘法运算。这可以被用于提升程序性能

这些算术运算的延迟、发射时间和容量会影响合并函数`combine`的性能，用每元素周期数CPE的两个基本界限来描述就是：
![[Pasted image 20240920202919.png]]
延迟界限是**任何必须按照严格顺序完成合并运算的函数所需要的最小CPE值**；而吞吐量界限是**CPE的最小界限**，例如只有一个发射时间为1的整数乘法器时，机器不可能支持每个时钟周期执行大于1条乘法运算的速度
**从内存中读数据的需求也会产生吞吐量界限的限制**，因为**加载单元限制了加载的速度**，间接影响了运算单元的性能，尽管运算单元可能有更大的吞吐量

### 5.7.3 处理器操作的抽象模型
观察目前最快的`combine4`函数的CPE：
![[Pasted image 20240920205132.png]]
可以发现除了加法以外的**测量值与处理器的延迟界限一致，这表明函数的性能是由所执行的求和或乘积计算主宰的**

我们会使用程序的**数据流**来分析在现代处理器上执行的**机器级程序**，它图形化的表示方法展现了不同操作之间的数据相关是如何限制程序的性能的，以`combine4`为例：
我们主要关注循环执行的那些运算，这是决定性你的主要因素。考虑double数据的乘法合并运算，汇编代码：
```
Inner loop of combine4 . data_t = double, OP = * 
acc in %xmmO, data+i in %rdx, data+length in %rax
.L25:
	vmulsd    (%rdx),%xmm0,%xmm0            用data[i]乘acc
	addq      $8,%rdx                       i++
	cmpq      %rax,%rdx                     与data+length比较
	jne       .L25                          若!=，进行跳转
```
而在我们假想的处理器设计中，指令译码器将这些指令扩展为一系列5步的操作：最开始的乘法指令被扩展为一个load和mul操作，用于执行从内存中读取和乘法操作
![[Pasted image 20240920211029.png]]
上图中的线和方框给出各个指令使用和更新寄存器的方式：顶部方框是循环开始时寄存器的值，底部则是它们最后的值，中途经过的操作方框指示它们在过程中发生的操作是什么
右边操作框外有些箭头从操作框指向操作框，代表产生的值直接传给操作，而不经过寄存器

可以访问到的寄存器分为：只读——只用作源值，不被修改；只写——只用作目的；局部——在循环内部被修改和使用，**不同迭代之间不相关**；循环——既作为源值，也作为目的，**一次迭代中的值会被另一次迭代用到**
其中，==**循环寄存器==之间的操作链决定了限制性能的数据相关**，将原图进行重排列，将不属于循环寄存器之间的相关链的操作给标白或去掉：
![[Pasted image 20240920213233.png]]
可以发现，程序的浮点乘法器成为了主要的制约资源，读取、跳转、移动和测试指针等操作是与乘法器并行执行的，因此即使很快，还是受乘法器的制约，这称为**关键路径：执行一组机器指令所需时钟周期数的一个下界**，**设其运算延迟为L，当L大于1时测量出来的CPE就是L**

综上所述，`combine4`的关键路径长是对程序值acc的连续更新造成的，将CPE限制为最多长为浮点乘法器的延迟L。接下来我们的目标就是：**重新调整操作结构，增强指令级并行性，使得唯一的限制变成吞吐量界限**

## 5.8 循环展开
循环展开是一种程序的变换：**通过增加每次迭代计算的元素的数量，从而减少循环的迭代次数**。例如求前缀和时每次循环求两个元素，使得迭代次数减半
**循环展开减少了不直接有助于程序结果的操作的数量，比如索引的计算和条件分支；同时提供了可以减少计算中关键路径上的操作数量的代码变换**

以下面的“2\*1循环展开”为例说明"k\*1循环展开“的思想：
```CPP
void combine5(vec_ptr v, data_t *dest) {
	long i;  //循环变量i要用在两个for中，所以单独提出来
	long length = vec_length(v);
	long limit = length - 1;   //为了防止越界，设置上限为长度-1
	data_t *data = get_vec_start(v); 
	data_t acc = IDENT;

//2*1循环展开：一次计算两个元素
	for (i = 0; i < limit; i += 2) {
		acc = (acc OP data[i]) OP data[i+1];
	}
//由于向量长度不一定为2的整数倍，所以单独处理一下剩余元素
	for ( ; i < length; i++) {
		acc = acc OP data[i];
	}
	*dest = acc;
}
```
代码中，在一次迭代下对acc进行两次处理，由于向量长度不一定是2的倍数，同时为了防止索引越界，将第一个for循环的范围限制在`length - 1`，然后在i停下的地方继续往前遍历处理剩余的元素

因此对上面的思想进行归纳，**一个循环按任意因子k进行"k\*1循环展开”时，上限应设置为`n-k+1`，循环内合并运算的元素为`i`到`i+k-1`，每次循环有`i += k`，然后第二个循环从最后一个`i`开始处理剩余元素**

可以看见循环展开后的CPE：
![[Pasted image 20240922131318.png]]
由于整数乘法和浮点数乘除法已经到达延迟界限，只有整数加法有CPE的改进，但是**经过多次循环展开后CPE的改进并不会超过延迟界限**，其原因可以从机器代码看到：
当data_t为浮点数，OP为乘法时，生成的机器代码为：
```
nner loop of combines. data_t = double, OP = * 
i in %rdx, data %rax, limit in %rbp, acc in %xmm0
.L35:
	vmulsd    (%rax,%rdx,8),%xmm0.%xmm0    用data[i] * acc
	vmulsd    8(%rax,%rdx,8),%xmm0,%xmm0   用data[i+1] * acc
	addq      $2,%rdx                      i += 2
	cmpq      %rdx,%rbp                    比较limit和i
	jg        .L35                         若limit > i,跳转
```
相比`combine4`，gcc生成的代码使用了**数组引用的更直接转换**：索引i在寄存器%rdx中，data_t地址在寄存器%rax中，**使用`vmulsd`将数组从内存加载出来，再乘进累计值的寄存器中**。
抽象为数据流图就可以看见：**尽管减少了迭代次数，但循环展开的每次迭代中还是要进行k次顺序的乘法操作，并没有消除关键路径的性能制约**
![[Pasted image 20240922133817.png]]

不过幸运的是，**编译器可以很容易地自动执行循环展开，只需要调高编译器的优化等级（3以上）就会执行了**

## 5.9 提高并行性
程序的性能是受运算单元的延迟限制的，执行加法和乘法的功能单元是**完全流水线化的**，它们可以在每个时钟周期开始一个新操作，一些操作还可以被多个功能单元执行。但是这样的能力并不能被之前的代码使用，这是**因为我们将累积值全部放在一个单一变量acc中，在一个计算完成之前不能计算它的新值，导致只能在每L个时钟周期才能开始一个新操作，L是运算操作的延迟**
现在我们得考虑打破这种**顺序相关**，获得比延迟界限更好的性能
### 5.9.1 多个累积变量
对于一个**可结合和可交换的运算**，例如乘法和加法来说，我们可以**将一组运算分割成两个或更多的部分，在最后合并结果来提高性能**，例如：
$$\begin{align}
&若P_n+\prod_{i=0}^{n-1}a_i，当n为偶数时，可以使用下面的变量：\\
&PE_n=\prod_{i=0}^{n/2-1}a_{2i}\quad;\quad PO_n=\prod_{i=0}^{n/2-1}a_{2i+1}\\
&来表示索引为偶数和索引为奇数部分的乘积
\end{align}


$$
这样的表示方法既使用了两次循环展开，也使用了**两路并行：将元素累计在不同的变量中**，因此我们可以称其为**2\*2循环展开**，最后对两个变量应用合并运算来计算最终结果
![[Pasted image 20240922140923.png]]
可以看见所有情况都有所改进，而且**除了整数加法以外，CPE都降低至延迟界限的一半**。利用数据流图：
![[Pasted image 20240922141326.png]]
可以看见右侧操作框中的`load`和`mul`所组成的`vmulsd`指令变为了两个，意味着**现在有两条关键路径**，这代表**程序正在利用功能单元的流水线能力，将利用率提高为两倍**
但是整数加法还是有太多循环开销，比理论上的0.50提升要高一些

将这种思想归纳为：**将循环展开k次，同时并行累计k个值，执行k\*k循环展开，当k值足够大时，程序的CPE在所有的情况下都能逼近吞吐量界限**
通常，**只有保持能够执行该操作的所有功能单元的流水线都是满的时，才能达到这个操作的吞吐量界限**，即：
**对于延迟L，容量C的操作，要求循环展开因子$k\geq C*L$**，例如浮点乘的C=2，L=5，则k必须满足$k\geq 10$才能达到吞吐量界限

同时，**使用k\*k循环展开变换的原始函数必须是==可交换且可结合的==，以免产生不一样的值** 例如**补码运算**就是这样，包括溢出时也满足可交换和可结合性，因此可以使用**
而**浮点乘和浮点加则因为其舍入和溢出不可结合**，所以使用这样的循环展开后可能会得到一个不一样的值。不过对于需要使用**浮点运算**的场合，**性能翻倍的获利比不上结果不对的风险，因此大多数编译器并不会对浮点运算产生这样的优化**

### 5.9.2 重新结合变换
另一种打破顺序相关以提高程序性能的方法是从根本上改变合并执行的方式，以下面的代码为例：
```
void combine7(vec_ptr v, data_t *dest) {
	long i;
	long length = vec_length(v);
	long limit = length-1;
	data_t *data = get_vec_start(v);
	data_t acc = IDENT;

	for (i = 0; i < limit; i+=2) {
		acc = acc OP (data[i] OP data[i+1]);	
	}

	for ( ;i < length; i++) {
		acc = acc OP data[i];
	}
	*dest = acc;
}
```
区别在于第一个循环中的`acc = (acc OP data[i]) OP data[i+1]`被修改为了`acc = acc OP (data[i] OP data[i+1])`，看似与k\*1循环展开区别不大，但是比较性能可以发现有所提高：
![[Pasted image 20240922145325.png]]
除了整数加以外的操作的性能是k\*1循环展开的两倍
**这个修改中的第一个运算`data[i] OP data[i+1]`不需要等待前一次迭代的累积值就能执行，因此最小的可能CPE变为原来的1/2**
该函数抽象出来的数据流图：
![[Pasted image 20240922204640.png]]
可以看见**只有一个`mul`操作(最下面的)形成了循环寄存器间的数据相关链，另一个mul操作在内部，不需要等待上一次迭代的值就可以进行**
这也称为**k\*1a循环展开**，它同样**要求运算是可结合的，以防导致结果错误**，例如浮点数运算，但**大多数情况下浮点运算是可以这样重新结合的**

大多数编译器不会对浮点运算做重新结合，因为不一定是可结合的；对整数运算会执行重新结合，但效果不一定好


> [!NOTE] 使用AVX扩展生成向量指令可以达到更高的并行度
> 单指令多数据SIMD执行模型**使用单条指令对整个向量数据**进行操作，这些**向量保存在一组向量寄存器%ymm0~%ymm15中，目前长32字节**。这些数据既可以是整数也可以是浮点数，**使用AVX指令可以对这些寄存器执行并行向量操作**
> 例如若%ymm0中包含8个单精度浮点数，%rcx储存了8个单精度浮点数在内存中的地址，那么指令 `vmulps (%rcx),%ymm0,%ymm1`就是把内存中的这8个数读出，乘上%ymm0中的8个数，保存到%ymm1中，一条指令对8个值进行了操作，8路并行
> 所以，向量化的机器代码有利于达到更高的并行度，**GCC支持对C语言的扩展，使得程序员在程序中可以使用向量操作**，**即使用GCC的向量扩展语法编写代码**，编译时启用选项`-mavx`：`gcc -mavx -o name name.c`就行了
> 语法例如定义一个256位的向量类型：`typedef float v4sf __attribute__ ((vector_size (32))); // 8个float`

## 5.11 限制因素
程序的数据流表示图的关键路径指明了该程序所需时间的一个基本下界，这条链的上的所有延迟之和T就是程序至少需要的始终走起


P378

---


399
# Chapter 6. 存储器的层次结构
**存储器系统**是一个具有不同容量、成本和访问时间的**存储设备的层次结构**
==**CPU寄存器==保存着最常用的数据**，靠近CPU的小且快速的==**高速缓存存储器==作为慢速主存储器中数据和指令的缓冲区域**，而==**主存==缓存容量较大且慢速的磁盘中的区域**，最后==**磁盘==又常常作为存储在其他机器磁盘或磁带上的数据的缓冲区域**

这样的存储器层次结构是可行的：**具有良好==局部性==的程序倾向于一次又一次地访问相同的数据项集合，或是倾向于访问邻近的数据项集合**，程序的局部性和连续性往往也是决定程序性能的关键

温馨提示：存储器是CPU和内存之间的部分，而我们之前说的寄存器是CPU中的临时存储单元，暂存数据和指令，速度是最快的。本章并不讨论它们

## 6.1 存储技术
### 6.1.1 随机访问存储器
随机访问存储器RAM分为**静态RAM（SRAM）和动态RAM（DRAM）**，静态更快且更贵
**SRAM用于作为==高速缓存存储区==，DRAM则用来作为==主存==和==图形系统的帧缓冲区**==。一般来说，一个桌面系统的DRAM字节数远大于SRAM
#### 1. 静态RAM
SRAM**将每个位存储在一个双稳态的存储器单元中**，每个单元使用一个六晶体管电路实现，它可以无限期地保持在两个不同电压配置（状态）之一，其他的状态都不稳定
因为它的**双稳态特性**，SRAM在即使有电子噪音等干扰的情况下，在消除干扰后**电路电压依然能恢复到稳定值**

#### 2. 动态RAM
DRAM**将每个位存储为对一个电容的充电**，电容非常小，DRAM由很密集的单元组成，每个单元由一个电容和一个访问晶体管组成。
**DRAM对干扰非常敏感，电容的电压被扰乱后就永远不会恢复了**

可以发现，**SRAM比DRAM使用了更多的晶体管，因而密集度低，更贵且功耗更大**

#### 3. 传统的DRAM
DRAM芯片中的单元被划分为d个**超单元**，每个超单元由w个**DRAM单元**组成，所以**一个$d* w$的DRAM总共存储了$d*w$位的信息**
超单元是一个r行c列的长方形阵列，有$r*c=d$，每个超单元有形如$(i,j)$的地址，前面是行标，后面是列标
信息通过被称为**引脚**的**外部连接器**流入和流出芯片，**每个引脚携带一个1位的信号**
看到下面的示意图：
![[Pasted image 20241103215735.png]]
右边是芯片，上面的一个格子就是一个超单元；内存控制器和芯片之间有两组引脚：8个`data`引脚，**8个引脚传送或传出一个字节**；2个`addr`引脚，**2个引脚携带2位标识行和列的超单元地址**
当然还有其他引脚没有标注

每个DRAM芯片被连接到某个称为**内存控制器**的电路，它**可以一次传送w位到每个DRAM芯片，或是一次从DRAM芯片中传出w位**，所以通过引脚`addr`，内存控制器将**行地址i（行访问选通脉冲RAS）和列地址j（列访问选通脉冲CAS）** 发送给DRAM，然后DRAM将该位置$(i,j)$超单元的内容发送回控制器作为相应
可以只有RAS或只有CAS，表示一整行或一整列的内容。
**内部行缓冲区用于首先将请求内容复制到它上面，然后再通过`data`引脚发送回内存控制器**

DRAM组织成这样的二维阵列的好处在于可以**降低芯片上引脚的数量**（需要更少的地址引脚`addr`就能表示更多的位置），但坏处在于**必须分两步发送地址，增加==访问时间**==

### 4. 内存模块
**DRAM芯片封装在内存模块中**，被插在主板的扩展槽上，**引脚就附在内存模块上**
例如，core i7系统使用240个引脚的双列直插内存模块，以64位为块传送和传出数据

一个内存模块的基本思想可以表示为下图：
![[Pasted image 20241103221615.png]]
这是一个具有$DRAM0\sim DRAM7$，共8个64Mbit的DRAM芯片的内存模块，一共存储64MB（64兆字节）。**每个DRAM的超单元存储主存的一个字节**，用相应超单元地址$(i,j)$访问8个DRAM上的超单元来存储一共$8*8=64$位的内容，**主存地址A通过转换变为$(i,j)$超单元地址**
而在取出它时，先**把主存地址A转换为超单元地址**，然后**从相应超单元中取出8位**，在**内部行缓冲区中合并为64位字，返回给内存控制器**

**将==多个内存模块==连接到==内存控制器==，就聚合成为了==主存**==
这时，**控制器接收到一个地址A时，选择包含A的相应内存模块，把A转换为超单元地址的形式，发送给该模块，进行读取或写入**

### 5. 增强的DRAM
DRAM存储器种类有很多，每一种都基于传统的DRAM单元，进行一些优化，提高访问基本单元的速度
包括：快页模式DRAM，扩展数据输出DRAM，同步DRAM，双倍数据速率同步DRAM，视频DRAM等等

### 6. 非易失性存储器
如果断电，DRAM和SRAM就会丢失它们的信息，所以是**易失的**
**非易失性存储器**则即使在关电后，也仍然保存着信息，它们整体上被称为**只读存储器ROM**（虽然其中一些可以被读写）
**可编程ROM只能被编程一次**，这是因为它里面的每个存储器单元有一种熔丝，只能被高电流熔断一次
**可擦写可编程ROM可以被多次编程**，这是因为它有一个透明的石英窗口，使得光能够到达存储单元，对单元进行清除
**闪存**也是一类**非易失性存储器**，它非常流行，广泛用于大量电子设备
**固态硬盘则是一种基于闪存的磁盘驱动器**，提供比传统旋转磁盘更快速，更强健和更低能耗的选择

存储在**ROM**中的**程序**称为==**固件**==，**这些程序提供少量基本的输入和输出函数，我们电脑的基本输入输出系统BIOS例程就是一个例子**

### 7. 访问主存
数据流是通过被称为==**主线**==的**共享电子电路**在处理器和DRAM主存之间传递的。**CPU和主存之间为了传送数据而执行的一系列步骤称为==总线事务==**，例如：
**读事务**从**主存**传送数据到**CPU**；而**写事务**从**CPU**传送数据到**主存**

**总线是一组并行导线，携带地址、数据和控制信号**，数据与信号可以共享同一组导线，也可以不共享，**多个设备也能共享同一总线**
**控制线**所携带的信号完成**同步事务，并且标识当前被执行的事务类型**的工作

下面是一个计算机系统配置的示例：
![[Pasted image 20241104184207.png]]
（影印原因，CPU芯片、IO桥接器和主存之间的两组总线不明显）
可以发现，**系统总线连接CPU和I/O桥接器；内存总线连接I/O桥接器和主存**
**I/O桥接器**将**系统总线的电子信号**翻译为**内存总线的电子信号**，它们用于控制各元件的沟通
**I/O桥接器还会将系统总线和内存总线连接到==I/O总线==，用于I/O设备共享使用**

> [!NOTE] Intel的南北桥芯片架构
> 早期的芯片组分为两个I/O桥接器：**负责连接快速CPU、内存与显卡接口等元件的北桥**和**负责连接速度较慢的设备接口的南桥**。在目前的主流架构中，大多将北桥内存控制器整合在CPU封装中了，所以看不到北桥芯片

考虑当CPU执行下面这个**加载操作**时：
```
movq A, %rax
```
内存地址A的内容被加载至寄存器`%rax`中，此时**总线接口会在总线上发起读事务**
读事务由三个步骤组成：
- 首先，CPU把地址A放到系统总线上，**通过I/O桥接器传递给内存总线**
- 然后，主存获取内存总线上的地址信号，读出地址后翻译为DRAM中的超单元地址，**从DRAM中取出数据字，并把数据写到内存总线**，通过I/O桥接器翻译成**系统总线**信号，传递给CPU
- CPU感觉到系统总线中传来的数据，**将数据读出**并且复制到寄存器`%rax`

同理，当CPU执行下面的**存储操作**时：
```
movq %rax, A
```
此时，寄存器`%rax`的内容被写到内存地址A处，**CPU会发起写事务**
同样由三个步骤组成：
- CPU将**地址放在系统总线**，通过I/O桥接器进入内存总线，并被内存读出
- CPU将寄存器`%rax`中的**数据字复制**到系统总线，并通过IO桥接器进入内存总线
- 最后，主存从内存总线中读出数据，把数据存储到DRAM中

### 6.1.2 磁盘存储
前面基于随机访问存储器RAM的**存储数据量远低于磁盘**的存储数据量，但从磁盘中读**取信息的速度远慢于从RAM**中读取

#### 1. 磁盘构造
**磁盘由==盘片==构成**，每个盘面有**两个表面**，表面覆盖着**磁性记录材料**
盘片中央有一个可以旋转的**主轴**，**主轴使盘片以固定旋转速率旋转**，这样的盘片在磁盘中有多个，被包含在密封容器内
![[Pasted image 20241104194615.png]]
**盘面的表面**由一组称为**磁道**的同心圆组成，每个磁道被划分为一组**扇区**，**每个扇区中包含数量相等的数据位**，扇区之间由一些**不存储数据位的间隙**分隔开，**间隙存储的是用于标识扇区的==格式化位==**

> [!NOTE] 扇区是怎么存储位的？
> 扇区**通过其上微小的磁性颗粒的磁极表示位**。
> 具体来说：每个扇区由许多微小的磁性颗粒组成，硬盘通过**改变这些颗粒的磁极**来存储二进制位（0和1）。具体来说，磁性颗粒的磁极方向不同，代表不同的二进制值。例如，颗粒磁化方向向一个方向可能表示“1”，而向另一个方向可能表示“0”
> 硬盘的磁头（Read/Write Head）在扇区上移动，**通过电磁感应改变或检测颗粒的磁极方向**，从而实现数据的写入和读取

多个叠放在一起的盘片被包含在密封容器内，就组成了**磁盘驱动器**，简称**磁盘**或**旋转磁盘**（因为还有基于闪存的固态硬盘）
**柱面是所有盘片表面上的与主轴中心距离相等的==磁道的集合**==

#### 2. 磁盘容量
一个磁盘上**可以记录的最大位数**就是最大容量，简称**容量**，由以下技术因素决定：
- 记录密度（位/英寸）：磁道一英寸的段中可以放入的位数
- 磁道密度（道/英寸）：从盘片中心出发的半径上，一英寸的段内所含有的磁道数
- 面密度（位/平方英寸）：= 记录密度 \* 磁道密度

现代的磁盘制造商提高面密度以提高磁盘容量，但是原始扇区的设计有一个问题：**每个磁道的扇区数（扇区存储的位数）是固定的，这使得越往外层，物理长度越宽，每个位的间距越大，即扇区之间不存储数据位的间隙越大**，造成了不可接受的浪费
为了解决这个问题，**现代大容量磁盘**采用**多区记录**的技术：**柱面集合**被分隔成**不相交的记录区**子集合，每个区包含一组连续柱面，每个柱面的每条磁道的扇区数量相同，**扇区数量由该记录区内最里面的磁道所能包含的扇区数决定**

计算公式：
$$ 磁盘容量=\frac{字节数}{扇区}\times \frac{平均扇区数}{磁道} \times \frac{磁道数}{表面}\times \frac{表面数}{盘片} \times \frac{盘片数}{磁盘}
$$
最后就能计算出以字节为单位的磁盘容量了，一般以$1GB=10^8字节$ 或 $1TB=10^{12}字节$ 为单位

#### 3. 磁盘操作
磁盘使用**读/写头**来**读写存储在磁性表面的位**，读写头连接到**转动臂**的一端：
![[Pasted image 20241104203033.png]]
沿着半径轴，像唱片那样前后移动转动臂，**驱动器能够将读/写头定位至盘面上的任何磁道**。
当磁道上的每个位通过它的下面时，读写头可以对这个位的值读或写
如b图所示，**多盘片的磁盘在每个盘面上都有一个独立的读/写头**，它们垂直排列，独立行动：**任何时刻，所有的读/写头都位于同一个柱面**

读写头大约在磁盘表面高度约0.1微米处，且速度很快（80km/h），所以盘面上的任何一点灰尘都会对它产生巨大的反冲力（读/写头冲撞），这就是磁盘密封包装的原因

磁盘读写数据是以扇区大小的块来进行的，对扇区的**访问时间**分为：
- **寻道时间**：将读写头**定位到包含目标扇区的磁道上的时间**
- **旋转时间**：定位完成后，驱动器**等待目标扇区的第一个位旋转到读写头下的时间**，依赖于读写头当时的位置以及磁盘旋转次数
$$ 最大旋转延迟 T_{maxrotation}=\frac{1}{RPM}\times \frac{60s}{1min}
$$
平均旋转时间$T_{avgrotation}$是它的一半

- **传送时间**：驱动器**读或写一个扇区所需要的时间**，依赖于旋转速度和每条磁道的扇区数目
$$ 平均传送时间T_{avgtransfer}=\frac{1}{RPM}\times \frac{1}{每条磁道的平均扇区数}\times \frac{60s}{1min}$$
在实际应用时，有一些很重要的问题：
- 访问磁盘扇区中全部512个字节所消耗的时间主要是寻道时间和旋转时间。**寻找第一个字节的时间很长，但是剩余字节的传送时间很短**
- **寻道时间和旋转时间大致相同，传送时间很小，可以直接将寻道时间乘2来估计磁盘访问时间**
- 对存储在SRAM中的一个64位字的访问时间约为`4ns`，DRAM则是`60ns`，所以从磁盘中读取数据所需要的访问时间是从SRAM中读取的40000倍，是DRAM的2500倍。可见**从随机访问存储器中读取数据要比从磁盘中读取数据快很多**

#### 4. 逻辑磁盘块
从前面的叙述可以看见，磁盘的物理构造复杂，为了向操作系统隐藏这样的复杂性，现代磁盘把其构造以更简单的视图呈现：**一个由B个扇区大小的==逻辑块==组成的序列**，编号为$0,1,\dots ,B-1$
磁盘封装中的硬件+固件设备==**磁盘控制器==维护逻辑块号与物理磁盘扇区之间的映射关系**

磁盘控制器上的固件程序执行一个**快速表查找**，**将逻辑块号翻译为$(盘面，磁道，扇区)$三元组**。唯一标识了一个物理扇区，通过读写头感知位，并放在磁盘控制器的一个小缓冲区中
所以，当操作系统希望执行一个I/O操作时（向/从磁盘读写数据），向磁盘控制器发送命令，经过映射后，通过磁盘控制器的缓冲区进行数据的传递

#### 5. 连接I/O设备
所有的输入输出设备都需要通过**I/O总线**，**系统和内存总线是与CPU相关的，但I/O总线例如外围设备互连总线PCI被设计成与底层CPU无关的**：
![[Pasted image 20241105110438.png]]
**I/O总线比系统和内存总线要慢**，但是**可以容纳各种第三方I/O设备**
如上图所示，有三种不同设备连接到总线：
- **通用串行总线==USB**==控制器：连接到USB总线的设备的中转机构，**USB总线是广泛使用的标准**，许多外围I/O设备都可以通过USB总线连接
- **图形卡（适配器）负责代表CPU在显示器上画像素**，包含硬件和软件逻辑
- **主机总线适配器将一或多个磁盘连接到I/O总线**，它使用的是一个特别的主机总线接口定义的通信协议，最常用的有**SCSI**和**SATA**
- 其他设备通过插入主板上的空**扩展槽**，**直接连接**到I/O总线

#### 6. 访问磁盘
I/O设备的工作机理和如何对它们进行编程超出了本章的范围，但是可以进行一个概要的描述
**CPU使用==内存映射I/O==的技术来向I/O设备发送命令**，在这样的系统中，**地址空间保留一块与I/O设备通信的地址**，称为**I/O端口**，当设备连接到总线时，**被映射到一个或多个端口**

**磁盘控制器的访问是一个I/O端口的使用例子**
例如，假设磁盘控制器被映射到端口`0xa0`，那么CPU通过**发送三条存储指令**完成对磁盘的**读**
- 发送一个命令字，**告诉磁盘发起了一个读**，以及其他所需参数
- **指明**应该读的**逻辑块号**
- **指明**应该存储磁盘扇区内容的**主存地址**
随后，磁盘控制器将逻辑块号**翻译**为扇区地址，**读取**其中内容，**将其直接传送到主存而不需CPU的干涉**

**直接内存访问：设备自己执行读或写的总线事务，而不需要CPU干涉的过程**，这样的数据传送称为**DMA传送**
DMA传送完成后，磁盘扇区的内容被安全地存储在主存中，**磁盘控制器发送一个中断信号给CPU芯片的一个外部引脚**，暂停当前的工作，**跳转到一个操作系统例程记录I/O已经完成**，然后再返回到被中断的地方继续执行

### 6.1.3 固态硬盘SSD
**固态硬盘SSD是一种基于闪存的存储技术**，它的思想如下图：
![[Pasted image 20241106221054.png]]
固态硬盘被封装到一个**标准硬盘插槽**中，通常是USB或SATA，**连接到I/O总线**，它**处理来自CPU读写逻辑磁盘块的行为**和别的磁盘**一模一样**
一个SSD封装由一或多个**闪存芯片和闪存翻译层**组成，**闪存芯片代替旋转磁盘中的机械驱动器；闪存翻译层则类似于磁盘控制器，进行请求的翻译**，也是一个硬件和固件设备

**读SSD要比写SSD快**，因为底层的闪存由**B个块的序列**组成，**每个块由P页组成**，数据是**以页为单位读写**的，**只有该页所在的块被整个擦除后才能对这页进行读写**，块擦除磨损的次数大约是100000次
因此，**随机写需要擦除块，所需时间很长**；并且如果对页p进行修改写，**这个块内所有带数据的页都得被复制到一个新的被擦除过的块**，才能进行写
这就是写SSD慢的原因了

### 6.1.4 存储技术趋势
通过对现代存储技术的简单讨论，可以总结出以下的思想：
- **不同存储技术有不同的价格和性能折中**，**快速存储总比慢速存储贵**，造价：SRAM>DRAM>SSD>磁盘

- **不同存储技术的价格和性能属性以截然不同的速率在变化：增加密度以降低成本比降低访问时间容易得多**

- **DRAM和磁盘的性能滞后于CPU的性能**：CPU因为多核处理器的出现而性能递增，这导致**处理器-内存之间出现了加大的性能差异**，这个差异一开始与延迟有关，而在多核出现后，**主导因素变为了吞吐量**：**多个处理器核会==并发==地向DRAM和磁盘发送请求**

因此，**现代计算机频繁地使用基于SRAM的高速缓存以试图弥补处理器-内存之间的差距，这是由于应用程序的==局部性==属性才得以实现的**

## 6.2 局部性
一个好的计算机程序常常具有**良好的局部性：它们倾向于引用邻近于其他==最近引用过的==数据项的数据项，或最近引用过的数据项本身**，这就是**局部性原理**
- **时间局部性：被引用过一次的内存位置很可能在不远的将来被再次引用**
- **空间局部性：若一个内存位置被引用了一次，那么程序在不远的将来很可能引用它附近的一个内存位置**

一般来说，**拥有良好局部性的程序比局部性差的程序运行得更快**，现代计算机系统层次：硬件->操作系统->应用程序 的设计处处体现着局部性的思想
- **硬件**层，计算机设计者根据局部性原理引入**高速缓存存储器**用来**保存最近被引用的指令和数据项，以提高对主存的访问速度**
- **操作系统**层，根据局部性原理，**系统使用主存作为虚拟地址空间最近被引用的块的高速缓存**；同时**使用主存来缓存磁盘文件系统中最近被使用的磁盘块**
- **应用程序**层，例如，大容量的Web服务器将最近被请求的文档放置在**前端磁盘告诉缓存中**，以更快地对它们进行访问

### 6.2.1 对程序数据引用的局部性
考虑下面对向量元素求和的简单函数：
```c
int sumvec(int v[N]) {
	int i. sum = 0;
	for (i = 0; i < N; i++)
		sum += v[i];
	return sum;
}
```
这里的变量`sum`**在每次循环迭代中被引用一次，因此由良好的时间局部性**；但是**标量变量没有空间局部性（并不是容器，没有这种说法）**
而对于输入的向量`v[N]`来说，**其中元素被按照它们在内存中存储的顺序读取，有良好的空间局部性**，但是**因为每个元素只被引用一次，时间局部性很差**
该函数循环体中的每个变量，要么有良好的时间局部性，要么有良好的空间局部性，所以整个函数的局部性是良好的

像`sumvec`这样顺序访问一个容器每个元素的函数，我们称它**具有步长为1的引用模式**，或是**顺序引用模式**；若在连续向量中，每隔k个元素进行访问，就是**步长为k的引用模式**了
步长为1的引用模式是程序中空间局部性常见和重要的来源，一般来说，**随着步长的增加，空间局部性下降**

对于引用多维数组的程序，步长也很重要。
```c
int sumarrayrows(int a[M][N]) {
	int i, j, sum = 0;
	for (i = 0; i < M; i++) 
		for (j = 0; j < N; j++)
			sum += a[i][j];

	return sum;
}
```
**双重嵌套循环按照行优先顺序读取数组的元素：内层循环读第一行的元素，然后第二行……以此类推**
上面的`sumarrayrows`函数就是一个具有良好空间局部性的例子，**按照数组被存储的行优先顺序来访问这个数组：**
![[Pasted image 20241107124755.png]]

让我们看看如果不按照这个顺序，会产生什么后果：
```c
int sumarraycols(int a[M][N]) {
	int i, j, sum = 0;

	for (j = 0; j < N; j++)
		for (i = 0; i < N; i++)
			sum += a[i][j];
			//循环顺序反过来了
	return sum;
}
```
该函数**空间局部性很差：按照列顺序扫描数组，但C数组在内存中按照行顺序存储，这产生了步长为N的引用模式**
![[Pasted image 20241107131050.png]]

### 6.2.2 取指令的局部性
**程序指令是存放在内存中的，由CPU读出**（取出），因此**程序关于取指令的局部性**也能够被评价
例如，6.2.1节中第一个的for循环中，指令执行的顺序和内存顺序一致，拥有良好的空间局部性；而又因为循环体被多次执行，也具有良好的时间局部性

**代码区别于程序数据的重要属性是在运行时代码不能被修改：CPU只从内存中读出指令，很少重写或修改这些指令**

### 6.2.3 局部性小结
量化评价程序中局部性的一些简单原则：
- **重复引用相同变量**的程序具有**良好的时间局部性**
- 对于具有步长为k的引用模式的程序，**步长越小，空间局部性越好**
- 对于**取指令操作**，**循环结构**具有良好的时间和空间局部性：**循环体越小（每次迭代操作越少），迭代次数越多，局部性越好**

## 6.3 存储器层次结构
前面讨论了存储技术和计算机软件的基本属性：
- 存储技术：不同存储技术的访问时间差异很大，速度较快的技术每字节所需成本比速度较慢的技术要高，容量较小
- 计算机软件：良好的程序倾向于有良好的局部性

硬件和软件在这些基本属性上互补得很好，这样的特征产生了一种**组织存储器系统的方法**：==**存储器层次结构**==，所有现代计算机系统中都使用了这个方法
![[Pasted image 20241107134247.png]]
从上往下，存储设备更大、更慢且更便宜
- 最高层是**少量快速的CPU寄存器，CPU可以在一个时钟周期内访问它**
- 接下来是一或多个中小型的**基于SRAM的高速缓存存储器**，CPU可以在几个时钟周期内访问它们
- 然后是一个大型的**基于DRAM的主存**，CPU在几十到几百个时钟周期内访问它们
- 下一层则是**慢速但容量很大的本地磁盘**
- 最后，有些系统包括一层**附加的远程服务器上的磁盘，通过网络进行访问**，例如**分布式文件系统AFS和NFS，它们允许程序访问存储在远程的网络服务器上的文件**

### 6.3.1 存储器层次结构中的缓存
**高速缓存cache是一个小且快速的存储设备，作为存储在更大更慢的设备中的数据对象的缓冲区域**
**使用高速缓存的过程称为==缓存**==

存储器层次结构的中心思想是：**对于每个k，位于k层的更快更小的存储设备作为位于k+1层的更大更慢的存储设备的缓存**（**上面一级的存储设备是下面一级存储设备的缓存**）
下图展示了存储器层次结构中缓存的一般性概念：
![[Pasted image 20241107135830.png]]
第k+1层（下面一级的存储设备）的存储器被划分为**连续的数据对象组块，称为==块**==，每个块有一个唯一的地址或名字用于区别
**块通常是固定大小的，但也可以是可变大小的（Web服务器上的远程HTML文件）**
上图中，第k+1层的存储器被划分为16个大小固定的块

类似地，第k层（上面一级的存储设备）的存储器被划分为**较少的块的集合，每个块的大小与第k+1层的块的大小一致（层次结构中，一对相邻的层次之间块的大小一致）**
**数据总是以块大小为==传送单元==在第k层和k+1层之间进行来回复制的**
要注意，层次结构中**块的划分在不同的层次对中可以不同，不一定是传递性的**，例如在L1和L0之间，块大小固定为1字8字节；而在L2和L1之间的传送通常使用的块大小为几十字节；更往后的L5和L4之间甚至使用几百或几千字节的块
这是**为了补偿层次结构中较底层（离CPU较远）的设备的较长的访问时间，需要在较低的层次对之间使用较大的块来传输**

#### 1. 缓存命中
当程序需要第k+1层中的某个数据对象d时，首先在当前存储在第k层的一个块中查找d，**若需要查找的对象d刚好缓存在当前的第k层中，就是缓存命中**，该程序直接在第k层中读取对象d即可

#### 2. 缓存不命中
**如果当前所在的第k层没有缓存数据对象d，就是缓存不命中**
此时**第k层的缓存从第k+1层缓存中取出包含数据对象d的那个块，若第k层已满，则可能会覆盖掉现存的一个块**

覆盖现存的一个块的过程叫做**替换或驱逐这个块，这个块称为牺牲块**
决定需要替换哪个块是由缓存的**替换策略**来控制的，例如，采用**随机替换策略的缓存随机选择一个块进行替换**；采用**最近最少被使用替换策略LRU的缓存会选择那个最后被访问的时间距离现在最远的块**
进行读取后，程序就能继续在第k层读出d了

#### 3. 缓存不命中的种类
1.  **冷缓存：第k层的缓存是空的，对任何数据对象的访问都会不命中**
这样的不命中称为**冷不命中或强制性不命中**，通常是短暂的事件，因为在反复访问存储器使得缓存**暖身**之后就不会出现了

只要发生了不命中，就需要采取**放置策略：确定从k+1层中取出的块该放在哪里**
如果允许**来自第k+1层的任何块放置在第k层的任何块中**，这会非常灵活，**常用于高层靠近CPU的缓存中**。通过硬件来实现，但是**比较昂贵**，因为随机放置块会导致定位代价较高

硬件缓存通常使用更严格的放置策略：**将第k+1层的某个块限制放置在第k层块的一个小的子集中**（有可能小到只有一个块）
举个例子，在这张图中：
![[Pasted image 20241107135830.png]]
我们可以建立一个映射：**第k+1层的块i必须放置在第k层的块(i mod 4)中**，例如，第k+1层的块`0, 4, 8, 12`映射至第k层的块`0`，而块`1, 5, 9, 13`被映射到块`1`
和哈希一样，无论何种映射都会产生一种不命中：**冲突不命中：不同的对象被映射到同一个缓存块，即使缓存足够保存被引用的数据对象，缓存也会一直不命中**
例如，比如程序请求块`0`，再请求块`8`，由于它们都被映射至第k层的块`0`，在第k层的缓存中对它们的每次引用都会不命中

**程序通常按照一系列阶段（如循环）运行，每个阶段访问缓存块的某个相对稳定不变的集合**。例如一个嵌套循环可能反复访问一个数组的元素
**程序每个阶段访问的块的集合称为这个阶段的==工作集**==，当工作集的大小超过了缓存的大小时，缓存就会经历**容量不命中**（太小了，无法处理这个工作集）

#### 4. 缓存管理
存储器层次结构的本质是将每一层存储设备作为下一层的缓存，在每一层上，必须以某种形式的逻辑**管理缓存**，也就是说，**将缓存划分成块、在不同层之间传送块、判定是否命中等操作，需要通过软件或硬件所提供的逻辑实现**
例如，**编译器**管理**寄存器**文件，并**缓存层次结构的最高层**；L1、L2和L3层的缓存完全由内置在其中的硬件逻辑管理；在有虚拟地址的操作系统中，DRAM主存作为磁盘上数据块的缓存，**由操作系统软件和CPU上的地址翻译硬件共同管理**；而对于**具有像AFS这样分布式文件系统的机器**，使用本地磁盘作为缓存，由**运行在本地机器上的AFS客户端进程管理**
大多数时候，***缓存自动运行，不需要显式行动***

### 6.3.2 局部性与缓存
- **时间局部性**：同一数据对象可能会被多次使用，数据对象在第一次不命中后被复制到缓存中，**后续的命中服务就会比第一次的不命中快很多**
- **空间局部性**：**块包含个数据成员**，可能在从块中取出第一个数据成员发生了不命中，复制块的速度很慢，因此我们**期望后面能通过对同一个块中的其他对象进行访问**，**以补偿不命中造成的损失**

## 6.4 高速缓存存储器
最开始的计算机系统存储器层次结构只有：CPU寄存器、DRAM主存储器和磁盘存储三个部分
但是，由于CPU和主存之间出现了增大的性能差距，系统设计者不得不在**CPU寄存器文件和主存之间**插入一个小的**SRAM高速缓存存储器**，称为**L1高速缓存**（一级缓存）
L1高速缓存的访问速度几乎和寄存器一样快：
![[Pasted image 20241107192432.png]]
随着CPU与主存之间性能的进一步加大，设计者在**L1高速缓存与主存之间**又插入了一个**L2高速缓存**；有些现代系统在**L2高速缓存与主存**之间插入**L3高速缓存**

### 6.4.1 通用的高速缓存存储器组织结构
考虑一个计算机系统，每个存储器地址有m位，形成$M=2^m$个不同的地址
![[Pasted image 20241107193531.png]]
该机器的高速缓存被组织称一个有$S=2^s$个**高速缓存组**的数组
每个高速缓存组包含E个**高速缓存行**，每行由一个$B=2^b$子节的**数据块**组成；最前面的**有效位指明这个行是否包含有意义的信息**；中间的$t=m-(b+s)$个**标记位唯一地标识存储在这个高速缓存行中的块**

一般而言，**高速缓存的结构可以用四元组$(S,E,B,m)$来描述**，其大小（容量）是所有块的大小之和，$C=S\times E\times B$，不包括有效位和标记位

当CPU执行一条从主存地址A中读取一个字的指令时，它**将地址A发送到高速缓存**，若高速缓存正好保存了A处的字的副本，立即发给CPU
**高速缓存检查自己是否包含CPU传来的地址的副本**的原理是：
当发送地址A给高速缓存时，地址A**可以转换为具体的物理地址，也可以作为高速缓存中的组和块的索引，以供在高速缓存中直接找到其副本**（如果有的话）
参数S和B将m个地址A的位分为三个字段
![[Pasted image 20241107195048.png]]
在地址A中，具有s个**组索引位，用于得到它在S个组中的组号索引**，这是一个无符号整数，用于告诉我们这个字必须被存储在哪个组中
而A中的t位**标记位告诉我们这个组的哪一行包含这个字**（如果有的话）
**当且仅当该组设置了有效位且该行的标记位与地址A中的标记位匹配时，才说明组中的这一行包含这个字**


> [!NOTE] 选取中间的位用作索引的原因
> 首先需要明确，**地址A在高速缓存中的组索引来自它真实的地址表示，也就是从完整的地址表示中取出一部分来进行索引**
> 如果采用高位进行索引，相邻的地址会被映射至相同的块。例如0000和0001、0002等等，都被映射至00，这就会导致访问连续地址时出现频繁冲突不命中，降低性能


当我们在组索引所标识的组中定位了标号所标识的行后，b个**块偏移位给出了在B个字节的数据块中的字偏移**

![[Pasted image 20241108131133.png]]

### 6.4.2 直接映射高速缓存
**高速缓存可根据每个组的高速缓存行数E被分为不同的类：**
- 每组只有一行（$E=1$）的高速缓存称为**直接映射高速缓存**
这是最容易实现并且理解的高速缓存，我们下面的叙述以它为例：
![[Pasted image 20241108131602.png]]
设想这样一个系统：
系统具有一个CPU、一个寄存器文件、一个L1高速缓存和一个主存
当CPU执行一条读内存字$w$的指令，它**向L1高速缓存请求这个字**，若L1高速缓存存有这个字的一个缓存的副本，就得到**L1高速缓存命中**，能够将它很快地返回给CPU；反之就是**缓存不命中，需要向主存请求包含这个字的块的一个副本**，然后将其存放在它的一个高速缓存行中，抽出字$w$，返回给CPU

高速缓存**确定一个请求是否命中，然后抽取出请求的字的过程分为三步：**
- 组选择
- 行匹配
- 字抽取

#### 1. 直接映射高速缓存中的组选择
这一步骤，**高速缓存从$w$的地址中间抽取出$s$个组索引位，被解释为对应于一个组号的无符号整数**
![[Pasted image 20241108133418.png]]

#### 2. 直接映射高速缓存中的行匹配
在第一步中，我们选择了具有组索引的某个组i，接下来一步就是要确定**这个组i中是否有字$w$的一个副本存储在其高速缓存行中**
高速缓存中的行匹配很快，因为每个组只有一行，**当且仅当设置了有效位，而且高速缓存行中的标记与$w$的地址中的标记相匹配时，才说明这个高速缓存行中包含了$w$的一个副本**
![[Pasted image 20241108134218.png]]

图中的组中的唯一一个高速缓存行设置了有效位，并且标记与$w$的地址标记一致，因此产生了缓存命中。

#### 3. 直接映射高速缓存中的字选择（缓存命中的情况）
出现缓存命中，我们就知道$w$在这个块中的某个地方，**需要确定这个字在块中是从哪里开始的**。
**块偏移位提供了所需要的字的第一个字节的偏移**，就像是把块看成一个数组那样
图6-29的例子中，位偏移位的值为$0110_2$，代表**w的字节是从块中的字节4开始的**

#### 4. 直接映射高速缓存中的行替换（缓存不命中的情况）
若出现缓存不命中，**高速缓存L1需要从存储器层次结构中的下一层取出被请求的块，然后将新的块存储在组索引位指示的组中的一个高速缓存行中**
一般而言，若组中的高速缓存行已满，那么必须驱逐出一个现存的行。在直接映射高速缓存中，因为只有一个高速缓存行，因此直接替换即可

#### 5. 运行中的直接高速缓存
高速缓存选择组和标识行的机制很简单，但是
假设有一个直接映射高速缓存：
$$ (S,E,B,m) = (4,1,2,4) $$
即该高速缓存中有4组，每组1行，每个块2个字节，每个地址表示共有4位
我们假设取出的字都是单一字节的，那么可以列举出整个地址空间并且划分好位：
![[Pasted image 20241108194723.png]]
- **标记位和索引位唯一地标识了内存中的每个块**，也就是说，**将标记位和索引位的二进制位看作同一个数的位表示，表示的十进制数就是块号**
  例如，十进制地址10和11中的两个块的由标记位和索引位组成的二进制数都是$101_2$，也就是十进制的5

- **内存块的个数(8)大于高速缓存组的个数(4)，因此会出现多个块映射至同一个高速缓存组的情况（它们具有相同的组索引）**
  $$通过 \quad 高速缓存组号=块号\mod 4$$的方式进行到四个高速缓存组的映射

- **映射至同一高速缓存组的块由标记位唯一标识**。例如：对于映射到组0的块0和4，块0的标记位为0，而块4的标记位为1

##### 模拟高速缓存在CPU执行一系列读时的行为
初始时，高速缓存是空的（每个有效位均为0）
![[Pasted image 20241108200248.png]]
这里的第一列“组”只是用于标识，便于阅读的；后面的四列“块”代表每个高速缓存行的实际位

CPU开始执行时：
1. 读地址0的字
  组0的有效位是0，因此此时会发生缓存不命中。高速缓存从下面一层的存储器结构中**取出整个块0，并将其放入组0中**
![[Pasted image 20241108202945.png]]
由于空间局部性原理，**当发生缓存不命中时，通常不仅会加载当前请求的字或字节，还==会加载包含该地址附近的多个字节或字**==（**块的大小比请求的字节或字往往更大**，因而能够实现多加载的操作）
这就导致**实际加载的除了请求的那个字以外，还有它附近的一个字**，毕竟良好的空间局部性程序会倾向于访问上次请求的字附近的字
最后，取出块`0`中的`m[0]`位置上的字返回给CPU即可

2. 读地址1的字
由于在读地址0时将其周围的一个字，即地址1的字一同读取到高速缓存中了，此时发生了高速缓存命中，直接从块`[1]`中返回`m[1]`即可

3. 读地址14的字
根据$组号=地址\quad mod\quad4$的映射，地址14被映射至组`2`，但此时组`2`有效位未被设置，因此缓存不命中，将相应的块以及周边块加载到组`2`，返回`m[14]`

4. 读地址8的字
由于地址8和地址0都映射至组`0`，因此**检查标记位时发现不匹配**，发生缓存不命中。于是高速缓存将相应的块**替换地加载到组`0`当中**，然后返回`m[8]`
之后若又请求地址0的字，依然会发生缓存不命中，因为内容已经被替换了

#### 6. 直接映射高速存储中的冲突不命中（抖动现象）
冲突不命中的问题在程序中很常见，往往会出现你认为拥有良好空间局部性的程序但实际运行速度并不理想的情况：
```c
float dotprod(float x[8], float y[8]) {
	float sum = 0.0;
	int i;

	for (i = 0; i < 8; i++) 
		sum += x[i] * y[i];
	return sum;
}
```
看上去，对于数组x和y来说这个程序的空间局部性良好，我们期望其命中率会比较高
但是**实际并不如此**
假设浮点类型`float`的大小为4字节，x被加载到从地址0开始的$4\times 8=32$字节连续内存中，y被加载到x之后的32字节连续内存中。
假设一个块是16字节，能够存储4个浮点数；而高速缓存共有2个组，总共32字节大
根据上面的假设，我们可以列出这样的地址表格：
![[Pasted image 20241108211230.png]]
在循环中，**我们每次访问的x和y数组中的对象都恰好地映射到了一起，这就导致了每一次都发生了缓存不命中-覆盖-缓存不命中这样的现象**
这种情况的术语是==**抖动==：高速缓存反复地加载和驱逐相同的高速缓存块的组**

所以，**即使程序有良好的空间局部性，但是由于映射的冲突性，可能仍然会在每次引用时产生冲突不命中**

##### 修正抖动的方法：增加填充
当然，修正抖动的方法有很多，最简单的方法是**在每个数组的结尾放上B个字节的填充，例如将`x`定义为`float x[12]`而不是`float x[8]`**，这能够使得映射变为：
![[Pasted image 20241108212533.png]]
因为把数组y的地址给往后推移了，映射得到的索引和x错开，进而消除了抖动不命中

### 6.4.3 组相联高速缓存
直接映射高速缓存容易产生冲突不命中的原因是整个组只有一行，E=1；而**组相联高速缓存中每个组都保存有多余一个的高速缓存行**
一个$1<E<C/B$的高速缓存通常称为**E路组相联高速缓存**，其结构大致如下：
![[Pasted image 20241108215547.png]]

#### 1. 组相联高速缓存中的组选择
和直接映射高速缓存一样，使用组索引标识组：
![[Pasted image 20241108220030.png]]

#### 2. 组相联高速缓存中的行匹配和字选择
由于组内的高速缓存行数更多，组相联高速缓存的行匹配要比直接映射高速缓存更复杂，**必须检查多个行的标记位和有效位**
内存可以被视为一个值的数组，用地址作为输入以访问对应位置的值
**相联存储器**也是类似的，它是一个`(key, value)`键值对的数组，输入`key`，访问值`value`，键就是标记和有效位，值就是块的内容
![[Pasted image 20241108221106.png]]
总之就是需要**搜索组索引指引的组中的每一行，找到标记位匹配的设置了有效位的行，根据块偏移找到整个字**

#### 3. 组相联高速缓存中的行替换
当CPU请求的字不在组内的任何一行中，就需要从内存中取出包含这个字的块
但是如果每个行都满了，高速缓存取出块后应该用它替换哪一行？
简单的策略是随机选择被替换的行，更复杂的利用局部性原理的策略的实现比较复杂，例如**最不常使用策略LFU，它替换过去某时间引用次数最少的一行；最近最少使用策略LRU替换最后一次访问的时间最久远的一行**
这些策略需要额外的时间和硬件成本，但是是值得的。不过因为**程序员很难在代码中利用高速缓存替换策略**，因此不过多叙述

### 6.4.4 全相联高速缓存
**全相联高速缓存中，没有分组，所有的高速缓存行都被包含在一个组内：$E=C/B$**
![[Pasted image 20241108221831.png]]
#### 1. 全相联高速缓存的组选择
很简单，因为只有一个组，所以干脆在地址中不进行组索引：
![[Pasted image 20241108222302.png]]

#### 2. 全相联高速缓存中的行匹配和子选择和行替换
**都和组相联高速缓存一样，只是规模不同**。遍历每一行进行有效位和标记位的判定，然后通过块偏移找到字，如果不存在，则向下一级请求并进行替换

**构造一个又大又快的高速缓存很难很贵，所以全相联高速缓存只适合做成较小的高速缓存，例如虚拟内存系统的==翻译备用缓冲器==，它缓存页表项**

### 6.4.5 高速缓存的写情况
高速缓存的写情况相比读会稍微复杂一些。
假设我们要**写一个已经缓存了的字$w$**（发生了**写命中**），高速缓存更新这个字的副本，然后**需要将$w$在更低一层的存储器结构中的副本进行更新**
最简单的方法称为**直写：立刻将含有$w$的那个高速缓存块写回到它的低一层**，但是这样作的缺点在于**每次写都会引起总线流量，即每次发生写操作都会传递到主存，占用总线带宽，加大负载**

另一种方法叫做**回写：尽可能地推迟更新，只有当替换算法==需要驱逐这个块时==才把它写到下一层中**，这样可以显著地减少总线流量
回写会增加复杂性：高速缓存必须为每个高速缓存维护一个额外的**修改位：用于标明这个块是否被修改过**

对于**写不命中**的处理方式，一种方法称为**写分配：加载相应的低一层中的块至高速缓存，任何再更新这个高速缓存块**。该方法显然在每一次不命中时都会让一个块从低一层被加载到高速缓存
另一种改进方法是**非写分配：避开高速缓存，直接将这个字写到下一层去**
**直写高速缓存通常是非写分配的，回写高速缓存通常是写分配的**

为了写操作而优化的高速缓存是一个困难细致的问题，往往它们的技术是不开源的。
对于希望编写高速缓存友好的程序员来说，**建议在印象中采用一个使用回写+写分配的高速缓存模型**。这是因为：
- 存储器层次结构中**底层的缓存更可能使用回写**
- **回写+写分配的组合和处理读的方式互相对称**，都试图利用局部性
这样我们就可以无视很多细节，在较高的层面上进行软件的开发

### 6.4.6 真实高速缓存层次结构的解剖
目前为止我们的讨论都是基于高速缓存只保存数据这个前提的，但实际上，**高速缓存既保存数据，也保存指令**
**只保存指令的高速缓存称为$i-cache$，通常是只读的；只保存程序数据的高速缓存称为$d-cache$；既保存指令又保存数据的则称为统一的高速缓存**

现代处理器有着独立的$i-cache$和$d-cache$，这样处理器可以同时读一个指令字和一个数据字。这两个高速缓存**可以有不同的块大小、相联度和容量**，它们也能保证数据访问与指令访问之间不会出现冲突不命中，但可能引起**容量不命中的增加**

下面是一个Intel Core i7处理器的高速缓存层次结构：
![[Pasted image 20241109202746.png]]
该芯片有四个核，每个核有自己私有的$i-cache$和$d-cache$，但是**所有核共享 片上L3统一的高速缓存，且所有的SRAM高速缓存存储器都在CPU芯片上**（L1和L2高速缓存在核上，也就是CPU芯片上）

### 6.4.7 高速缓存参数的性能影响
衡量高速缓存的指标有许多：
- 不命中率：程序执行期间，内存引用不命中的比率 = 不命中的数量 / 引用的数量
- 命中率： 1 - 不命中率
- 命中时间：从高速缓存传送一个字到CPU所需的全部时间
- 不命中处罚：由于发生不命中而需要的额外时间

优化高速缓存的成本和性能需要在程序代码中进行大量模拟，我们只认识一些定性的这种考量即可
#### 1. 高速缓存大小
**较大的高速缓存可能回提高命中率，但是可能会增加命中时间**，所以上层高速缓存会比下层更小

#### 2. 块的大小
**较大的块能够利用程序的空间局部性，提高命中率（能够取更多目标附近的字）**，另一方面，**块越大，高速缓存行数越少，对于时间局部性优秀的程序不友好（更频繁地进行块的更新，访问之前访问的字时更可能发生不命中）**；并且，**更大的块会增加不命中处罚，因为传送时间会越长**

#### 3. 相联度的影响
相联度也就是**每个组中的高速缓存行数E**，E的值越大，**高速缓存由于冲突不命中而产生抖动的可能性越小**；但是较高的相联度的硬件成本很高，**因为行数增加，作为标记位和LRU状态位（最近最少替换策略使用的计数位）的二进制位就越多**，还会需要额外的控制逻辑，**增加了复杂性，也就是命中时间和不命中处罚增加了**

#### 4. 写策略的影响
**直写高速缓存可以使用独立于高速缓存的==写缓冲区==以更新内存**，并且读不命中的开销很小，因为不会触发向内存的写入
而**回写高速缓存引起的数据传送更少，能够节省内存带宽用于执行DMA的I/O设备**

而越往存储器层次结构下面走，传送时间越多，所以需要减少传送的次数，这就是为什么**一般而言，高速缓存越往下层，越可能使用回写而不是直写**

## 6.5 编写高速缓存友好的代码
明白了高速缓存存储器的工作机理，我们就能更加准确地探究程序的局部性了
**局部性较好的程序更容易有更低的不命中率，这会使其运行得更快**，下面是一些用于确保程序**高速缓存友好**的基本方法：

- **让最常见的情况运行得快**：也就是**将注意力集中在核心函数中的循环中，对它们进行优化**
- **尽量减少每个循环内部的缓存不命中数量**：很好理解，因为不命中率低的循环运行得更快

根据这样的方法，我们能总结出一些关于实际编写代码时的重要事项：
- **对局部变量的反复引用是好的（利用时间局部性）**
- **步长为1的引用模式是好的，因为存储器结构体系中所有层次的缓存都是将数据存储为连续的块的（空间局部性）**

对于空间局部性的利用，有时候步长过大，**可能因为高速缓存容量大于整个数组，缓存了数组中的所有元素，因此不命中率低**，运行速度没有变化；但是更有可能的是数组大小大于高速缓存，不命中率更高，运行速度显著减慢

## 6.6 高速缓存对程序性能的影响
本节综合讨论高速缓存对运行在实际机器上的程序的性能影响

### 6.6.1 存储器山
**程序从存储系统中读数据的速率称为==读吞吐量== 或 ==读带宽==**：
$$ \begin {align}
&设一个程序在s秒的时间内读n个字节，则该程序的读吞吐量为\frac{n}{s}\\
&单位为兆字节每秒(MB/s)
\end {align} $$

下面给出一个**测量读序列的读吞吐量的程序**，采用的方法是**从一个紧密程序循环中发出一系列读请求**：
```c
long data[MAXELEMS];  //将要遍历的全局数组

//测试函数：从数组的第一个元素开始，以步长stride的倍数遍历，使用4*4循环展开
int test(int elems. int stride) {
	long i, sx2 = stride*2, sx3 = stride*3, sx4 = stride*4;
	long acc0 = 0, acc1 = 0, acc2 = 0, acc3 = 0;
	long length = elems;
	long limit = length - sx4;

	//4*4循环展开，一次计算四个值
	for (i = 0; i < limit; i += sx4) {
		acc0 = acc0 + data[i];
		acc1 = acc1 + data[i+stride];
		acc2 = acc2 + data[i+sx2];
		acc3 = acc3 + data[i+sx3];
	}

	//计算剩余的没对齐的元素
	for (; i < length; i+=stride) {
		acc0 = acc0 + data[i];
	}
	return ((acc0 + acc1) + (acc2 + acc3));  //将每次循环展开计算的四个和加到一起
}

//运行函数运行上面的测试函数，并且返回读吞吐量，size以字节为单位，stride是数组中遍历的步长，Mhz是CPU的时钟周期，单位Mhz
double run(int size, int stride, double Mhz) {
	double cycles;
	int elems = size / sizeof(double); //以数组元素类型为单位

	test(elems, stride);   //这次调用先对缓存“热身”
	cycles = fcyc2(test, elems, stride, 0);  //fcyc2是测量函数执行时间的函数，返回值以CPU周期为单位

	return (size / stride) / (cycles / Mhz);
	//计算读吞吐量并返回
}
```
可以看到，测试函数以步长`stride`扫描一个数组的前`elems`个元素来产生读序列，同时**使用$4\times4$循环展开提高内循环的并行性**
`run`函数是一个**包装函数：它调用`test`函数，进行运行时间测量，并且返回计算的读吞吐量**，在测试之前还先调用测试函数对缓存进行暖身，同时调用`fyc2`函数，它**返回估计的运行时间，单位是CPU周期**

`run`函数的参数`size`和`stride`用于客户端控制读序列的时间和空间局部性程度：**`size`的值越小，工作集越小，时间局部性越好；`stride`的值越小，步长越小，空间局部性越好**
以**不同的`size`和`stride`调用`run`函数，获取三维的函数图像，就是==存储器山**==了：
![[Pasted image 20241110214408.png]]
出现**垂直于`size`大小轴的山脊，对应于工作集在各级存储器层次中的时间局部性区域**。不同山脊两侧是上级存储器的最低点和下级存储器的最高点，**差别有一个数量级**

**每个计算机都有它唯一的存储器山**，对这样的三维函数进行分析可以得到一些有趣的结论：
- **当程序的时间局部性很差时，增加空间局部性也是可以进行补救的**

- 当步长为1时，可以看见**此时读吞吐量相对保持不变**，这是因为这个存储器山所来自的Core i7存储器系统的**硬件预取机制**，它自动识别顺序且步长为1的引用模式，**在一些块被访问之前预测性地将其取到高速缓存中**

从不同的方向切割这个存储器山，可以得到这样的剖面图
保持步长为常数：
![[Pasted image 20241110221752.png]]
这说明**大小为32KB的工作集能被完全放进L1 $d-cache$中，因此对它的读都是由L1来服务的，吞吐量保持在峰值12GB/s**
工作集越大，主要的服务由主存提供。而在L2和L3高速缓存区域，往左侧工作集变大方向边缘出现了读吞吐量的下降（最左边的那条直线比其他直线低一些），很可能是与其他数据和代码行的冲突造成的

保持工作集大小不变：
![[Pasted image 20241112140949.png]]
这说明了**空间局部性对读吞吐量的影响**，这张图保持工作集大小为4MB，位于L3高速缓存的山脊上。
可以看见，**随着步长增加，读吞吐量稳定下降，直到s8以后保持不变**，这是因为**L2高速缓存中的读不命中会导致一个块从L3传送到L2，当步长过大，每个读请求都会不命中，因此速率保持在从L3传送高速缓存块到L2的速率（下界）**

### 6.6.2 重新排列循环以提高空间局部性
考虑$n\times n$矩阵相乘问题：
$$ \begin{bmatrix}
c_{11}c_{12}\\
c_{21}c_{22}
\end{bmatrix} = 
\begin{bmatrix}
a_{11}a_{12}\\
a_{21}a_{22}
\end{bmatrix}
\begin{bmatrix}
b_{11}b_{12}\\
b_{21}b_{22}
\end{bmatrix}
$$
其中：
$$\begin{align}
c_{11}&= a_{11}b_{11}+a_{12}b_{12}\\
c_{12}&=a_{11}b_{12}+a_{12}b_{22}\\
c_{21}&=a_{21}b_{11}+a_{22}b_{21}\\
c_{22}&=a_{21}b_{12}+a_{22}b_{22}\\
\end{align}
$$
最简单的实现是使用3个嵌套的循环，使用`i`，`j`和`k`标识三层循环，可以得到6个不同版本的循环：
![[Pasted image 20241112143123.png]]
理论上，它们的复杂度都是$O(n^3)$，且**如果加法是可结合的，计算出的结果都一样**
但是显然，它们在访问数量和局部性上是有差异的，不妨假设：
- 数组元素类型为`double`，`sizeof(double) = 8`
- 仅有一个块大小B=32字节的高速缓存
- 数组大小n很大，矩阵每一行都不能被完全装入高速缓存中
- 编译器将局部变量存储在寄存器中，循环内对局部变量的引用不需要额外的加载和存储指令

那么可以发现，六个版本的循环**按照最内层循环的访问对象**组成了三个等价的类，下面是**对最内层循环的分析结果：**
![[Pasted image 20241112144602.png]]
- 类AB例程的最内层循环以步长1扫描数组A，步长n扫描数组B
  由于每个高速缓存块保存4个8字节的字，也就是说**每次不命中后可以额外取相邻的4个`double`类型到该层高速缓存，使得后面的3个元素可以命中**。
  因此，对于步长为1访问的A，其不命中率是$\frac{1}{4}$（每4个请求会出现一次不命中）
  对于步长为n访问的B，由于步长远大于高速缓存块能够保存的元素个数，其不命中率是1（每次都不会命中）
  由于是对于最内层循环的分析，C的未命中次数不计入

- 类AC例程的内循环以步长n扫描数组A和C的列，导致每次加载都不会命中，因此未命中率是2。

- 类BC例程使用步长为1的访问模式遍历数组B和C，每次迭代不命中率只有0.25，一共0.5

根据这6个版本，测量出每次内循环迭代所需要的CPU周期数与数组大小n的函数：
![[Pasted image 20241112151223.png]]
可以看到：
- 在较大的n值下，最快的版本比最慢的版本所需周期少约40倍
- 同一等价类中的一对版本，测量性能大致相同
- 在这种情况下，不命中率是一个比内存访问总数更好的性能预测指标
- 对于更大的n值，最快的（最下面两条曲线）一对版本的性能几乎没有改变，这是因为**预取硬件能够辨认出步长为1的访问模式**，且速度足够跟上内循环的内存访问，**在这之前预取到下一步要用到的元素到高速缓存中了**

### 6.6.3 小结：程序中利用局部性的经验

- 将你的注意力集中在最内层的循环中，大部分计算和内存访问都在这里
- 按照数据对象存储在内存中的顺序，以步长为1的访问模式来读数据，有利于利用预取机制，提高空间局部性
- 一旦从存储器中读入一个数据对象，就尽可能多地使用它

---


# Chapter 7. 链接
**链接是将各种代码和数据片段收集并组合成为一个单一文件的过程**，这个文件被**加载（复制）** 到内存并执行。
链接可以执行于**编译时：源代码被翻译为机器代码时**，也可以执行于**加载时：程序被加载器加载到内存并执行时**，还可以执行于**运行时：由应用程序来执行**
现代操作系统中，**链接是由链接器程序自动执行的**

链接器是软件开发的关键程序，利用它可以实现**编译分离：将一个大型的应用程序分解为更小的、更好管理的模块，允许我们独立地修改和编译这些模块，修改后只需要简单地进行单独重编译和重新链接即可，而不会影响其他文件**

## 7.1 编译器驱动程序
考虑以下的C语言运行示例：
main.c：
```c
int sum(int *a, int n);
int array[2] = {1, 2};
int main() {
	int val = sum(array, 2);
	return val;
}
```
sum.c：
```c
int sum(int *a, int n) {
	int i, s = 0;
	for (i = 0; i < n; i ++)
		a += a[i];

	return s;
}
```
大多数编译系统提供**编译器驱动程序**，它代表用户在需要时调用的**语言预处理器、编译器、汇编器和链接器**，例如将上面的两个源代码构建为程序，就需要输入下面的命令：
```
gcc -Og -o prog main.c sum.c
```
生成可执行文件`prog`的步骤如下：
![[Pasted image 20240922212537.png]]
在翻译过程中，**驱动程序首先运行==c预处理器cpp==来将`.c`源程序文件翻译为`.i`ASCII码源文件：**
```
cpp [...一些其他的语句] main.c /tmp/main.i
```
**然后运行==c编译器ccl==将`.i`ASCII码源文件翻译为一个ASCII汇编语言文件`.s`：**
```
ccl /tmp/main.i -Og [...一些其他语句] -o /tmp/main.s
```
然后才**运行==汇编器as==，将`.s`文件翻译为可重定位目标文件`.o`：**
```
as [...其他语句] -o /tmp/main.o /tmp/main.s
```

在把所有的组件生成为可重定位目标文件后，运行==**链接器ld**==，把必要的目标文件组合起来，创建**可执行目标文件**
```
ld -o prog [一些系统的中间目标文件和语句] /tmp/main.o /tmp/sum.o
```
生成完之后，在当前目录下直接输入程序的名字即可运行它了：
```
prog
```
这步中shell调用了操作系统中的**加载器**函数，**它将可执行文件中的代码和数据复制到内存，然后将控制转移到该程序的开头**

## 7.2 静态链接
像Linux LD这样的==**静态链接器==以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的，可以加载和运行的可执行目标文件作为输出**。
输入的**可重定位目标文件由各种不同的代码和数据节构成**，每一节都是一个连续的**字节序列**，指令在一节中，初始化了的全局变量在一节中，未初始化的变量又在另一节中

为了构造可执行文件，链接器必须完成两个主要任务：
- **符号解析**：目标文件定义和引用符号，每个符号对应于一个函数、全局变量或静态变量。**符号解析的目的是将每个符号引用正好与一个符号定义关联起来**
- **重定位**：编译器和汇编器生成从地址0开始的代码和数据节，**链接器把每个符号定义与一个内存位置相关联，进行重定位，修改所有对这些符号的引用使其指向这个内存位置**。链接器使用汇编器产生的重定位条目的详细指令，不加甄别地执行重定位

下面的章节会对这些任务进行详细介绍，我们只需记住：**目标文件是字节块的集合，这些块中有些包含程序代码，有些包含程序数据，其他的则包含引导链接器和加载器的数据结构。链接器将这些块进行连接，确定被链接块的运行时位置并修改代码和数据块中的各种位置**
链接器没有什么关于目标机器的信息，因为编译器和汇编器进行了大部分工作

## 7.3 目标文件与目标模块
目标文件有以下三种形式：
- **可重定位目标文件：包含二进制代码和数据，在编译时可和多个可重定位目标文件进行合并，创建一个可执行目标文件**
- **可执行目标文件：包含二进制代码和数据，可以直接被复制到内存并执行**
- **共享目标文件：一种特殊类型的==可重定位目标文件==，可以在加载或运行时被动态地加载进内存并链接**

编译器和汇编器生成可重定位目标文件和共享目标文件，链接器生成可执行目标文件。==**一个目标模块就是一个字节序列==，一个目标文件就是一个==以文件形式存放在磁盘中的目标模块**==，它们常常被混着用
目标文件按特定的目标文件格式来组织，各个系统的格式都不相同，**现代Linux和Unix系统使用可执行可链接格式ELF**

## 7.4 可重定位目标文件
一个典型的**ELF可重定位目标文件**中的格式如下：
![[Pasted image 20240923180945.png]]
 ELF头以一个**16字节的序列开始**，序列描述了生成该文件**系统的字的大小和字节顺序**；剩下的部分则包含帮助链接器进行**语法分析**和**解释目标文件的信息**，包括ELF头的大小、目标文件的类型、机器类型、**节头部表**的文件偏移和节头部表中条目的大小和数量

在ELF头和节头部表之间的部分都是**节**，典型的**ELF可重定位文件**包含以下几个节：
- .text ：**已编译程序的机器代码**
- .rodata ：**只读数据**，例如printf语句的格式串和switch语句的跳转表
- .data ：**已初始化的全局和静态变量**。局部变量由于存储在运行时栈中，不会出现在这里
- .bss ：**未初始化的全局和静态变量，以及所有被初始化为0的全局和静态变量**。这个节不占实际空间，只作为占位符，用于优化空间效率，可以理解为“Better Save Space"
- .symtab ：一个**存放在程序中定义和引用的函数和全局变量信息的符号表**，每个重定位文件都有这么一张表，但它不包括局部变量的条目
- .rel.text ：一个.text节中位置的列表，用于**指明当链接器将该目标文件与其他文件组合时需要修改的位置**
- .debug ：**调试符号表，储存程序中定义的局部变量和类型定义、程序中定义和引用的全局变量，以及原始C源文件。只有用`-g`选项调用编译器时才能得到**
- .line ：**原始C源程序中的行号与.text节中机器指令之间的映射**，只有用`-g`选项调用编译器时才能得到
- .strtab ：**字符串表，包括.symtab和.debug节中的符号表，以及节头部中的节名字，是以null结尾的字符串序列**

## 7.5 符号和符号表
每个可重定位目标模块m都有一个符号表，包含m定义和引用的符号的信息，有以下三种不同的符号：
- **由模块m定义并能被其他模块引用的全局符号**，对应于**非静态的C函数和全局变量**
- 由其他模块定义并被模块m引用的全局符号，称为**外部符号**
- **只被模块m定义和引用的局部符号**，对应于带`static`属性的C函数和`static`全局变量（**也就是静态的**），不能被其他模块引用

注意：**“本地非静态程序变量”和“非静态的函数和全局变量”是不同的概念，前者只能适用于局部作用域**，例如函数体中，而后者是全局的。因此上述符号表会被储存在.symtab节中
**本地非静态程序变量是运行时在栈中被管理的**，链接器对它们不感兴趣

而带有`static`属性的**本地过程变量**不在栈中管理，而**会在.data或.bss中单独被编译器分配空间，创建一个有==唯一名字==的链接器符号**。
例如若同一模块的两个不同函数都声明了`static int x = 1;`，那么编译器在编译时会向汇编器输出两个不同名字的局部链接器符号，像是`x.1`和`x.2`

总之，**带有`static`属性的全局变量和函数是模块私有的，带有`static`属性的函数内变量是函数私有的，它常用于隐藏内部的函数和变量声明**

上述符号表中的符号由编译器输出到汇编语言`.s`文件，由汇编器构造，存储在.symtab节中，下图是**一个符号中的条目格式**的示例：
![[Pasted image 20240923200834.png]]
- **name是字符串表中的字节偏移**，它指向符号的**以null结尾的字符串名字**；
- **value是符号的地址**，即**距定义目标的节的起始位置的偏移**，在可执行目标文件中是**绝对运行时地址**；
- **size是目标的以字节为单位的大小**；
- type要么是数据，要么是函数
- binding表示符号是本地的还是全局的

**每个符号**都被分配到**目标文件的某个节**，表示为**section**字段，**section字段其实是一个指向单个符号所在节的==索引**==，范围到节头部表，它有三个**伪节**：**ABS，不该被重定位的符号；UNDEF，未定义的符号，即在本模块引用，在其他地方定义的符号；COMMON，还未被分配位置的未初始化数据目标，由value字段给出对齐要求，size字段给出最小大小**。这些伪节只有可重定位目标文件中有，可执行目标文件中没有
注意，COMMON和.bss有些区别：CMMON是”未初始化的全局变量“，而.bss是”未初始化静态变量和初始化为0的全局或静态变量“


**可以使用GNU READELF工具来查看目标文件的内容**，例如下面展示了`main.o`文件中的后三个条目：
![[Pasted image 20240923203814.png]]
Num指示项目行号，这里省略了前0~7的8个条目；**Ndx指示它们在一个文件中的节的位置**（看7.4节的图），**从上到下用整数索引**，例如这里main位于Ndx=1处，即位于.text节中，偏移量value=0，大小为size=24字节；同理array位于Ndx=3，即.data节中，偏移量为0，大小为size=8字节；**sum的Ndx=UND，即是外部符号的引用**

## 7.6 符号解析
链接器解析符号引用的方法是**将每个引用和它输入的可重定位目标文件的符号表中的一个确定的符号定义关联起来**
**局部符号**：编译器只允许每个模块中的每个**局部符号**有**一个**定义，**静态局部变量也会有本地链接器符号，同时编译器确保这些定义有唯一的名字**
**全局符号**：但对全局符号的引用解析就较为复杂，当编译器遇到一个不是在当前模块中定义的符号（变量或函数名）时，会假设它是在其他某个模块中定义的，生成一个**链接器符号表条目，交给链接器处理**。如果链接器在任何输入模块中都无法找到这个被引用符号的定义，就输出一条错误信息并终止
**多个目标文件可能会定义相同名字的全局符号**，这时链接器要么标志一个错误，要么以某种方法选出一个定义并抛弃其他定义

### 7.6.1 链接器如何解析多重定义的全局符号
链接器的输入是一组**可重定位目标模块**，**每一个模块都定义了一组符号，有些是局部的，仅对定义它们的模块可见；有些是全局的，对其他模块也可见**。
如果多个模块定义了同名的全局符号，进行区分的方法是**编译时，编译器向汇编器输出每个全局符号时有强弱之分，汇编器将该信息隐含地编码在可重定位目标文件的符号表里**，其中==**函数和已初始化的全局变量==是强符号，==未初始化的全局符号==是弱符号**
Linux链接器为强弱符号规定以下规则来处理重命名的全局符号：
- **不允许有多个同名的强符号**
- **如果强符号和多个弱符号重名，那么选择强符号**
- **如果多个弱符号重名，任意选取一个弱符号**

当强符号被多次定义时，例如两个模块同时出现了`main`函数的定义，那么就会生成错误信息
```
gcc fool.c bar1.c
/tmp/ccq2Uxnd.o: In function'main':
bar1.c:(.text+Ox0): multiple definition of'main'
#报错信息
```
不过如果一个全局符号名虽然被多次声明，但是**只被一个模块初始化**，链接器就会默认地选择被初始化的模块中的该符号；对其他弱符号和强符号也是同理的，**链接器通常不会表明它检测到多个弱符号与强符号同名**

考虑这样一个例子：
全局变量x在一个有main函数的模块中被声明为int并初始化；另一个模块中被声明为double但未被初始化，同时在该模块下的函数中为x赋了一个double值，在第一个模块中的main函数被调用。
这种情况下被赋值的x实际上是int的那个全局变量x，因此在调用gcc后会进行警告：为一个4字节的int赋上了8字节的double值

这个错误往往会在程序执行一段时间后才表现出来，远离错误的发生地，因此在大型系统中相当难以修正，此时**使用选项`GCC-fno-common`调用链接器，会告诉链接器在遇到多重定义的全局符号时触发错误，或者用`-Werror`选项把所有警告变成错误**，会便于我们发现错误一些

编译器在翻译一个模块，遇到弱全局符号，无法确定其他模块是否也定义了它，或是应该使用多重定义中的哪个，于是将该符号分配为COMMON，决定权留给链接器；如果是初始化了的全局符号和唯一构造的静态符号，编译器就能自信地分配其为.data或.bss

### 7.6.2 与静态库链接
目前为止我们都只是假设链接器读取一组可重定位目标文件，并把它们链接在一起形成可执行文件。实际上，**所有的编译系统都提供一种将所有相关的目标模块打包成一个单独的文件的机制，称为==静态库==**。
如果不使用静态库的形式，我们就得让编译器一个个判断出所使用的标准库函数是什么，这会大大**增加编译的复杂性**；而如果把所有标准库的函数都放在同一个可重定位目标模块中，会**浪费磁盘空间**，因为**很多用不到的函数副本都放在内存中**了
因此我们**为每个标准函数创建一个独立的可重定位文件**，把它们存放在一个大家都知道的目录中，但是这样又有一个问题：需要程序员显式地将各个可重定位文件打出来进行链接，就像
```
gcc main.c /usr/lib/scanf.o /usr/lib/printf.o ...
```
这太麻烦了，为此，静态库的概念允许**相关函数可以被编译为独立的目标模块**，然后**封装成一个单独的静态库文件**，应用程序可以通过在命令行上指定单独的文件名字来使用这些库中定义的函数
例如，使用c标准库和数学库中的所有函数，可以指定：
```
gcc main.c /usr/lib/libm.a /usr/lib/libc.a
```
这样链接器只需要复制被引用的这俩目标模块即可，而且不需要太多显式的指定（**C编译器驱动程序也会自动将一些目标模块传递给链接器**，比如`libc.a`，所以这里的该项其实是多余的）
在Linux系统中，**静态库的文件格式是==存档==，扩展名为`.a`，它有一个头部用于描述每个成员目标文件的大小和位置**；在windows系统中文件格式拓展名则为`.lib`

我们可以使用**AR工具**创建一个**静态库**，例如将函数`addvec`和`multvec`合并为一个静态库：
```
gcc -c addvec.c multvec.c
ar rcs libvector.a addvec.o multvec.c
```
当函数`main.c`使用了该静态库定义的函数原型时，我们首先**把它翻译为可重定位目标文件**：
```
gcc -c main.c
```
**所有的标准库头文件都在GCC的默认搜索路径下，所以如果引用了标准库头文件，无需显式说明它们**
然后将已经构造好的静态库文件与可重定位目标文件编译并链接：
```
gcc -static -o prog main.o ./libvector.a
```
其中`./libvector.a`是指在当前目录`.`下找到`libvector.a`
用到的其他默认静态库无需被显式说明，整个生成过程可以表示为：
![[Pasted image 20240924150408.png]]

### 7.6.3 链接器如何使用静态库来解析引用
Linux链接器使用静态库解析外部引用的方式容易引起困惑：在符号解析阶段，链接器**从左到右**按照编译器驱动程序命令行上出现的顺序来扫描可重定位目标文件和存档文件，**这时如果是`.c`文件会自动翻译为`.o`文件**；扫描时链接器维护一个**可重定位目标文件的集合E**，一个**含有未解析的符号的集合U**（即引用了但未定义的符号的集合），和一个**在前面输入的文件中已定义了的符号集合D**
- 对于命令行中的每个输入文件f，链接器判断f是一个目标文件还是一个存档文件：**如果是目标文件，将f添加到E，修改U和D来反应f中的符号定义和引用**
- 如果f为存档文件，链接器试图**匹配U中未解析的符号和由存档文件成员定义的符号**，如果某**存档文件成员m定义了一个解析U中一个引用的符号，将m加入E，修改U和D**。对存档文件中的成员目标文件依次进行这样的过程直到U和D不再变化，**丢弃掉所有不在E中的成员目标文件**
- 如果进行完上述所有步骤，**U还是非空的，就输出错误并终止**；反之**对所有E中的可重定位目标文件进行合并，构建出可执行文件**


特别要注意，**命令行中库和目标文件之间的顺序十分重要**，在命令行中，**如果定义一个符号的库出现在引用这个符号的目标文件==之前==，该库会比目标文件先处理，导致符号不会被添加到E中，从而使得在处理目标文件的时候引用无法被解析，链接失败**
也就是说，**==尽量让库放在命令行的结尾==，在库之间没有成员引用时顺序随意，但当有成员引用时，==必须使得每个被引用的符号s，在命令行中至少有一个s的定义位于s的引用之后==**
***命令行顺序决定了处理顺序，一个符号s至少要有一个定义位于所有引用s的文件之后***

为了满足依赖需求，**可以在命令行上多次使用同一个库**：
```
gcc foo.c libx.a liby.a libx.a
```
或者将libx.a和liby.a合并为一个文档

## 7.7 重定位
在链接器完成符号解析后，也就是将符号引用与一个符号定义关联起来后，链接器就知道它的输入目标模块中的**代码节和数据节的确切大小**，进而开始重定位
**重定位步骤合并输入模块，并为每个符号分配运行时地址**，由以下两步组成：
- **重定位节和符号定义**：链接器将所有**相同类型的节**合并为同一类型的**聚合节**，例如所有的.data。然后**将运行时内存地址赋给新的聚合节、输入模块定义的每个节和输入模块定义的每个符号**，这样**程序中的每条指令和全局变量就拥有了==唯一的运行时内存地址**==
- **重定位节中的符号引用**：链接器**修改代码节和数据节中对每个符号的引用，使其指向正确的运行时地址**，这依赖于可重定位目标文件中的数据结构——***重定位条目***

### 7.7.1 重定位条目
汇编器生成目标模块时，并不知道数据和代码最终存放的内存位置，也不知道模块引用的外部定义的函数或全局变量的位置，所以**对于这些未知最终位置的目标引用**，汇编器生成一个==**重定位条目**==，告诉链接器在合并它们时应该如何修改这些引用
**代码的重定位条目放在.rel.text中，已初始化数据的重定位条目则放在.rel.data中**

重定位条目的格式如下：
![[Pasted image 20240924160430.png]]
==**offset==是需要被修改的引用的节偏移；
==symbol==标识被修改引用应该指向的符号；
==type==告知链接器应该如何修改新的引用；
==addend==是有符号常数，一些类型的重定位要用它对被修改引用的值做偏移调整**

ELF定义了32种不同的重定位类型，最基本的两种是：
- `R_X86_64_PC32`：该重定位使用32位PC相对地址的引用，==**PC相对地址==就是距程序计数器PC当前运行时值的偏移量**，**当CPU执行一条使用PC相对寻址的指令时，它就将在指令中编码的32位值加上PC当前的运行时值，得到有效地址**。PC当前的值通常是**下一条指令在内存中的地址**
- `R_X86_64_32`：重定位使用一个**32位绝对地址**的引用，***绝对寻址***，**CPU直接使用指令中编码的32位值作为有效地址**，不需要处理

**小型代码模型假设可执行目标文件中的代码和数据的总体小于2GB**，所以运行时可以使用32位PC相对地址进行访问，GCC默认就是小型代码模型；大于2GB的程序则使用中型代码模型和大型代码模型，通过标志`-mcmodel=medium`和`-mcmodel=large`来编译，不过多讨论这些模型

### 7.7.2 重定位符号引用
#### 1. 重定位算法
重定位算法的伪代码如下：
![[Pasted image 20240924162835.png]]
第1行和第2行**在每个节s以及与该节相关联的重定位条目r上迭代执行**
具体来说，假设每个节是一个**字节数组s**，而每个**重定位条目r**是类型为`ElF64_Rela`的结构，也就是上一节图7-9的格式
同时，它假设当重定位算法运行时，链接器已经为每个**节ADDR(s)和每个符号**都选择了**运行时地址ADDR(r.symbol)**
第3行计算的是**需要被重定位的4字节引用在字节数组s中的地址**。
两个条件判断代表：如果该引用使用**PC相对寻址**，那么就使用5~9行中的方式来进行重定位；如果该引用使用**绝对寻址**，则使用11~13行进行重定位

#### 2. 示例
以下面使用GNU OBJDUMP工具产生的`main.o`的反汇编代码为例，说明链接器是怎么使用该算法对示例程序进行引用的重定位的：
![[Pasted image 20240928220429.png]]
main函数引用的是全局符号`array`和`sum`，为每个符号引用，汇编器产生一个**重定位条目**，它们会显示在**引用的后面一行上**，作用是**告诉链接器对一个引用应该是使用32位PC相对地址还是绝对地址进行重定位**，然后链接器对这些引用应用相对应的重定位方法：
**符号sum使用重定位PC相对引用（有占位符13）；而符号array使用重定位绝对引用**

1. **重定位PC相对引用**：在上图的第6行，main函数调用函数`sum`，它在模块`sum.o`中被定义，可以看见`call`指令**开始于**节偏移`0xe`的位置，具有1字节的**操作码**`0xe8`。13和`<main+0x13>`**只是占位符**
	对应的重定位条目r的四个组成部分的值分别是：
		`r.offset = 0xf`    代表需要被修改的引用的节偏移
		`r.symbol = sum`    代表被修改引用应该指向的符号 
		`r.type = R_X86_64_PC32`   代表符号引用的类型，*32位PC相对引用*
		`r.addend = -4`   进行引用偏移调整的有符号值

   这些字段告诉链接器去修改**开始于偏移量0xf**处的**32位PC相对引用**。假设链接器已经确定
   `ADDR(s) = ADDR(.text) = 0x4004d0`  （节的运行时地址）
   `ADDR(r.symbol) = ADDR(sum) = 0x4004e8`   （符号的运行时地址）

算法中的处理如下：
![[Pasted image 20241008205427.png]]
   根据上述算法，链接器**先计算出==引用==的运行时地址**：
   $$\begin {align}
   refaddr &= ADDR(s)+r.offset \\
   &=0x4004d0+0xf\\
   &=0x4004df
   \end {align}$$
   然后**更新引用，使其在运行时指向sum程序**：
   $$ \begin{align}
   *refptr&=(unsigned)(ADDR(r.symbol)+r.addend-refaddr)\\
   &=(unsigned)(0x4004e8+(-4)-0x4004df)\\
   &=(unsigned)(0x5)
   \end{align}$$
   该引用的作用是在PC寄存器进行**寻址时**，**提供能找到该符号的运行时地址的偏移量**
   
   这样一来，在可执行文件中，进行函数调用的`call`指令的形式就变为：
```
4004de: e8 05 00 00 00          callq 4004e8<sum>
```
这说明运行时，`call`指令被存放于`0x4004de`的位置中；`callq`后的内存位置表明，当执行该指令时，**PC需要经过0x5的偏移到达位置0x4004e8**，所以此前PC的值为0x4004e3，是**紧随在call指令之后那条指令的地址**
换而言之，**callq后跟着的地址就是该sum例程的第一条指令所在位置**，这样一来就可以完成寻址了

2. **重定位绝对引用**：重定位绝对引用的过程就很简单了，因为它**直接指示运行时的内存位置**。
![[Pasted image 20241008215108.png]]
   在图7-11的第4行，`mov`指令**将array的地址复制到寄存器%edi中**，这是一个32位立即数值，由于加载前的**运行时地址值暂未确定**，因此复制过去的是**对array的32位绝对引用的占位符**。
   array对应的**占位符条目r**各成员的值：
	   `r.offset = 0xa`
	   `r.symbol = array`
	   `r.type = R_X86_64_32`
	   `r.addend = 0`
	
它们告诉链接器**要修改的绝对引用的第一个字节位于偏移量0xa**，假设链接器已经确定：
```
ADDR(r.symbol) = ADDR(array) = 0x601018
```
即该引用的绝对运行时地址
那么和图7-10说的一样，使用下面的语句进行引用修改：
![[Pasted image 20241008220219.png]]
$$ \begin{align}
*refptr &= (unsigned)(ADDR(r.symbol) + r.addend)\\
&=(unsigned)(0x601018 + 0)\\
&= (unsigned)(0x601018)
\end{align}$$
于是在得到的可执行文件中，`mov`指令所传给寄存器%edi的地址为：
```
4004d9: bf 18 10 60 00         mov  $0x601018,%edi
```
这代表了**array运行时的绝对地址**


在经过上述重定位过程后，原来使用各种占位符进行运行时地址的替代的机器代码在加载时被重写为：
![[Pasted image 20241008220802.png]]’这样的指令字节就**可以被直接复制到内存并执行**了

## 7.8 可执行目标文件
上一节叙述了**链接器将多个目标文件合并为一个可执行目标文件的过程**，我们的程序由一组**ASCII文本文件**转化为了一个**包含所有加载程序到内存并运行所需的信息的二进制文件**
一个典型的==**ELF可执行文件**==的构成如下：
![[Pasted image 20241008221343.png]]
它有点类似于ELF可重定位目标文件的格式
- **ELF头描述文件的总体格式**，它包括程序的**入口点：程序运行时要执行的第一条指令的地址**
- `.text`、`.rodata`和`.data`节与可重定位目标文件中相应节储存的内容一致，**区别仅在于它们已经被完成了重定位，地址改为最终运行时地址了**
- `.init`节定义了一个叫做`_init`的小函数，**在程序的初始化代码中被调用**
- 既然已经完成了所有的重定位，自然不需要任何`rel`节来指示应该修改的引用


ELF可执行文件很容易被加载到内存，它的连续的**片段chunk：含有包括代码段、数据段、堆、栈、符号表、BSS在内的总的功能部分** 被映射到**连续的内存段**，映射关系由程序头部表描述
程序头部表可以由OBJDUMP显示，例如：
![[Pasted image 20241008223224.png]]
表中将值与名字一一对应地展示了这种映射关系
最上面一部分是**可执行文件中只读内存段（代码段）的部分**，根据`flags`项目可以看到该代码段有**读和执行访问的权限**，其**开始的内存位置**为`vaddr 0x400000`，**总共的内存大小**为`memsz 0x69c`字节，被初始化为**可执行目标文件**在**内存**中的`filesz 0x69c`个字节（也就是**初始化后占可执行目标文件的多少字节**，可以看见它进行初始化的位置无偏移`off 0x0`，**而`memsz == filesz`，说明整个段的部分都在运行前被初始化了**），这些字节包含了上面所说的ELF头、程序头部表、.init、.text、.rodata节（图7-13中标注为“只读内存段”的部分）

下面的部分则是**可执行文件中读/写内存段（数据段）的部分**，它开始于内存地址`vaddr 0x600df8`处，总内存大小为`memsz 0x230`，它使用从目标文件中偏移`off 0xdf8`处的`.data`节中的`filesz 0x228`个字节进行初始化（**只有0x228字节大的部分在运行前被初始化**）
剩下的`0x230 - 0x228 = 0x8`个字节对应于**运行时才被初始化为0的`.bss`数据**

**对于任何段s，链接器必须选择一个起始地址`vaddr`，满足**：
$$ vaddr \mod align = off \mod align$$
`off`是该段的第一个节的偏移量，`align`是程序头部指定的对齐，如图7-14的数据段（后面那个部分）中的对齐$align = 2**21 = 2^{21} = 0x200000$，有
$$ \begin {align}
vaddr \mod align &= 0x600df8 &\mod 0x200000 &= 0xdf8\\
off \mod align &= 0xdf8 &\mod 0x200000 &= 0xdf8
\end{align}$$
**对齐的要求是为了当程序执行时，目标文件中的段能更有效率地传输到内存中**，这个优化关于**虚拟内存的组织形式**，会在第九章讲解

## 7.9 加载可执行目标文件
运行可执行目标文件prog，在linux shell中输入
```
./prog
```
即可运行
bash将所有不是内置shell命令的名字都视为一个**可执行目标文件**，调用某个驻留在存储器中的**操作系统代码：加载器**来运行该文件，任何Linux程序都可以通过**调用`execve`函数来调用加载器**，这个函数会在8.4.6节详细讲到
**加载器将可执行目标文件中的代码和数据从磁盘复制到内存，跳转到程序的第一条指令（入口点）来运行该程序**，这样复制到内存并运行程序的操作就是加载

每个linux程序都有一个**运行时内存映像**：
![[Pasted image 20241011200259.png]]
**代码段总是从地址`0x400000`开始**（只读代码段），后面依次跟着数据段和运行时堆，**运行时堆会随着`malloc`库的调用而向上增长**
堆后面的区域是**共享模块：动态链接库被加载到进程的虚拟地址空间中的位置**
再往后的**用户栈**总是从**最大的合法用户地址$2^{48}-1$开始，向较小的内存地址增长**，栈上从$2^{48}$开始的区域是为**内核中的代码与数据**保留的，即**操作系统驻留在内存中的部分**

当加载器运行时，它创建上面这样的内存映像，在**程序头部表**的引导下将可执行文件的**片**复制到**代码段和数据段**，随后跳转到程序的入口点，linux操作系统的入口点设置为`_start`函数的地址，该函数定义在**系统目标文件`ctrl.o`** 中，调用**系统启动函数`__libc_start_main`**，初始化执行环境，并且调用**用户层的`main`函数**

具体的加载过程需要使用到**进程、虚拟内存和内存映射**的概念，这里只是给出一个大致的概念，随着后面几章的学习会更加具体

## 7.10 动态链接共享库
7.6.2节中的**静态库解决了关于如何让大量相关的特定函数对应用程序可用的问题**。然而静态库也有缺点：需要定期维护和更新，并且使用者需要了解并下载这些更新后的库才能进行使用
同时由于**内存系统资源总是非常稀缺的**，使用静态库时，其中的函数的代码会被复制到运行进程的文本段中，一旦这样的进程多了起来，内存资源就产生了许多浪费

**共享库**的存在就是为了解决静态库的缺陷：共享库是一个**目标模块**，在**运行或加载时**可以**被加载到任意的内存地址**，并和任意一个**在内存中的程序**进行链接，这就是**动态链接**的过程
动态链接由**动态链接器**程序来执行，共享库也称为**共享目标，其后缀常为`.so`（`.dll`是windows系统的动态链接库DLL后缀）** 

共享库以两种不同的方式来实现”共享“：
- 在任何给定的文件系统中，**一个库有且只有一个`.so`文件**，所有引用该库的可执行目标文件都共享它里面的代码和数据，而非将其副本嵌入到文件中去
- 在内存中，**一个共享库的`.text`节的一个副本可以被不同的正在运行的进程共享** （这部分在第九章进行详细说明）

程序与动态库进行动态链接的过程可以被概括如下：
![[Pasted image 20241011210845.png]]
动态链接库将链接分成静态链接和动态链接两个阶段。**动态链接库与`.c`文件进行==静态链接==部分的代码是位置无关的**，这样的共享库文件可以通过以如下命令调用链接器来构造：
```
gcc -shared -fpic -o libvector.so addvec.c multvec.c
```
其中`-fpic`指示编译器**生成与位置无关的代码**，`-share`指示链接器**创建一个共享的目标文件`.so`**
有了共享库文件后，直接与程序进行链接形成可执行目标文件：
```
gcc -o prog21 main2.c ./libvector.so
```

此时**没有任何`libvector.so`的代码和数据节被真的复制到可执行文件`prog21`中**，进行静态链接的部分是一些**重定位和符号表信息**，用于运行时对`libvector.so`中的代码和引用进行解析
当加载器对`prog21`进行加载和运行时，如7.9节所说的一样，程序的运行时内存映像为共享区域预留出一片位置，**可执行目标文件包含一个`.interp`节，它含有==动态链接器==的路径名**
由于**动态链接器本身就是一个目标**，加载器根据`.interp`节的路径对动态链接器进行加载和运行，动态链接器执行下面的工作来完成动态链接：
- **重定位**不同的`.so`文件的文本和数据到**不同的内存段**
- **重定位**可执行程序中所有对由这些`.so`文件定义的符号的**引用**
- 将控制传递给应用程序，此时共享库的位置就固定了

## 7.11 从应用程序中加载和链接共享库
一些应用中，**应用程序**可能**在它运行时也会要求动态链接器加载和链接某个共享库**，而非在编译时链接，例如：
现实世界中，开发者常常利用共享库来分发软件更新：生成一个新版本共享库，用户进行下载并替代当前版本，下次运行应用程序时，程序在运行时自动链接和加载新的共享库
或者是在高性能Web服务器中生成动态内容，这都是基于**动态链接**的应用

**动态链接**的思路是**将每个生成动态内容的函数打包在共享库中，当一个来自Web浏览器的请求到达时，服务器动态地加载和链接适当的函数，进行直接调用**，而不是在子进程的上下文中进行函数的运行。从而使得服务器无需停止就可以对函数进行更新、添加
linux系统为动态链接库提供了一个简单的**接口**来**允许应用程序在运行时加载和链接共享库**：

- **打开一个新共享库**`filename`：
```
#include <dlfcn.h>  //需要引用这个库

void *dlopen (const char *filename, int flag);
//返回一个指向*句柄*的指针，出错时为NULL
// filename是共享库的名字
```
`dlopen`函数**加载和链接共享库`filename`**，当使用`RTLD_GLOBAL`选项打开共享库时，该库的符号会被标记为全局符号，函数使用这样的库来解析`filename`库中的外部符号
若当前的可执行文件使用`-rdynamic`选项进行编译，这表示将所有的全局符号导出，它的全局符号也可用于解析外部符号
函数中的第二个参数`flag`要么包括`RTLD_NOW`：**告诉链接器立刻解析对外部符号的引用**；要么包括`RTLD_LAZY`：**指示链接器直到执行来自库中的代码时才进行符号解析**
上述两个标志值可以与`RTLD_GLOBAL`连用，表示使库中符号对后续库可用，解析时间取决于`RTLD_NOW`和`RTLD_LAZY`
句柄：是一种**用于标识或引用系统资源的抽象概念**，通常是一个整数或指针，**代表某个对象或资源**。程序通过句柄来**间接访问这些资源**，更加安全、便于管理

- 在已经打开的**共享库**中**寻找符号定义**：
```
#include <dlfcn.h>
void *dlsym (void *handle, char *symbol);
//接受一个句柄指针，返回一个指向符号的指针
```
函数`dlsym`的输入是一个**指向前面已经打开了的共享库的句柄**和一个**名字`symbol`**，如果寻找的符号`symbol`存在，就**返回该符号的地址**；反之则NULL

- **卸载无用的共享库**：
```
#include <dlfcn.h>
int dlclose (void *handle);
```
如果**没有其他共享库还在使用这个共享库，那么卸载该共享库**，卸载成功为0，反之-1

- **错误检查与返回**：
```
#include <dlfcn.h>
const char *dlerror (void);
```
该函数返回一个字符串：描述调用`dlopen`、`dlsym`或`dlclose`函数时发生的**最近错误**，若没有错误发生，则返回NULL

下面是一个使用这些接口进行动态链接的示例，我们动态链接之前的`libvector.so`共享库：
```
#include <stdio.h>
#include <stdlib.h>
#include <dlfcn.h>

int x[2] = {1, 2};
int y[2] = {3, 4};
int z[2];

int main() {
	void *handle;
	void (*addvec)(int *, int *, int *, int);
	char *error;

	handle = dlopen("./libvector.so", RTLD_LAZY);  //我们要找的资源就是"libvector.so"
	if (!handle) {
		fprintf(stderr, "%s\n", dlerror());
		exit(1);
	}

	addvec = dlsym(handle, "addvec"); //寻找共享库libvector.so中符号addvec的定义并使用
	if ((error = dlerror()) != NULL) {
	fprintf(stderr, "%s\n", error);
	exit(1);
	}

	addvec(x, y, z, 2);
	printf("z = [%d %d]\n", z[0], z[i]);

	if (dlclose(handle) < 0) {  //关闭共享库，如果失败，进行报错
		fprintf(stderr, "%s\n", dlerror());
		exit(1);
	}
	return 0;
}
```


要编译该程序，以下面的方式调用GCC即可：
```
gcc -rdynamic -o prog2r dll.c -ldl
```

> [!NOTE] 共享库与Java本地接口**JNI**
> **Java本地接口JNI**是Java定义的**标准调用规则**，它允许java程序调用**本地的C和Cpp函数**，其思想是：将本地的函数编译到一个共享库中，当java程序试图调用函数，**java解释器**利用`dlopen`接口动态链接和加载该共享库，然后进行符号查找与调用


## 7.12 位置无关代码
共享库的主要目的是**允许多个正在进行的进程共享内存中相同的库代码，从而节省内存资源**（无需多次拷贝库代码）
上一节介绍了动态加载和链接共享库的接口，那么多个进程是如何实现共享一个代码段副本的？
可以设想一个简单的方法：**为每个共享库分配一个实现预备好的专用的地址空间片，要求加载器总在该地址加载一个共享库**，但是显然，这种方法对于地址空间的使用非常死板：这部分空间**无论用或不用都会被分配**，同时如果库更新了，还得**确保这个片的大小能够容纳下变大的库**，否则得去寻找另一个片；又或者新增库的时候，又要**为其分配新的片**，而且每个系统的库的分配还可能不同
**管理紊乱，空间使用效率不高**

作为改进，现代系统**对共享模块的代码段使用特别的编译方式编译为==位置无关代码==**，使其可以被加载到内存的任何位置而**无需链接器修改**，实现多个进程共享同一代码段的**单个副本**
**位置无关代码PIC：可以加载而无需重定位的代码**，这样的代码可以**使用GCC的`-fpic`选项生成**，**共享库的编译必须使用该选项**
在同一目标模块中，符号的引用不需要进行特殊处理就是PIC的，这些引用使用PC相对寻址的方式编译，由静态链接器在目标文件的构造时对其进行重定位
而共享模块中定义的**不在程序中的外部过程**，及**其对全局变量的引用**，需要使用下面的特殊技巧使其称为PIC：
### 1. PIC数据引用
**全局变量的PIC引用**基于下面这个事实：**无论我们在内存中的何处加载一个目标模块**（包括共享模块），**模块的数据段与代码段的距离都是不变的**，因此**代码段中的任何指令**与**数据段中的任何变量**之间的**距离**都是一个**运行时常量**，与代码段和数据段的绝对内存位置无关

生成全局变量的PIC引用时，编译器在**数据段开始的地方**创建了一个**全局偏移量 表GOT**的表格，在表格中，**每个被该目标模块引用的全局数据目标**（过程或全局变量）都拥有一个**8字节的条目**，编译器为每个条目生成一个**重定位记录**，加载时**动态链接器**根据实际加载的绝对地址填充这个表，程序代码通过**间接引用GOT**来访问全局变量，从而实现位置无关。

例如，示例中的`libvector.so`共享库的GOT如下所示：
![[Pasted image 20241017160555.png]]
`addcnt`是一个在该模块中定义的全局变量，定义在共享模块`libvector.so`中，模块中的`addvec`例程在使用这个全局变量时，使用的其实是对`GOT[3]`的间接引用，也就是寄存器`%rax`的值，然后根据这个地址在内存中找到`addcnt`，对其加1
代码段中，**寄存器`%rip`存储的是当前指令下一条指令的地址**，由于数据段与代码段之间的距离是常量，我们可以**通过指令的地址获得数据段中全局偏移量表某个项目的引用**
`mov 0x2008b9(%rip),%rax`代表由下一条指令`addl`的地址加上`0x2008b9`的常量偏移，得到GOT表中索引3处的位置，存到寄存器`%rax`中，此时**相当于是一个占位符**：当还没加载时，该位置中没有任何实际的地址；加载完成后，动态链接器**为该位置赋予一个指示全局变量真实位置的绝对地址**，那么这个占位符就变成了对应全局变量的地址，**即`%rax`中的值在加载后变为了一个具体的地址**
随后`addl`指令对寄存器`%rax`中存储的地址进行访问，也就是访问全局变量`addcnt`并且进行加1

总之，GOT的思想是：**在未加载时提供一个“内存目录”，当代码段中的指令需要访问全局变量的内存位置时，先通过指令和数据段的常量距离这个性质，使指令访问GOT中为该全局变量预留的位置，作为“占位符”；在加载后，该位置便会填充上该全局变量的真实内存地址，“占位符”位置上就是一个有效地址，可以无缝衔接地对全局变量进行访问**

分析：首先需要明确：**无论是动态还是静态链接，对一个全局变量的访问终归是需要一个真实的内存地址，在地址没被解析时，寄存器存的所谓全局变量的地址都是“占位符”**
区别在于：
若程序引用**静态链接库**，**库代码整合到最终的可执行文件中**，加载时被一同加载，因此存在一个相对关系或能知道绝对地址，通过**重定位算法**能为符号与一个绝对运行时地址相关联，因此该变量符号就对应了一个内存地址，**机器代码中寄存器存的地址占位符直接在重定位的过程中被解析**：
```
mov [global_var],%rax  #[global_var]在编译时已知，链接时被解析
```

若程序引用**动态链接库**，**共享模块可能被加载到任意的内存位置**，和程序代码无关，因此动态链接时，无法知道一个符号的具体地址或者与某个指令的相对位置，**只有在程序运行时通过==动态链接库==才能知道具体的地址**
**一个个找到存储代表这些全局变量的地址的“占位符”的寄存器，进行代码的修改太麻烦了，不如直接组织一个数据结构，改变“占位符”的形式，使其指向这个数据结构，在获取具体地址信息时传递给该数据结构，然后“占位符”随之被解析为真实的地址**，这就是GOT的主要思想
GOT强行为其提供相对位置：**利用代码段与数据段总的距离固定，每个部分之间的距离也固定**这一性质，在数据段开辟一个位置，当指令需要访问全局变量时，**用该指令和GOT中存放该变量的相对距离进行位置的索引**，起到占位符的作用，在动态链接后，这个位置就会被赋予该变量的真实内存位置，指令可以顺畅地进行变量的访问
```
mov [%rip + GOTPCREL],%rax  #%rip是下一条指令，也就是会用到全局变量的指令的地址，GOTPCREL是数据段中全局变量在GOT的位置与下一条指令之间固定的偏移量
```

（上面所说的“占位符” 的更正规名字是 “==**重定位记录**==”）

### 2. PIC函数调用
全局数据目标除了全局变量外，还有**程序中调用的过程（函数）**
假设程序调用一个由共享库定义的函数，共享模块可能被加载到任意内存位置，**编译器自然也无法知道这个函数的运行时地址**
如果我们为调用该函数时所用的名字**引用生成重定位记录**，在加载时通过**动态链接库**为该重定位记录进行解析，也不是不行，但是**需要链接器对调用该函数的模块进行代码修改**，这不PIC

==**延迟绑定==：将过程地址的绑定推迟到第一次调用该过程时**
采用这种技术的原因是虽然库中会有很多很多函数，但一个程序往往只会使用其中的一部分，所以**将函数地址的解析推迟到它第一次被实际调用时，就可以避免大量的无用重定位**
后续的调用采用对第一次调用的间接引用即可

延迟绑定的实现需要**两个数据结构：==数据段==中的全局偏移量表GOT和==代码段==中的过程链接表PLT**
若一个目标模块调用了任何一个定义在共享库中的文件，它就会有自己的GOT和PLT
- **过程链接表PLT**：一个**代码段中的数组**，它的每个条目都是**16字节代码**，**一个条目负责调用一个具体的函数（跳转到函数代码的位置）**，有几个特殊的条目：`PLT[0]`：跳转到**动态链接器**；`PLT[1]`：调用**系统启动函数**，初始化执行环境并调用main函数；`PLT[2]~more`：调用用户代码调用的函数
- **全局偏移量表GOT**：一个**数据段中的数组**，每个条目8字节，当与PLT一起使用时会有几个特殊的条目：`GOT[0] & GOT[1]`：包含动态链接器解析函数地址时用到的信息；`GOT[2]`：动态链接器在`ld-linux.so`模块中的入口点，除此以外，其他项目要么对应于程序用到的全局变量，要么对应于一个被调用的函数，地址都需要在运行时解析
- 对于函数调用的解析，每个GOT中的条目都有一个相匹配的PLT条目，GOT和PLT协同工作。初始时每个GOT条目都指向**对应PLT条目的第二条指令**（一个PLT条目由多条指令组成，也就是函数的机器代码）

下图展示了GOT与PLT是怎么协同工作的：
![[Pasted image 20241017193709.png]]
对于共享库内的函数`addvec`，在第一次调用时才开始解析，**第一次调用**时：
- 1. 首先不直接跳转到`addvec`对应的实际地址，而是**先进入`addvec`在PLT中的条目`PLT[2]`**
- 2. PLT中，`addvec`的入口首先包含一个**跳转到GOT中`addvec`对应条目**的指令，这里是`GOT[4]`
- 3. 初始时，由于**GOT条目指向的是对应于该函数的PLT条目中的第二条指令**，所以跳转到`GOT[4]`就是**跳转到`PLT[2]`中的下一条指令**
动态链接器需要栈中有两个条目：**函数的ID**，以及另外一个**重定位条目地址**：需要被重定位的具体地址，这样才能确定需要解析的函数是什么：
- 4. `PLT[2]`的第二条指令把函数ID`0x1`压入栈中，第三条指令跳转回`PLT[0]`的第一条指令
- 5. `PLT[0]`通过`GOT[1]`把重定位条目地址压入栈，然后通过`GOT[2]`跳转到动态链接器
- 6. 动态链接器使用两个参数，确定`addvec`的运行时位置，**用该地址重写`GOT[4]`并跳转到`addvec`的实际地址**

后续的调用：
- 1. 进入`PLT[2]`
- 2. 通过`GOT[4]`存储的`addvec`运行时地址进行跳转

## 7.13 库打桩机制
Linux的链接器支持**库打桩机制：允许截获对共享库函数的调用，改为执行自己的代码**
这样的机制让我们可以追踪某个特定库函数的调用，进行验证甚至更换
库打桩机制的基本思想：给定一个**需要打桩的目标函数**，创建一个**原型与目标函数完全一样的包装函数**，包装函数通常执行它自己的逻辑，然后调用目标函数，再**通过包装函数**把目标函数的**返回值**传递给调用者
打桩可以发生在**编译时**、**链接时**或当程序被加载和执行的**运行时**，以下面的示例程序为例进行说明，程序保存在文件`int.c`中
```
#include <stdio.h>
#include <malloc.h>

int main() {
	int *p = malloc(32);
	free(p);
	return 0;
}
```
我们的目标是利用打桩来追踪程序运行时对malloc和free的调用
### 7.13.1 编译时打桩
**编译时打桩通过==定义宏==，用自定义的包装函数调用替换共享库函数调用来实现**
在**本地的`malloc.h`文件**中，我们**声明包装函数与用于替换的宏**：
```
#define malloc(size) mymalloc(size)
#define free(ptr) myfree(ptr)   //注意这些宏

void *mymalloc(size_t size);
void myfree(void *ptr);
```
由于我们的包装函数只对函数调用进行追踪，不修改函数的行为，所以参数和返回类型和共享库函数一致
而**头文件使用==宏==来指示预处理器用相对应包装函数的调用==替换==对目标函数的调用，从而对目标函数进行替换**
在`mymalloc.c`中，我们定义包装函数：
```
#ifdef COMPILETIME  //如果定义了这个宏，执行下面的代码
#include <stdio.h>
#include <malloc.h>

void *mymalloc(size_t size) {
	void *ptr = malloc(size);
	printf("malloc(%d)=%p\n, (int)size, ptr);
}

void myfree(void *ptr) {
	free(ptr);
	printf("free(%p)\n", ptr);
}
#endif
```
它指示**如果定义了宏`COMPILETIME`，插入打桩代码**。这个宏通过使用**编译选项`-DCOMPILETIME`** 定义：
```
gcc -DCOMPILETIME -c mymalloc.c
```
并且使用下面的选项将编译完成的中间目标文件`mymalloc.o`与要追踪的程序`int.c`进行链接：
```
gcc -I. -o prog int.c mymalloc.o
```

这样一来，通过使用参数`-I.`指示C预处理器对程序进行打桩：C处理器会在搜索通常的系统目录之前，**先在当前目录下查找`malloc.h`文件**，

实际上，**使用 `-D` 选项后面紧接宏的名称，就可以在编译时定义一个这样的宏**
### 7.13.2 链接时打桩
Linux静态链接器支持使用**标志`--wrap f`** 进行**链接时打桩**，它告诉链接器：**将对符号`f`的引用解析为`__wrap_f`，并且把对符号`__real_f`的引用解析为`f`**，从而实现**在链接阶段对符号进行替换**，达到打桩的效果
使用下面定义宏`LINKTIME`的方法把程序代码文件和包装函数代码文件编译为可重定位目标文件：
```
gcc -DLINKTIME -c mymalloc.c
gcc -c int.c
```
然后通过对链接器传输上述标志，进行名称的替换：
```
gcc -Wl,--wrap,malloc -Wl,--wrap,free -o prog int.o mymalloc.o
```
**传输标志给链接器**的格式是：`-Wl,option`，其中`option`是所需的（可能多项的）标志，**其中的空格要全部替换为逗号`,`**
而在我们的包装函数`mymalloc.c`中，要修改`#ifdef`的定义为链接时，同时把我们要包装的函数的名字改成链接时会用来代替原共享库函数的形式`__wrap_*`：
```
#ifdef LINKTIME
#include <stdio.h>

void *__real_malloc(size_t size);
void __real_free(void *ptr);

void *__wrap_malloc(size_t size) {
	void *ptr = __real_malloc(size);  //调用真实的malloc函数，在编译选项下需要更名
	printf("malloc(%d)=%p\n", (int)size, ptr);
	return ptr;
}

void __wrap_free(void *ptr) {
	__real_free(ptr);  //调用真实free函数
	printf("free(%p)\n", ptr);
}
#endif
```
这样就通过链接时更名实现了库打桩

### 7.13.3 运行时打桩
**编译时打桩需要访问程序的源代码；链接时打桩需要访问程序的可重定位对象文件；而运行时打桩需要访问可执行文件**
这个机制基于**动态链接器的`LD_PRELOAD`环境变量**
该环境变量**用于解析未定义的引用**，当它被设置为一个**共享库路径名的列表时，动态链接器会首先搜索其中的库来进行未定义引用的解析**，然后才在其他库中进行搜索
通过这个机制，我们在加载时，**当动态链接器开始对程序引用的共享库函数名或全局变量进行解析时**，让其**优先在含有包装函数的共享库中**进行搜索，将搜索结果用于解析，从而实现替换函数的打桩效果：
这就需要**首先构建一个含有我们自定义的包装函数的共享库：**
```
gcc -DRUNTIME -shared -fpic -o mymalloc.so mymalloc.c -ldl
```
同时还定义了宏`RUNTIME`来进行代码的使用。
我们的主程序**正常编译即可**，我们在它运行时才进行打桩：
```
gcc -o prog int.c
```

在`mymalloc.c`中，代码应该使用我们在$7.11$节中介绍的**允许程序在运行时加载和链接共享库的接口，在程序中调用原共享库中的函数原型来完成其基本功能，因为我们不希望改变其作用效果**：
```cpp
#indef RUNTIME
#define GNU_SOURECE
#include <stdio.h>
#include <stdlib.h>
#include <dlfcn.h>

/*会被用来替换原malloc函数*/
void *malloc(size_t size) {
	void *(*mallocp)(size_t size);  //声明函数指针，该指针稍后使用dlsym获取原共享库中malloc的地址，用于对其进行调用
	char *error;

	mallocp = dlsym(RTLD_NEXT, "malloc");
	//句柄RTLD_NEXT指向该动态链接库的下一个依赖库，这里就是libc.so，在里面查找malloc这个符号，返回其地址，以使用其实现
	if ((error = dlerror()) != NULL) {
		fputs(error, stderr);
		exit(1);
	}
	char *ptr = mallocp(size);  //这里mallocp就成功被赋了原malloc中的地址，直接使用即可
	printf("malloc(%d)=%p\n", (int)size, ptr);
	return ptr;
}

/*会被用来替换原free函数*/
void free(void *ptr) {
	void (*freep)(void *) = NULL;  //和上面一样，会指向free的函数指针
	char *error;

	if (!ptr) return;

	freep = dlsym(RTLD_NEXT, "free");  //和上面一样，在下一个共享库中找到free的地址
	if ((error = dlerror()) != NULL) {
		fputs(error, stderr);
		exit(1);
	}
	freep(ptr);
	printf("free(%p)\n", ptr);
}
#endif
```

运行时，**我们需要为环境变量`LD_PRELOAD`提供我们包装函数共享库的路径，然后才进行程序的执行**，这样程序的符号解析就会使用我们的包装函数共享库了：
```
LD_PRELOAD="./mymalloc.so"
./prog
```

总结：进行运行时打桩时，不仅要实现对符号的替换，**还要在包装函数中使用系统提供的接口来访问被替换的那个共享库的原函数并使用，从而实现原函数一样的效果**，但是添加自己希望的一些功能
## 7.14 处理目标文件工具的汇总列表
Linux系统提供了大量的工具来理解和处理不同的目标文件，下面对其进行总结：
-  AR: **创建静态库**，插入、删除、列出和提取成员 。 
-  STRINGS: 列出一个目标文件中**所有可打印的字符串**。 
-  STRIP: 从目标文件中**删除符号表信息** 。 
-  NM: 列出 一 个目标文件的**符号表中定义的符号**。 
-  SIZE: 列出目标文件中**节的名字和大小** 。 
-  READELF: **显示一个目标文件的完整结构**，包括 ELF 头中编码的所有信息。包含 SIZE 和 NM 的 功能。 
-  OBJDUMP: 所有 **二进制工具之母**。能够**显示一个目标文件中所有的信息**。它最大的作用是反汇编 .text 节中的二进制指令 。 
Linux 系统为操作共享库还提供了 LDD 程序： 
-  LDD: 列出一个可执行文件在**运行时**所需要的共享库 。

# Chapter 8. 异常控制流
控制流：**程序计数器**计数一个序列，序列中的每个元素都是**某个相应指令的地址**。当从一个指令的地址**过渡到**另一个指令的地址时，就发生了**控制转移**。这个序列就是**处理器的控制流**
通常情况下，控制流是**平稳的：相邻的两个指令地址在内存中都是相邻的**，当平稳控制流发生**突变**时，往往是发生了跳转、调用或是返回等指令，它们都是必要的机制
但系统也需要对**系统状态的变化**做出反应，系统状态的变化可能是与程序执行无关的，例如：硬件定时器定期产生信号；包到达网络适配器，必须进行存储等等
现代系统通过**使控制流发生突变来对系统状态的变化作出反应**，这些突变就是**异常控制流ECF**，它们可能发生在计算机系统的任何层次

## 8.1 异常
**异常是异常控制流的一种形式**，一部分由硬件实现，一部分由操作系统实现，所以有些具体细节会随系统不同而不同，但其基本思想一般是相同的
**异常就是控制流中的突变，用于响应处理器状态中的某些变化**：
![[Pasted image 20241018220304.png]]
**处理器的状态被编码为不同的位和信号**，若当处理器正在执行当前指令$I_{curr}$时**发生一个重要的状态变化**，就说发生了一个**事件**。事件可能与当前指令的执行直接相关，也可能没有关系
在任何情况下，当处理器检测到有事件发生时，它通过一张叫做***异常表***的**跳转表**结构进行一个**间接过程调用**，跳转到专门处理这类事件的**异常处理程序**进行处理
处理完成后，程序要么把控制返回给当前的指令$I_{curr}$，要么把控制返回给它的下一条指令$I_{next}$，要么终止整个程序

### 8.1.1 异常处理
处理异常需要软件和硬件紧密合作，系统对于每种可能的异常类型都分配了**唯一的非负整数**，称为***异常号***。其中的一些号码由**处理器**的设计者分配，例如除0、内存访问违规、断点和算术运算溢出等；其他号码则是由**操作系统内核（常驻内存的部分**）的设计者分配，例如系统调用和来自外部I/O设备的信号等
当系统启动时，操作系统会分配并初始化一张**每个表目k包含了相应异常k的异常处理程序地址**的**跳转表：*异常表***，在系统执行某个程序时，处理器若检测到发生一个事件，并且确定其异常号k后，就会**触发异常：间接过程调用，通过异常表的表目k转到相应的异常处理程序**，所以**异常号是到异常表中的索引**
下图展示了处理器用异常表来触发异常的过程，有了异常号作索引，**还需要获得异常表的起始地址**，异常表的起始地址放在一个特殊的**CPU寄存器**：**异常表基址寄存器**中：
![[Pasted image 20241019140341.png]]

异常的流程类似于过程调用，但是有一些需要注意的差异：
- **过程调用时**，在进行到处理程序的跳转之前，**处理器要把返回地址压入运行时栈**；而**异常**由于返回地址要么是当前指令，要么是下一条指令，**入栈地址只有这两种情况**
- 处理器也会把**一些额外的处理器状态**压入栈中，因为处理程序返回重新执行被中断的程序时会需要这些状态
- 如果**控制**从**用户程序**转移到**内核**，那么地址、状态等项目**被压入内核栈，而非用户栈**中
- **异常处理程序运行在==内核模式==下，对所有系统资源都有完全的访问权限**

程序处理完事件后，通过执行一条特殊的**从中断返回**指令，可选地返回到被终端的程序，同时把适当的状态弹回到处理器的控制和数据寄存器中；如果中断的是用户程序，会在返回控制之前把状态恢复为**用户模式**

### 8.1.2 异常的类别
异常可以分为**中断、陷阱、故障和终止**四种类别：
![[Pasted image 20241019142154.png]]
#### 1. 中断
中断是**异步发生**的，是**来自处理器外部的I/O设备的信号**的结果，它**不由任何一条专门的指令造成，因此说它是异步的**。**硬件中断**的异常处理程序称为**中断处理程序**
I/O设备，例如网络适配器、磁盘控制器和定时器芯片，通过向处理器芯片上的一个**引脚**发送信号，**并将异常号放到系统总线上**来触发中断，**该异常号标识了引起中断的设备**：
![[Pasted image 20241019143005.png]]
即：处理器在执行完当前指令后，检测到**中断引脚**的电压变高，于是从系统总线中读取异常号，调用对应的中断处理程序，程序返回时，**将控制返回给下一条指令，程序继续执行**

**其他三种异常类型是同步发生的：是由当前执行的指令造成的**，这样的指令称为**故障指令**
#### 2. 陷阱：提供系统调用
**陷阱是有意的异常**，是执行一条指令的结果。类似于中断处理程序，**陷阱处理程序也将控制返回到下一条指令**
陷阱最重要的用途是**在用户程序和内核之间提供一个像过程一样的接口**，称为==**系统调用**==

用户程序经常需要向内核请求服务，例如读文件`read`、创建新进程`fork`、加载一个新的程序`execve`或是终止当前进程`exit`
为了允许对这些内核服务的**受控访问**，处理器提供了一条特殊的指令`syscall n`
当用户想要请求服务n时，执行这条指令，它**会导致一个到异常处理程序的陷阱**，**该处理程序对参数进行解析，然后调用适当的内核程序**：
![[Pasted image 20241019145346.png]]
系统调用行为上和普通函数调用类似，但是它们的实现不同：普通函数运行在**用户模式**下，**限制了函数可以执行的指令的类型，只能访问于调用函数相同的栈**；而系统调用运行在**内核模式**下，**允许系统调用执行特权指令，访问定义在内核中的栈**

#### 3. 故障
故障由**错误情况**引起，可能能被**故障处理程序**修复。故障发生时，处理器转移控制给故障处理程序，如果处理程序**能够修正**该错误情况，将控制返回给**引起故障的指令**，进行**重新执行**；如果不能修正，处理程序返回到内核中的`abort`例程，**终止**引起故障的应用程序
![[Pasted image 20241019150341.png]]

**缺页异常**是一个典型的故障，当指令引用一个虚拟地址，而**与该地址对应的物理页面不在内存中**，取出时就会发生故障。缺页处理程序从磁盘加载适当的页面进行修复，使当指令重新执行时相应的物理页面已经驻留在内存中了

#### 4. 终止
终止是**不可恢复的致命错误**引发的结果，通常是**硬件错误**，例如DRAM或SRAM位被损坏时发生的奇偶错误
终止处理程序将控制返回给一个`abort`例程以终止该应用程序

### 8.1.3 linux/x86-64系统中的异常
让我们看看x86-64系统定义的一些异常。其异常种类高达256种：
![[Pasted image 20241019151025.png]]
#### 1. linux/x86-64 故障和终止
- 除法错误：应用**试图除以0**时，或者一个**除法指令结果对于目标操作数来说过大了**的时候，会引发该错误，linux shell会把除法错误报告为**浮点异常**，不会被尝试修复
- 一般保护故障：一般是因为一个程序引用了一块**未定义的虚拟内存区域**；或是试图**写一个只读文本段**。该故障会被报告为“**段故障**”，不会被尝试修复
- 缺页：和之前说的一样。处理程序会**把适当的磁盘上虚拟内存的一个页面映射到物理内存的一个页面**，重新执行发生故障的指令
- 机器检测：在导致故障的指令执行中检测到**致命的硬件错误**

#### 2. linux/x86-64 系统调用
linux提供了几百种系统调用，常见的有：
![[Pasted image 20241019152116.png]]
编号（系统调用号）唯一地对应一个名字与偏移量。它也是一个**跳转表**
C程序用`syscall`函数可以直接调用任何系统函数，但这不是必要的。
对于**大多数系统调用**，标准C库提供一组方便的**包装函数**，它们将参数打包在一起，以适当的**系统调用指令**进入内核，然后将系统调用的**返回状态**传递回调用程序。**系统调用和与它们相关联的包装函数都称为==系统级函数==**

研究程序如何使用**陷阱指令`syscall`** 进行直接的linux系统调用十分有趣。**所有到linxu系统调用的参数都是通过==通用寄存器==进行传递的，而不是栈**
按照惯例：寄存器`%rax`包含**系统调用号**；寄存器`%rdi, %rsi, %rdx, %r10, %r8, %r9`包含最多**6个参数**，参数顺序和寄存器顺序一致；**从系统调用返回**时，寄存器`%rcx`和`%r11`会被**破坏**，而寄存器`%rax` **存储最后的返回值**。返回值在-4095到-1之间都标识发生了错误
例如，下面的程序将`printf`改用为系统函数`write`：
```
int main() {
	write(1, "hello,world\n", 13);
	_exit(0);
}
```
`write`的第一个参数代表将输出发送到`stdout`，第二个参数则是要写的字节序列，第三个参数是要写的字节数，注意到`write`的系统调用编号是`1`
而该程序的汇编语言：
```
.section .data 
string:
	.ascii "hello,world\n"
string_end:
	.equ len, string_end - string
.section .text
.globl main                              都是一些指示信息的头
main:
    对write的调用
    movq    $1,%rax         将write的系统调用号1传递给%rax
    movq    $1,%rdi         第一个参数
    movq    $string,%rsi    第二个参数：字节序列
    movq    $len,%rdx       第三个参数：字节数，即string的长度
    syscall                 根据前面传递给%rax的系统调用号就能进行系统调用了

	 对_exit的调用
	movq    $60,%rax        _exit的系统调用号为60
	movq    %0,%rdi         第一个参数，退出状态码
	syscall                 执行系统调用
```

## 8.2 进程
**异常是允许操作系统内核提供==进程管理==概念的==基本构造块**==
在现代系统上运行一个程序时，系统为我们提供了“好像我们的程序是当前系统中**唯一运行的程序**”的假象，包括程序独占地使用处理器和内存、处理器无间断地执行程序指令、程序中的代码和数据是系统内存中唯一的对象……这些假象都是**进程**的概念提供给我们的

**进程：一个执行中程序的实例**，系统中的每个程序都运行在某个进程的**上下文：程序正确运行所需的状态**中，上下文中的状态包括：**存放在内存中的程序代码和数据、程序的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的内容**
每次用户向shell输入一个可执行目标文件的名字进行程序的运行时，shell就会**创建一个新的进程**，在这个**新进程的上下文**中运行该可执行文件
操作系统如何实现进程的细节本书不做讨论，我们关注**进程给应用程序提供的关键抽象**：
- 一个**独立的==逻辑控制流**==：提供“好像我们的程序独占地使用**处理器（CPU）**”的假象
- 一个**私有的==地址空间**==：提供“好像我们的程序独占地使用**内存系统**”的假象

### 8.2.1 逻辑控制流
即使系统中有许多其他程序在执行，进程也能向程序提供好像它在独占处理器的假象
使用调试器对程序单步执行时，我们可以看见一系列**程序计数器PC**的值，它们**唯一地对应于**包含在**程序的可执行目标文件**中的**指令**，或是包含在运行时动态链接到程序的**共享对象中的指令**
这样的**PC值的序列**就叫做**逻辑控制流（逻辑流）**

例如，一个系统运行着三个进程时，如下图所示：
![[Pasted image 20241022140433.png]]
**处理器**的一个**物理控制流被分为了三个逻辑控制流**，每个进程分得一个逻辑流，这里使用竖线代表一个进程的逻辑流的一部分
可以看见，**三个逻辑流的执行是交错的**，A运行了一会，停下来后运行B直到B完成，然后运行一会C，又转到A运行到完成，最后把C运行完成
可以看到，**进程是轮流使用处理器的**。每个进程执行它的流的一部分，然后被**抢占（暂时挂起）**。轮到其他进程，所以**对于运行于进程上下文中的程序来说就像是在独占地使用处理器**

如果使用秒表精确测量每条指令使用的时间，就会发现程序中的一些指令执行前后CPU会周期性地停顿，随后继续执行程序

属于逻辑流的例子：异常处理程序、进程、信号处理程序、线程、Java进程等
### 8.2.2 并发流
**一个逻辑流的执行在时间上与另一个流重叠**，就称为**并发流**，这两个流在**并发地运行**，准确来说：
$$ 流X和Y互相并发 \iff X在Y开始之后和Y结束之前开始$$
例如上一节的例子中：
![[Pasted image 20241022143558.png]]
进程A和B就是并发地运行的，因为B在A开始后和结束前开始
**多个流并发地执行**的一般现象称为**并发**，**一个进程和其他进程轮流运行**的概念称为**多任务**，**进程执行它的控制流的一部分的每一时间段**称为**时间片**（例如进程A就由两个时间片组成）
因此，多任务也称为**时间分片**

处理器内部由多个**独立的计算单元**组成，它们称为**处理器的核**，每个核都可以被认为是一个独立的处理器。
**若两个流并发地运行在不同的处理器核或不同的计算机上**，称它们为**并行流**，它们**并行地运行（进程或任务的启动）** 且 **并行地执行（指令的并行处理）**
并发流和并行流是两个概念，但是我们可以认为**并行流是并发流的一个真子集**

### 8.2.3 私有地址空间
进程为程序提供的另一个假象是好像它独占地使用**系统地址空间**
在一台n位地址的机器上，**==地址空间==** 是$2^n$个可能地址的集合：$0,1,\cdots , 2^n-1$
进程为**每个程序**提供它自己的**私有地址空间：与这个空间中某个地址相关联的内存字节是不能被其他进程读或写的**，这就是所谓的“私有”

与私有地址空间相关联的内存内容往往不同，但其结构是一致的，下面是x86-64 Linux**进程的地址空间**的组织结构：
![[Pasted image 20241022151155.png]]
进程地址空间的底部（0到$2^{48}-1$的部分）是保留给**用户程序**的，包括代码、数据、堆与栈段。代码段总从地址`0x400000`开始
进程地址空间的顶部保留给**内核**，包含有**内核在代表进程执行指令时**（例如应用程序执行系统调用）使用的**代码、数据与栈**

### 8.2.4 用户模式和内核模式
进程的抽象由操作系统内核提供，为了能使该抽象无懈可击，**处理器**必须提供**限制一个程序可以执行的指令以及可以访问的地址空间范围**的机制
这个机制通常由某个**控制寄存器**中的一个**模式位**提供的，**该寄存器描述了进程当前享有的特权**
**设置了模式位时，进程就运行在==内核模式==中**（超级用户模式），这代表**运行在内核模式的进程可以执行指令集中的任何指令，访问系统中的任何内存位置**

若没有设置该模式位，进程就运行在==**用户模式**==中，它**不被允许执行任何==特权指令==**，比如停止处理器、改变模式位、发起一个I/O操作；也**不被允许直接引用地址空间中==内核区==内的代码和数据**，用户程序**必须通过系统调用接口来间接访问内核代码和数据**

运行应用程序代码的进程初始时在用户模式中，进程**从用户模式变为内核模式**的**唯一方法**是通过**异常**，如中断、故障、陷入系统调用。当异常发生时，**控制传递到异常处理程序，模式变为内核模式**
进程**从内核模式变为用户模式**只需要**返回到应用程序代码**即可

***计算机教育中缺失的一课第1讲1.1***
Linux提供了一个聪明的机制：**`/proc`文件系统**，通过它**允许用户模式下的进程访问内核数据结构的内容**
`/proc`文件系统把许多**内核数据结构**的内容输出为一个**用户程序可以读的文本文件**的**层次结构**，就像是在进行文件的访问和修改一样，例如
```
echo 1060 | sudo tee brightness
```
进行屏幕亮度的修改。
**通过使用`/proc`文件系统可以找出许多系统属性，如CPU类型：`/proc/cpuinfo`；还可以找到某个特殊进程使用的内存段：`/proc/<process-id>/maps`**
2.6以后版本的linux内核还引入了`/sys`文件系统，输出**关于系统总线和设备的额外底层信息**

### 8.2.5 上下文切换
**多任务的实现**是通过操作系统内核使用一种称为**上下文切换**的较高层形式的**异常控制流**进行的。**上下文切换机制建立在8.1节所述的较低层异常机制之上**
内核为每个进程维护一个**上下文**，它是**当内核重新启动一个被抢占（暂时挂起）的进程时所需的状态信息**，它由一些**对象的值**组成，对象包括**通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种==内核数据结构==，如描述地址空间的==页表==、包含有关当前进程信息的==进程表==，以及包含进程已打开文件的信息的==文件表**==

在一个进程执行时，内核可以**决定抢占当前进程，并重新开始一个先前被抢占的进程**，这就是**调度**，由内核中的**调度器代码**处理。当内核选择一个新进程运行时，就说**内核调度了这个进程**
内核调度一个进程后，它就抢占当前进程，**使用上下文切换机制来把控制转移到新的进程**：
- 1. **保存当前进程的上下文**
- 2. **恢复**某个先前被抢占的进程**被保存的上下文**
- 3. 把**控制传递**给新恢复的进程

上下文切换可能发生在**内核代表用户执行系统调用**时，此时若系统调用因**等待某个事件发生而阻塞**，内核就可以休眠当前进程，切换到另一个进程
一般来说，就算系统调用无阻塞，内核也可以决定执行上下文切换
**中断也可能引发上下文切换**，例如，**所有的系统都有某种产生周期性定时器中断的机制，用于判定当前进程已经运行了足够长时间，切换到下一个进程**，周期通常为1ms或10ms

## 8.3 系统调用错误处理（错误处理包装函数）
Unix系统级函数遇到错误时，通常会返回`-1`，并设置**全局整数变量`errno`** 来表示出错类型
对错误的检查往往会使代码变得臃肿，例如，unix中**使用`fork`函数在进程下创建子进程**
调用unix`fork`函数时会检查这样的错误
```
if ((pid = fork()) < 0) { //将fork的返回值赋给pid，以检查是否正常调用
	fprintf(stderr, "fork error:%s\n", strerror(errno));
}
```
`stderror`函数返回一个描述和某个`errno`值有关的错误的**字符串**

**错误报告函数**是用来方便错误报告的，我们定义下面这样一个函数：
```
void unix_error(char *msg) {
	fprintf(stderr, "%s: %s\n", msg, strerror(errno));
	exit(0);
}
```
然后在需要错误检查的时候只要调用它就行：
```
if((pid = fork()) < 0) 
	unix_error("fork error");
```

**错误处理包装函数**是更进一步简化代码的方式，例如下面是`fork`函数的错误处理包装函数：
```C
pid_t Fork(void) {
	pid_t pid;

	if ((pid = fork()) < 0) 
		unix_error("Fork error");
	return pid;
}
```
将对`fork`的调用也封装在里面，这样我们的调用就自带错误报告的功能了：
```
pid = Fork();
```
**错误处理包装函数能保持代码示例简洁，一般以系统级函数首字母大写的形式出现**，本书后面使用的都是错误处理包装函数

**本书的包装函数定义在一个叫做`csapp.c`的文件中，原型定义在`csapp.h`，可以在课程网站上找到它们**

## 8.4 进程控制
Unix提供大量从C程序中**操作进程的系统调用**，本节介绍并使用这些重要的函数

### 8.4.1 获取进程ID
**每个进程有一个==唯一的正数==进程ID：PID**，函数`getpid`返回进程的PID，而`getppid`函数返回**其父进程**的PID
函数原型：
```
#include <sys/types.h>
#include <unistd.h>

pid_t getpid(void);
pid_t getppid(void);
```
返回值类型`pid_t`是整数值，在linux系统上的`types.h`中返回值是`int`

### 8.4.2 创建和终止进程
从程序员的角度，我们可以认为**进程总是处于以下三种状态之一：**
- **运行**：进程要么在CPU上运行，要么在等待执行且最终会被内核调度
- **停止**：进程的执行被**挂起**且**不会被调度**，**进程收到`SIGSTOP`、`SIGTSTP`、`SIGTTIN`或`SIGTTOU`信号时停止，保持直到它收到`SIGCONT`信号**
- **终止**：进程永远停止了，主要有三种原因造成：1. 收到一个终止进程的信号； 2. 从主程序中返回； 3. 调用`exit`函数

```
#include <stdlib.h>
void exit(int status);
```
该函数以**退出状态** `status`来**终止进程**，相当于在main中`return status`;

**父进程调用`fork`函数创建新的运行的子进程：**
```
#include <sys/types.h>
#include <unistd.h>

pid_t fork(void);
```
新创建的子进程**几乎但不完全与父进程相同**
子进程与父进程的相同点：
- 两者的**用户级虚拟地址空间相同但互相独立，即副本关系**，包括代码数据段、堆、共享库与用户栈相同
- 子进程获得与父进程任何**打开文件描述符**相同的**副本**，即：**子进程可以读写父进程中打开的任何文件**
子进程与父进程的不同点：
- 它们的**PID不同**

**`fork`函数只被调用一次，却返回两次：**
```
int main() {
	pid_t pid;
	int x = 1;

	pid = fork();
	if (pid == 0) {  //子进程开始处
		printf("child : x=%d\n", ++x);
		exit(0);
	}

	printf("parent : x=%d\n", --x);
	exit(0);
}
```
如果运行这个程序，会得到：
```
./fork
parent : x=0
child : x=2
```
这个例子体现了子进程和父进程的关系与性质：
- **`fork`函数被调用一次，返回两次：先返回到父进程，然后==返回到新创建的子进程**==。具有多个子进程的程序在这点上会令人迷惑
- **并发执行：==父进程和子进程是独立并发运行的==**，内核以任意方式交替执行它们的逻辑控制流中的指令，因此，在这个系统中我们的父进程先`printf`了它的语句，然后才是子进程，**但在另一个系统中可能完全不一样**，因此，***绝对不能对不同进程中指令的交替执行作任何假设***

- **地址空间相同但独立**：在进程开始时立即暂停，我们可以看见两个进程有**相同的用户栈、本地变量值、堆、全局变量值以及代码**，所以例子中两个进程中x的初始值是一致的。但是，**两个进程是独立的，它们都有自己的==私有地址空间**==，子进程对父进程的地址空间进行**拷贝**，子进程拥有和父进程**完全相同**的本地变量、全局变量、堆栈等，这里的本地变量`int x = 1`就是一个例子，但后续的操作是**隔离的，子进程和父进程中对这些对象进行操作后不会互相影响**，所以父进程输出的`x=2`，而子进程是`x=0`

- **共享文件**：我们注意到这里子进程和父进程的输出同样地显示在屏幕上，这是因为**子进程继承了父进程打开的所有文件，包括`stdout`标准输出文件，它指向屏幕，因此子进程的输出也指向屏幕**

绘制进程图有利于我们理解程序语句的偏序：每个顶点a对应一条程序语句的执行，有向边$a\rightarrow b$表示语句a发生在b之前，在边上还可以进行一些标记
![[Pasted image 20241024203306.png]]
每个进程的顶点序列结束与一个`exit`的调用对应，它没有出边
图中顶点的**拓扑排序**对应程序中语句的一个**可行的全序排列**，即把进程图中的这些顶点写成一行，每条有向边方向都是从左到右，那么这个排序就是一个可行的程序执行顺序

### 8.4.3 回收子进程
一个进程终止时，**内核并不会立即把它从系统中清除**，而是使其**保持在已终止状态**中，直到它**被父进程==回收**==。父进程回收已终止的子进程时，内核将**子进程的退出状态传递给父进程**，随后抛弃已终止的进程，这个进程就不存在了
**终止了但未被回收的进程称为僵死进程**

若父进程终止了，内核会**安排`init`进程成为该父进程的孤儿进程的==养父==**，`init`进程的**PID为1**，在系统启动时**由内核创建**，**它不会终止，是所有进程的祖先**
所以，若父进程没有回收僵死子进程就终止了的话，内核安排`init`进程进行它们的回收
当然，**对于长时间运行的程序，总应该及时回收它们的僵死子进程，因为它们会消耗系统的内存资源**

一个进程可以通过调用`waitpid`函数来**等待它的子进程终止或停止**
```
#include <sys/types.h>
#include <sys/wait.h>

pid_t waitpid(pid_t pid, int *statusp, int options);
```
默认情况`options = 0`时，`waitpid`**挂起调用进程的执行**，直到它的**等待集合**里的一个子进程终止，然后返回**已终止的这个子进程的PID**，此时该子进程已经被回收

`waitpid`函数有些复杂，下面介绍它的主要运行机制：
1. 判定**等待集合中的成员**
**等待集合中的成员由`pid_t pid`参数来确定**：
- 如果`pid > 0`，等待集合就是**一个单独的子进程，其PID就是`pid`**
- 如果`pid = -1`，等待集合由**父进程的所有子进程**组成
当然，它还支持其他类型的等待集合，例如`Unix进程组`。这部分请自行搜索相关文档

2. 修改默认行为
`int options`参数用于**修改默认行为**，它主要可以被设置为**常量`WNOHANG`、`WUNTRACED`和`WCONTINUED`**
- `WNOHANG`：等待集合中的任何进程**都没有终止时，立刻返回值0**
  这个选项是出于**在默认情况等待任何一个子进程终止时，该调用进程保持挂起**，而如果我们希望在等待的过程中调用进程还能做些别的工作，就会使用这个选项，在不需要挂起的时候退出

- `WUNTRACED`：**挂起调用进程的执行**，直到等待集合中的一个进程变为**已终止或被停止**
  这个选项是因为**默认情况下只返回已终止子进程**，当我们需要检查被停止的子进程时，就会使用它

- `WCONTINUED`：**挂起调用进程的执行**，直到等待集合中的一个正在运行的程序终止，或者一个**被停止的程序收到`SIGCONT`信号重新开始执行**
  这个选项用于**检测被重启的子进程**

当然，**选项可以被或运算组合起来：**
- `WNOHANG | WUNTRACED`：**立即返回，若等待集合中的子进程都没被停止或终止，返回0；反之则返回该子进程的PID**

3. 检查已回收子进程的**退出状态**
函数的`int *statusp`参数用于**储存关于导致返回的子进程的状态信息，它指向的值称为`status`**，一般是个`int`，传入参数时使用`&status`引用传参
值`status`有以下几个宏：
以分组的形式展示有关联的几个状态
- `WIFEXITED`：若子进程**通过调用`exit`或`return`进行正常终止，返回真**
- `WEXITSTATUS`：返回一个**正常终止的子进程的退出状态**，只会在`WIFEXITED`返回真时被定义

- `WIFSIGNALED`：若子进程**因为一个未被捕获的信号终止，那么返回真**
- `WTERMSIG`：返回**导致子进程终止的信号编号**，只在`WIFSIGNALED`为真时被定义

- `WIFSTOPPED`：若**引起返回的子进程现在还是停止状态，返回真**
- `WSTOPSIG`：返回**引起子进程停止的信号编号**，只在`WIFSTOPPED`为真时被定义

- `WIFCONTINUED`：若**子进程收到`SIGCONT`信号重新启动，返回真**

上述常量均间接定义在头文件`wait.h`中，如果不知道应该包含哪个头文件，可以检查该函数的`man`页面

4. 错误条件
`waitpid`函数的返回值在一定情况下会标志错误情况：
- 调用进程没有子进程，返回`-1`，设置`errno = ECHILD`
- `waitpid`函数被一个信号中断，返回`-1`，设置`errno = EINTR`

5. 简化版本：`wait`函数
```
#include <sys/types.h>
#include <sys/wait.h>

pid_t wait(int *statusp);
//等价于waitpid(-1, &status, 0);
```
只接受一个参数，其含义与前面所说的一致

要注意，***程序不会按照任何特定的顺序回收子进程*，这个行为随机器改变而改变，是非确定性的。因此不能假设一定会出现某种结果**
下面是`waitpid`函数的一个使用例子：
![[Pasted image 20241028195115.png]]
第一个循环（12行以前）父进程创建N个子进程，并且各自以不同的状态返回
第二个循环（15行以后）父进程以参数`-1`调用`waitpid`，因为**该函数的该调用情况在有任意一个子进程终止前保持挂起，所以在没有终止的子进程出现时会保持阻塞**，直到任意子进程终止

后面的判断则说明，当子进程正常终止时，将**僵死子进程**回收，输出退出状态；反之输出错误信息

所以，在系统上运行该程序，由于子进程回收顺序不定，可能出现
```
child 22966 terminated normally with exit status=100
child 22967 terminated normally with exit status=101
```
或
```
child 22967 terminated normally with exit status=101
child 22966 terminated normally with exit status=100
```
两种情况，它是非确定性的

可以进行一些简单的改进，来使得子进程按顺序回收：**父进程顺序存储记录其子进程的PID，将其作为`waitpid`的第一个参数来调用，按这样的顺序等待僵死子进程被回收：**
![[Pasted image 20241028200103.png]]

### 8.4.4 让进程休眠
`sleep`函数将一个进程**挂起**一段指定时间
```
#include <unistd.h>

unsigned int sleep(unsigned int secs);
```
若请求的时间量已到，该函数返回`0`，否则返回剩余的秒数
后一种情况主要是处理`sleep`函数**被一个信号中断**而导致过早地返回

另一个有用的函数是`pause`，它**令调用它的函数休眠，直到该进程收到一个信号**
```
#include <unistd.h>

int pause(void);
```

### 8.4.5 加载并运行程序
`execve`函数**在当前进程的上下文中加载并运行一个新程序**
```
#include <unistd.h>

int execve(const char *filename, const char *argv[], const char *envp[]);
```
它加载并运行**可执行目标文件`filename`，附带参数列表`argv`和环境变量列表`envp`**
若成功加载并运行，该函数**调用一次且从不返回**；若出现错误，才会以`-1`返回到调用程序
该函数**将当前进程的代码替换为另一个程序的代码**，所以原进程代码不再执行，该函数“从不返回”

参数列表的组织结构如下：
![[Pasted image 20241029141415.png]]
是一个**以NULL结尾的指针数组，每个指针都指向一个参数字符串**。按照惯例，`argv[0]`是**可执行目标文件的名字**

环境列表的组织结构如下：
![[Pasted image 20241029141616.png]]
是一个**以NULL结尾的指针数组，每个指针指向一个环境变量字符串，格式形如`NAME=value`**

当`execve`加载了`filename`以后，调用功能如7.9节所述一样的**启动代码**，启动代码设置栈，**把控制传递给新程序的主函数：**
```
int main(int argc, char **argv, char **envp);
```
等价于
```
int main(int argc, char *argv[], char *envp[];)
```

当主函数开始执行时，**用户栈**以下图所示的结构组织：
![[Pasted image 20241029143012.png]]
从栈底到栈顶**地址递减**，栈底首先是**环境变量字符串与命令行参数**，连续地分布在栈中，**全局变量`environ`指向环境变量中的第一个`envp[0]`**
栈顶还有**系统启动函数`libc_start_main`的栈帧**，更后面的位置则是留给主函数之后使用的栈帧

和我们知道的一样，`main`函数有三个参数：代表`argv[]`中非空指针数目的`argc`；`argv[]`的首元素指针`argv`；`envp[]`的首元素指针`envp`
Linux提供了一些函数来**操作环境变量数组：**
```
#include <stdlib.h>

char *getenv(const char *name);
```
函数`getenv`接受一个字符串，代表**环境变量的名字**。**在环境变量数组中寻找形如`name=value`的字符串**；如果找到了，返回一个指向`value`的指针（字符串`value`），否则返回`NULL`

下面的函数用于**删除名为`name`的环境变量：**
```
#include <stdlib.h>

void unsetenv(const char *name);
```

下面的函数用于**替换（在参数`overwrite`不为0时）或新建（没找到`name`环境变量时）环境变量：**
```
#include <stdlib.h>

int setenv(const char *name, const char *newvalue, int overwrite);
```
**在`overwrite`非零时替换名为`name`的环境变量为`name=newvalue`，否则忽略；如果环境不存在，则新建一个这样的环境变量，对任何`overwrite`参数成立**

### 8.4.6 利用`fork`和`execve`运行程序
Unix shell和Web服务器这样的**程序**会大量用到`fork`和`execve`函数，shell**执行一系列读或求值步骤，然后终止**。读步骤来自用户的一个命令行，求值步骤解析命令行并代表用户运行程序

下面是一个简单shell的`main`例程：
```c
#define MAXARGS 128

int main() {
	char cmdline[MAXLINE];   //代表命令行长度

	while (1) {
		printf("< ");  //输出命令行提示符
		Fgets(cmdline, MAXLINE, stdin);  //从stdin获取用户输入
		if (feof(stdin))   //检查输入流是否到达结尾
			exit(0);

		eval(cmdline);  //解析并运行命令的封装
	}
}
```
解析命令行是通过调用下面的`parseline`函数实现的：
![[Pasted image 20241029154407.png]]
它解析以空格符分隔的命令行参数，并且构造向量`argv`，第一个参数被假设为要么是一个内置的shell命令名，要么是一个可执行目标文件名

根据解析结果执行命令或使用`execve`函数创建子进程执行程序，就是一个简单的shell了
但是这样的shell**不会回收其后台子进程，这需要使用下面讲到的信号机制**

## 8.5 信号
Linux信号是**更高层的==软件形式的异常**==，它允许进程和内核中断其他进程
**一个信号就是一个小信息，通知进程：系统中发生了一个某种类型的事件：**
![[Pasted image 20241030192856.png]]
一种信号类型对应一种系统事件，底层硬件异常由内核异常处理程序处理，对用户进程不可见，但会**通过信号机制告知用户进程发生了这些异常**
信号的产生事件在图中已经标出，下面逐步介绍其作用机制

### 8.5.1 信号机制
传送一个信号到目的进程由**两个不同步骤**组成：
- **发送信号**：内核通过**更新目的进程上下文中的某个状态**，实现发送信号给目的进程的效果。**一个进程可以发送信号给它自己**
- **接收信号**：目的进程**被内核强迫**以某种方式对信号的发送作出反应。反应可以是**忽略、终止或执行一个信号处理程序来==捕获==该信号**，信号处理程序是**用户层函数**
![[Pasted image 20241030194716.png]]
发出但没有被接收的信号是**待处理信号**，任意时刻，**一种信号类型只会有至多一个待处理信号**，也就是说，**一旦该类型出现一个待处理信号，后面发送到该进程的同类型信号都会被丢弃**
进程也可以选择**阻塞接收某种信号**，即**对于这个进程来说，该信号被发送后产生的待处理信号不会被接收，直到进程取消这种阻塞**

待处理信号最多被接收一次，内核为进程维护一个**位向量`pending`以确定待处理信号的集合**，而**位向量`blocked`维护被阻塞的信号集合**
就像位向量经常用来的那样，传送了一个类型为k的信号，内核设置`pending`中第k位为1；接收某类型为k的信号，清除`pending`中第k位为0

### 8.5.2 发送信号
Unix**所有向进程发送信号的机制都基于==进程组==这个概念**
#### 1. 进程组
**每个进程都只属于1个进程组，进程组由一个正整数进程组ID进行标识**
函数`getpgrp`返回当前进程的进程组ID：
```
#include <unistd.h>

pid_t getpgrp(void);
```

**默认情况下，子进程和父进程同属一个进程组**。但进程可以**通过`setpgid`函数改变自己或其他进程的进程组：**
```
#include <unistd.h>

int setpgid(pid_t pid, pid_t pgid);
```
将PID为`pid`的进程的进程组改为`pgid`；若`pid==0`，使用当前进程的PID；若`pgid==0`，使用`pid`作为进程组ID
也就是说，`setpgid(0, 0)`会创建一个`pgid`为当前进程`pid`的新进程组，并把当前进程加入该进程组

#### 2. 使用`/bin/kill`程序发送信号
`/bin/kill`程序可以**向另外的进程发送任意信号：**
```
/bin/kill -9 15213
```
发送信号9：`SIGKILL`给PID为`15213`的进程。**第二个参数为负代表该参数为进程组的`pgid`的相反数，对该进程组所有进程发送第一个参数指定的信号**
注意这里**使用完整的`kill`程序路径索引，因为可能shell有自己内置的`kill`命令**

#### 3. 从键盘发送信号
unix shell将**对一条命令行求值而创建的进程**抽象为**作业`jobs`**（计算机学习中缺失的一课 \#5命令行环境），在任何时刻，**至多只能有一个前台作业，可以有0或多个后台作业***
例如，`ls | sort`就是一个由两个进程组成的前台作业，**shell为每个作业创建一个独立的进程组，其ID通常取作业中父进程中的一个**，例如：
![[Pasted image 20241102104335.png]]
在键盘上键入某些快捷键，例如`ctrl+c`，会**使内核发送一个信号到==前台进程组中的每个进程**==
（`ctrl+c`为`SIGNIT`信号，默认终止；`ctrl+z`为`SIGTSTP`信号，默认挂起）

#### 4. 用kill函数发送信号
进程通过调用`kill`函数**发送信号给其他进程（包括自己）**
```
#include <sys/types.h>
#include <signal.h>

int kill(pid_t pid, int sig);
```
若`pid > 0`，`kill`函数将会发送参数所传递的编号的信号`sig`给`PID=pid`的进程，它可以是调用它的进程自己；若`pid < 0`，那么它会发送信号`sig`给进程组`|pid|`中的每个进程。
```C
int main() {
	pid_t pid;
	if ((pid == Fork()) == 0) {
		Pause();  //暂停，直到接收到一个信号
		exit(0);
	}
	Kill(pid, SIGKILL);
	exit(0);
}
```
这里父进程向子进程传递了一个`SIGKILL`信号，由于子进程一开始就被暂停，然后父进程杀死它，所以本质上没有任何作用，`exit`都未被执行

#### 5. 用alarm函数发送信号
进程**可以使用`alarm`函数向它自己发送`SIGALRM`信号**：
```
#include <unistd.h>
unsigned int alarm(unsigned int secs);
```
参数`secs`控制“内核在`secs`秒后将向进程发送`SIGALRM`信号”，和闹钟一样，通常**用于提醒进程执行某些操作**，比如超时处理
若`secs = 0`，代表不会调度安排任何新的闹钟，但是仍然会触发`alarm`的固有性质：**任何情况下，对`alarm`的调用都会取消所有待处理的闹钟，并且返回它们离触发前还剩下的秒数，若没有待处理闹钟就返回0**
所以`secs = 0`也相当于取消当前所有待处理闹钟

### 8.5.3 接收信号
当内核把进程$p$**从内核模式切换到用户模式**时（比如从系统调用返回或完成一次上下文切换），它会检查进程$p$的**未被阻塞的待处理信号的集合**（允许接收的信号类型），
- 通常这个集合会是空的，此时内核会**将控制传递到$p$的逻辑控制流中的下一条指令$I_{next}$中**；
- 若集合非空，内核会选择这个集合中的某个信号$k$（通常是编号最小的），强制进程$p$接收信号$k$，触发进程采取某种行为，**完成该行为后再将控制传递到$p$的逻辑控制流中的下一条指令$I_{next}$中**
  进程采取的行为由**信号预定义的默认行为**决定，可以是：
  - 进程终止
  - 进程终止并转储内存
  - 进程停止（挂起）直到被SIGCONT信号重启
  - 进程忽略该信号
\## 8.5节最开始的图8-26列出了信号与其默认行为

进程可以通过`signal`函数**修改与信号相关联的默认行为**：
```
#include <signal.h>
typedef void (*sighandler_t)(int); //使用sighandler_t表示一个接收int返回void的函数指针

sighandler_t signal(int signum, sighandler_t handler);
```
该函数接收一个信号类型编号`signum`和一个信号处理函数指针`handler`，**返回上一个信号处理函数的地址**（上一个信号处理函数指针）
没有`typedef`的话就应该声明为`void (*signal(int signum, void (*handler)(int)))(int);`过于复杂

`handler`相当于是输入信号编号`signum`所进行的处理函数（函数指针的传递），该参数可以是下面三种情况之一：
- 若`handler == SIG_IGN`，代表**忽略类型为`signum`的信号**
- 若`handler == SIG_DFL`，代表**将类型为`signum`的信号的行为恢复至默认行为**
- 若`handler`是一个**用户自定义的函数指针**，那么这个函数称为**信号处理程序：只要进程接收到类型为`signum`的信号，就会调用该程序对其进行处理**。这样的过程叫做设置信号处理程序，调用信号处理程序称为**捕获信号**，执行信号处理程序叫做**处理信号**

**一个处理函数可以处理多种信号，当它`return`时，控制通常被传递回控制流中进程被信号接收`signal`中断位置处的指令**（某些系统中被中断的系统调用回

例如，下面的代码捕获用户在键盘上输入`ctrl+c`时发送的SIGINT信号，并修改其默认的立即终止该进程的行为：
```C
void sigint_handler(int sig) {  //信号处理程序
	printf("caught signal!");
	exit(0);  //在处理完成后终止进程
}

int main() {
	if (signal(SIGINT, sigint_handler) == SIGERR) //设置信号处理程序
		unix_error("signal error");  //设置失败的话执行错误处理函数

	pause();   //暂停进程直到捕获到对应信号，调用处理函数进行exit
	return 0;
}
```

当然，信号处理程序也可以捕获信号，传递给另外一个信号处理程序：
![[Pasted image 20241120170052.png]]
s和t两个信号需要是不同的

### 8.5.4 阻塞和解除阻塞信号
Linux提供了显式与隐式进行阻塞信号的机制：
- **隐式阻塞机制：内核默认阻塞任何当前处理程序正在处理的信号同类型的待处理信号**，例如，对于一个捕获了信号s的程序，在它返回之前向它发送的任何同类型信号都不会被接收，而是**保持待处理状态**
- **显式阻塞机制：程序可以使用`sigprocmask`函数及其辅助函数，明确地阻塞或解除阻塞所选定的信号**

显式阻塞机制所使用的函数及辅助函数原型如下：
```
#include <signal.h>

int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);
int sigemptyset(sigset_t *set);
int sigfillset(sigset_t *set);
int sigaddset(sigset_t *set, int signum);
int sigdelset(sigset_t *set, int signum);

int sigismember(const sigset_t *set, int signum);
```
其中，`sigset_t`就是我们在8.5.1节中所描述的作为存储信号的集合的**位向量blocked的类型**

`sigprocmask`函数**改变当前阻塞的信号集合`oldset`的状态**，具体的行为依赖于参数`how`的值：
- `SIG_BLOCK`：将`set`中的信号添加至`blocked`中 （使用`blocked = blocked | set`）
- `SIG_UNBLOCK`：从位向量`blocked`中删除`set`中的信号 （使用`blocked = blocked & ~set`）
- `SIG_SETMASK`：令`blocked = set`
  若`oldset`非空，那么位向量`blocked`将变化之前的值保存在`oldset`中

其他辅助函数的介绍如下：
- `sigemptyset`：将`set`初始化为**空集合**
- `sigfillset`：将**所有信号**都添加至`set`中
- `sigaddset`：将参数`signum`指代的信号添加至`set`中
- `sigdelset`：将参数`signum`指代的信号从`set`中删除。若集合中不存在该信号，返回`0`

例如，下面的例子使用`sigprocmask`来临时阻塞接收`SIGINT`信号（和前面8.3节所述的一样，函数首字母大写代表**错误处理包装函数**）：
```c
sigset_t mask, prev_mask;

Sigemptyset(&mask);
Sigaddset(&mask, SIGINT);

Sigprocmask(SIG_BLOCK, &mask, &prev_mask);  //阻塞SIGINT信号，存储原来的集合状态至prev_mask

/* ... 需要屏蔽SIGINT的代码部分 ... */

Sigprocmask(SIG_SETMASK, &prev_mask, NULL);  //将现在的集合状态设置回原来的集合状态，从而结束对SIGINT的阻塞
```

### 8.5.5 编写信号处理程序
在Linux系统编程中，信号处理程序的几个属性使它们很难被推理分析：
- **处理程序与主程序是并发运行的，共享同样的全局变量，因此处理程序可能会与主程序或其他处理程序互相干扰**
- 什么时候接收信号？怎么接收信号？往往和我们的直觉有违
- 不同的系统有不同的信号处理语义

本节重点讲述这些问题，并且介绍如何编写安全、正确和可移植的信号处理程序的基本规则
以及注意一个概念：**信号处理程序与主程序共享同一个进程的资源**，它们同属于一个进程，但**信号处理程序是主程序的特殊执行路径**，它不是独立的线程，但与线程的执行方式有一定相似性

（**线程是一个进程中拥有自己的独立栈（stack），但共享进程的地址空间的单一顺序控制流，一个进程可以并发多个线程**）
#### 1. 安全的信号处理
信号处理程序的复杂性主要在于**处理程序和主程序以及其他信号处理程序是并发运行的**：
![[Pasted image 20241120170052.png]]
这些并发运行的程序可以并发地访问同样的全局数据结构，这会导致出现不可知且致命的结果

详细的并发编程教程会在第12章讲到，这里我们主要介绍一些**保守的编写处理程序的原则**，以确保处理程序们能够安全地并发运行，不然等到出错时，调试的困难度会使你悔不当初

规则如下：
- G0. **处理程序要尽可能简单**。 
  我们要保持处理程序尽可能小且简单，例如只是简单地设置全局标志。**主程序负责所有与接收信号相关的处理，也就是检查处理程序设置的全局标志，进行对应的行为，然后重置标志**，这样的分工能使结构清晰，避免不必要的麻烦
  
- G1. **在处理程序中只调用==异步信号安全的函数**==。 
  异步信号安全的函数能够被信号处理程序安全地调用，主要包括：
  - **这样的函数是==可重入==的：它们只访问局部变量**
  - **这样的函数不能被信号处理程序中断**
Linux所保证的**安全的系统级函数**的列表如下：
![[Pasted image 20241121152459.png]]
注意一些常见的`exit`、`printf`、`malloc`、`sprintf`等函数都不在此列，说明它们是不安全的

**信号处理程序中唯一安全的输出方式是使用`write`函数，而不是调用`printf`或`sprintf`**
我们可以自己实现安全的I/O函数，来在信号处理程序中打印简单的消息：
```
ssize_t sio_putl(long v);
ssize_t sio_puts(char s[]);
                             //若成功输出，则返回传送的字节数；反之返回-1
void sio_error(char s[]);   //错误信息输出
```
前两个输出函数向标准输出传送一个`long`类型数字和字符串，后面的函数则用于打印错误信息并终止
下面是这些函数的实现：
```c
ssize_t sio_puts(char s[]) {
	return write(STDOUT_FILENO, s, sio_strlen(s));  //sio_strlen也是自定义的返回字符串长度的函数
}

ssize_t sio_putl(long v) {
	char s[128];
	sio_ltoa(v, s, 10);   //第三个参数指明数字v采用的进制，将其转换为字符串。其实现就是把数字按位读取存储，最后加上'/0'即可
	return sio_puts(s);
}

void sio_error(char s[]) {
	sio_puts(s);
	_exit(1);  //异步信号安全形式的exit函数
}
```

- G2. **要记得保存和恢复`errno`**
  这个全局变量指示上一次错误的类型，许多异步信号安全的函数会在出错返回时设置它。所以为了保证处理程序中对这些函数的调用不会干扰主程序中其他依赖于`errno`的部分，应该**在进入处理程序时将`errno`的现有值保存在一个局部变量中，在处理程序返回前恢复它**（当然，若处理程序用`_exit`结束了这个进程，就没有必要了）

- G3. **在访问全局数据结构时要阻塞所有的信号以保护对共享全局数据结构的访问**
  如果处理程序和主程序或其他处理程序共享同一个全局数据结构，那么**在访问这个数据结构的时候，处理程序与主程序应该暂时阻塞所有信号**
  这是因为从主程序访问一个数据结构d通常需要一系列指令来进行，若这样的指令序列被访问d的处理程序中断，**会出现状态不一致或未完成的修改**，所以导致信号处理程序出现不可知的结果。**在访问全局数据结构时阻塞其他所有信号，防止这个过程的指令序列被其他处理程序中断，产生错误的结果**

- G4. **要使用`volatile`声明全局变量**
  该限定符**强迫编译器每次在代码中引用该变量时，都要从内存中读取它的值**
  如果`main`函数周期性地读一个全局变量g，而处理程序会对g进行更新，那么对于优化编译器而言，`main`中g的值看起来是一直不变的，因此会顺理成章地**每次取出缓存在寄存器中的g的副本来满足对g的引用**。但**处理程序对g进行的更新是在内存中的，并不会同步更新寄存器中的副本**，这就**导致更新后的g值并不会被`main`函数使用**
  因此，通过类似于`volatile int g`这样的声明，**确保每次更新后的值都能被正确取出**
  当然，不要忘记在访问全局数据结构时暂时阻塞所有信号

- G5. **要使用`sig_atomic_t`来声明记录是否收到信号的标志**
  `sig_atomic_t`是一种**整型数据类型，对该类型的读和写保证会是原子的（不可中断的）**
  在处理程序中往往要对**记录是否收到了信号的全局标志变量**进行写，而主程序会读这个标志，进行相应的处理，然后清除它。因此对于这样的全局变量也要确保读写的安全
  使用`sig_atomic_t`类型声明标志，**能够让读和写变量的指令所需数变为1条，从而确保不可能中断指令序列**（根本没有序列），所以我们**无需对其他信号进行阻塞**就能安全地读写它了

  注意：**原子性的保证只适用于单个的读和写，像`flag++`或`flag += 10`这样的更新仍然需要多条指令，此时还是需要阻塞信号**

这六条规则是很保守的，在你确定绝对安全的情况下可以不必须，但是这个“绝对安全”很难判断。

#### 2. 正确的信号处理：不可用信号为事件计数
信号的一个反直觉的性质是**未处理的信号是不排队的**。位向量`pending`只为每种类型的信号对应了一位，因此**每种类型最多只能有一个未处理的信号**。
当有两个同类型k的信号发送给一个目的进程，且该目的进程正在执行信号k的处理程序，那么信号k就被阻塞了。**两个发送到进程的信号只有一个会变成待处理信号，另外一个则被简单丢弃**，不会排队。只要存在一个未处理信号，就说明至少有一个信号到达

为什么这样的性质会影响正确性?来看下面的例子：
下面的程序的基本结构是：父进程创建一些子进程，它们各自独立运行一段时间后终止，此时父进程必须回收子进程以避免在系统中留下僵死进程
同时，我们希望父进程在子进程运行的时间里能自由地做其他工作，所以我们**不显式地等待子进程终止，而是使用信号`SIGCHLD`的处理程序来回收子进程**。（只要有一个子进程终止或停止，内核就会发送一个SIGCHLD信号给父进程）
下面是一个有问题的程序的例子：
```c
-------------------signal1.c

void handler1(int sig) {   //处理程序：捕获SIGCHLD时被调用
	int olderrno = errno;
	if ((waitpid(-1, NULL, 0)) < 0)
		sio_error("waitpid error");
	Sio_puts("Handler reaped child\n");
	sleep(1);    //这个sleep代表对已结束子进程的回收处理
	errno = olderrno;
}

int main() {
	int i, n;
	char buf[MAXBUF];

	if (signal(SIGCHLD, handler1) == SIG_ERR)  //注册handler1为SIGCHLD的处理程序
		unix_error("signal error");

	for (i = 0; i < 3; i++) {
		if (Fork() == 0) {   //创建三个子进程
			printf("Hello from child %d\n", (int)getpid());
			exit(0);
		}
	}

	if ((n = read(STDIN_FILENO, buf, sizeof(buf))) < 0) 
		unix_error("read");   //STDIN_FILENO是标准输入的文件描述符，代表从键盘或终端中的数据输入，这里将其读到缓冲区buf中

	printf("Parent processing input\n");
	while (1)
	;   //无限循环，只是用于代表父进程同时进行的工作
	exit(0);
}
```
该程序创建了三个子进程，每个进程打印一条信息后终止。同时父进程**并没有调用`waitpid`函数来显式地等待子进程结束**，而是继续进行自己的工作
当任一子进程结束，内核发送一个`SIGCHLD`信号通知父进程，父进程捕获该信号同时调用处理程序进行处理（`sleep`）

但是，该程序**认为信号是排队的**，也就是说它认为可以依次捕获信号，调用处理程序，处理完成后捕获下一个信号进行处理。然而实际上，若在命令行中调用该程序，会出现：
```
linux> ./signal1
Hello from child 10473
Hello from child 10474
Hello from child 10475
Handler reaped child
Handler reaped child    #只回收了两个子进程
CR
Parent processing input
```
只有两个信号被捕获了，因此父进程只回收了两个子进程，剩下那个成为僵死进程
使用`ps`命令查看所有进程会看见`14075 pts/3 T 0:02 [signal1] <defunct>`，也就是说进程`14075`成为了一个僵死进程`<defunct>`

整个代码中发生的情况是：**父进程接收并捕获了第一个信号，当还在处理这个信号时，第二个信号又被传送并添加到待处理信号集合中而不被接收，随后第三个信号到达时，因为已经有了一个待处理信号，所以这个信号被简单地丢弃了**

所以，==**不可以用信号来对其他进程中发生的事件计数**==（例如，不可以像这样用信号SIGCHLD作为**一个子进程结束**的标志，而是视为“**至少**有一个子进程结束了”的标志）

***修正***
存在一个待处理的信号，暗示的是**至少**有一个该类型的信号被发出。在本例中，我们得到`SIGCHLD`信号后，因为只能得到一个至少的信息，其**处理程序应该直接等待所有子进程的结束并且进行回收**，这使用到`waitpid`
因此，改动如下：
```c
void handler2(int sig) {
	int olderrno = errno;

	while (waitpid(-1, NULL, 0) > 0) {  //在处理程序中等待子进程结束，然后回收
		Sio_puts("Handler reaped child\n");
	}
	if (errno != ECHILD)   //该错误标志检测最近调用的waitpid的情况
		Sio_error("waitpid error");
	Sleep(1);  //代表回收操作
	errno = olderrno;  //退出处理程序时恢复进入程序时的错误标志
}
```

这样就确保了所有僵死子进程的回收

#### 3. 可移植的信号处理：Signal包装函数
Unix信号处理的另一个缺陷在于**不同的系统有不同的信号处理语义**，例如
- **`signal`函数是一次性的**：在老版本的Unix中，信号处理程序注册函数`signal`是一次性的：在处理程序捕获并处理完信号后，系统会将信号处理器的行为**恢复为默认状态**，此后如果还收到该信号，行为又会变回默认行为，所以在处理程序的最后**还要调用一次`signal`来自己把自己再次注册回该信号的处理程序**

- **系统调用可以被中断**：像`read`、`write`和`accept`这样的**慢速系统调用会潜在地阻塞进程一段较长的时间**，一些早期Unix系统中，若处理程序捕获到一个信号，慢速系统调用被中断后，**在处理程序返回后这些系统调用不再继续**，而是返回错误条件，将`errno = EINTR`，程序员必须手动重启它们的代码

为了解决这些版本不同的系统产生的差异问题，Posix标准定义了下面的`sigaction`函数：
```
#include <signal.h>

int sigaction(int signum, struct sigaction *act, struct sigaction *oldact);
//成功返回0,否则返回-1
```
该函数**允许用户在设置信号处理时，明确地指定他们想要的信号处理语义**
函数的第一个参数指明信号类型，第二个参数是现定义的信号处理语义结构体，第三个参数可以传入一个空的处理语义结构体，调用时会自动将原语义传递给它，用于保存旧语义，便于恢复
它要求用户设置一个条目结构体`sigaction`，它的格式类似于：
```
struct sigaction {
    void (*sa_handler)(int);       // 信号处理函数指针
    void (*sa_sigaction)(int, siginfo_t *, void *); // 扩展信号处理函数
    sigset_t sa_mask;              // 处理信号时需要屏蔽的其他信号集合
    int sa_flags;                  // 行为标志
    void (*sa_restorer)(void);     // 不推荐使用（已废弃）
};

```

**关键字段说明**：
1. **`sa_handler`**：
    - 定义信号处理函数的入口地址。
    - 特殊值：
        - `SIG_DFL`：使用信号的默认行为。
        - `SIG_IGN`：忽略信号。
2. **`sa_sigaction`**：
    - 当 `sa_flags` 设置为 `SA_SIGINFO` 时，用于扩展信号处理程序，提供更多信号信息。（可选的）
3. **`sa_mask`**：
    - 是在处理当前信号时需要屏蔽的信号集合。
    - 防止信号嵌套处理。
4. **`sa_flags`**：
    - 控制信号处理行为的标志。
    - 常见值：
        - `SA_NOCLDSTOP`：忽略 `SIGCHLD` 信号中由子进程停止引发的通知。
        - `SA_RESTART`：系统调用被信号中断后自动重新启动。
        - `SA_SIGINFO`：使用 `sa_sigaction` 而非 `sa_handler`。



直接使用`sigaction`函数需要客户端提供这样一个条目，调用起来并不方便，因此需要加一层包装使其变得简洁
定义一个包装函数`Signal`，它的参数和`siganl`函数一样（调用模式相同），在该函数内部调用`sigaction`函数，为其设置如下语义：
- 设置该信号的处理程序
- 只**阻塞**这个处理程序当前正在处理的这种类型的信号
- 和往常一样，信号**不会排队等待**
- 只要可能，被中断的系统调用会**自动重启**
- 一旦注册了信号处理程序，它就会被**一直保持**，直到Signal被使用`handler`参数为`SIG_IGN`或`SIG_DFL`的形式调用

下面是它的定义：
```c
handler_t *Signal(int signum, handler_t *handler) {
	struct sigaction action, old_action;  //old_action存储执行处理程序之前的信号状态
	action.sa_handler = handler;  //信号处理函数的入口地址
	sigemptyset(&action.sa_mask);  //设置屏蔽信号集合sa_mask为只有当前处理的信号类型
	action.sa_flags = SA_RESTART;  //自动重启标志

	if (sigaction(signum, &action, &old_action) < 0)  //调用sigaction，这时会把旧状态存在old_action中
		unix_error("Siganl error");
	return (oldaction.sa_handler);  
    //返回旧状态，便于状态的恢复
}
```


可以看到，`sigaction`只需要声明后对需要的条目进行赋值和修改就行。传入空结构体用于储存旧的语义

### 8.5.6 同步流以避免讨厌的并发错误
并发编程中，若多个线程或并行任务需要读写相同的存储位置，并发流的运行顺序可能是交替进行的，比如一个线程先执行几条指令，另一个线程随后插入执行几条指令。这种不同线程指令的执行顺序被称为“**交错**”。
这些交错的一部分可能会产生正确的结果，一些则不会，为了避免错误的交错，获得最大的可行的交错集合，我们需要以某种方式**同步并发流**

下面的程序总结了一个典型的Unix Shell的结构，但是它是有问题的：
```c
void handler(int sig) {
	int olderrno = errno;
	sigset_t mask_all, prev_all;
	pid_t pid;

	Sigfillset(&mask_all);
	while ((pid = waitpid(-1, NULL, 0)) > 0)  { 
	    /* 回收僵死子进程的代码 */
		Sigprocmask(SIG_BLOCK, &mask_all, &prev_all);
		deletejob(pid);   //将子进程从任务列表中删除，由父进程（中的处理程序）调用
		Sigpromask(SIG_SETMASK, &prev_all, NULL);
	}

	if (errno != ECHILD)
		Sio_erro("waitpid error");
	errno = olderrno;
}

int main(int argc, char **argv) {
	int pid;
	sigset_t mask_all, prev_all;

	Sigfillset(&mask_all);
	Signal(SIGCHLD, handler);  //注册处理程序
	initjobs();

	while(1) {
		if ((pid = Fork()) == 0) {
		/*子进程*/
			Execve("/bin/date", argv, NULL);  
		}
		Sigprocmask(SIG_BLOCK, &mask_all, &prev_all);  //这里阻塞了所有信号，因为addjob涉及到对共享资源的修改，不能被信号终止
		addjob(pid);  //把pid加进工作列表了
		Sigprocmask(SIG_SETMASK, &prev_all, NULL);  //解锁：恢复至prev_all状态
	}
	exit(0);
}
```

这段代码可能出现下面这样的事件序列：
- 父进程执行`fork`函数，内核调度新创建的子进程运行，此时父子进程的指令交替运行
- 内核调度**新创建的子进程先运行**，**在父进程再次进行之前子进程终止**并且变为僵死进程
- 重新**运行父进程之前**，内核注意到由于子进程终止而产生的`SIGCHLD`信号，将其传递给父进程，**执行处理程序`handler`**
- 处理程序回收终止的子进程，调用`deletejob`，它会从调用进程中作业控制的数据结构（如作业表）中删除某个作业的信息，而这里**父进程还没有调用`addjob`把子进程加入作业表，因此该函数什么都没做**
- 处理程序运行完毕后，内核继续运行父进程，父进程从`fork`返回后运行`addjob`，错误地**将不存在的子进程添加到作业列表中了**

我们期望的事件序列是：父进程调用`fork`函数，创建一个子进程，而在`fork`函数调用返回时（注意：**fork函数返回不代表子进程终止，仅仅是把创建的子进程的PID传递给父进程而已**），内核调度运行的是父进程，它正常地将`pid`使用`addjob`加入了父进程的工作列表中，在此之后子进程才返回，内核接收到`SIGCHLD`信号并且调用处理程序，使用`deletejob`删除工作列表中的该子进程

但很显然，这样的交错情况并不总是一定的，这也就导致了在某些交错中出现了错误的结果

这样的同步错误被称为==**竞争==：对于一对类似于`addjob`和`deletejob`这样的先后关系应该固定的操作，它们的先后调用关系会导致结果的正确与否，但交错使得它们的先后关系不定**，这样的问题就是竞争

下面的程序展示了一种消除示例程序中的竞争的方法：
```c
void handler(int sig) {  //信号处理程序
	int olderrno = errno;
	sigset_t mask_all, prev_all;
	pid_t pid;

	Sigfillset(&mask_all);
	while ((pid == waitpid(-1, NULL, 0)) > 0) {/* 清除僵死子进程的操作 */
		Sigprocmask(SIG_BLOCK, &mask_all, &prev_all);
		deletejob(pid);  
		Sigprocmask(SIG_SETMASK, &prev_all, NULL);
	}  //这里使用waitpid来等待
	if (errno != ECHILD)
		Sio_error("waitpid error");
	errno = olderrno;
}

int main(int argc, char **argv) {
	int pid;
	sigset_t mask_all, prev_one, mask_one;

	Sigfillset(&mask_all);
	Sigemptyset(&mask_one);
	Sigaddset(&mask_one, SIGCHLD);  //mask_one中只有SIGCHLD信号
	Signal(SIGCHLD, handler);
	initjobs();  //初始化任务列表

	Sigprocmask(SIG_BLOCK, &mask_one, &prev_one);  //在调用fork前阻塞mask_one中的信号，也就是SIGCHLD信号
	while (1) {
		if ((pid = Fork()) == 0) {  //子进程开始
			Sigprocmask(SIG_SETMASK, &prev_one, NULL);  //子进程和父进程共享被阻塞的信号集合，因此要小心地在调用execve之前解除阻塞
			Execve("/bin/date", argv, NULL);
		}
		Sigprocmask(SIG_SETMASK, &mask_all, NULL); //阻塞所有信号以确保对共享资源的修改不会被打扰
		addjob(pid);
		Sigprocmask(SIG_SETMASK, &prev_one, NULL);  //在addjob完成后恢复prev_one中存储的状态
	}
	exit(0);
}
```

该改进程序**在调用`fork`之前阻塞`SIGCHLD`信号，然后在`addjob`被调用之后解除阻塞，这样就能保证`addjob`必定先于处理程序进行之前被调用，使添加子进程到任务列表中的操作必定先于删除的操作**
注意一点，因为**子进程继承了调用`fork`前的父进程的被阻塞集合**，所以子进程中对`SIGCHLD`的信号也是阻塞的，为了避免可能出现的问题，要在子进程开始时解除阻塞

### 8.5.7 显式地等待信号
主程序有时会需要**显式等待某个信号处理程序的运行**，例如在一个Linux shell的前台作业中，在接收下一条用户命令时，它必须**等待作业终止**，被`SIGCHLD`处理程序回收后才进行接收
```c
#include "csapp.h"

volatile sig_atomic_t pid;

void sigchld_handler(int s) {
	int olderrno = errno;
	pid = waitpid(-1, NULL, 0);  //阻塞当前进程，回收任意一个已经退出的子进程，记录回收子进程的pid
	errno = olderrno;
}

void sigint_handler(int s) {}

int main(int argc, char **argv) {
	sigset_t mask, prev;
	Signal(SIGCHLD, sigchld_handler); 
	Signal(SIGINT, sigint_handler);  //注册处理程序
	Sigemptyset(&mask);
	Sigaddset(&mask, SIGCHLD);  //将SIGCHLD加入阻塞列表，以避免父子进程的竞争

	while (1) { 
		Sigprocmask(SIG_BLOCK, &mask, &prev);
		if (Fork() == 0)  exit(0);  //子进程创建

		pid = 0;  //将pid重置为0，会在sigchld的处理程序中变为非0
		Sigprocmask(SIG_SETMASK, &prev, NULL); //取消阻塞SIGCHLD，在子进程结束发出SIGCHLD后能接收信号并执行处理程序
		while (!pid)  //pid变为非0后终止循环，pid只在处理程序中变为非0，因此相当于在等待处理程序执行完毕
			;  
		
		//此后已经完成了子进程结束的等待，父进程可以做下一步的工作了
		printf(". ");
	} 
	exit(0);
}
```

这个例子中，父进程注册了处理程序后，进入一个死循环：每次循环首先**阻塞`SIGCHLD`信号**，以**避免父子进程之间的竞争**，然后创建子进程，在父进程中将pid置为0，在处理程序中，等待**回收子进程**并且记录子进程的pid，**赋值给全局的`pid`变量**
在父进程中，**通过while循环显式等待pid变为非0**，之后父进程才进行下一步工作

这段代码执行时，**循环在浪费处理器资源**：

我们可以**在一次循环中插入`pause`，使得循环暂停在这一次**：
```
while (!pid)  //可以不使用循环吗？不可以
	pause();
```
因为**接收到一个或多个`SIGINT`信号，会中断`pause`函数**，所以我们**需要`while`循环确保显式的等待不会因为外部信号终止**
这个方法有个严重的竞争问题：**如果在`while`测试条件之后，与`pause`执行之前接收到`SIGCHLD`信号，`pause`会永远暂停整个程序**（`SIGCHLD`会终止`pause`，但是在`pause`执行之前就处理完`SIGCHLD`了，所以`pause`永远停不下来，除非输入`ctrl+c`发出`SIGINT`信号）

另一个方法是**用`sleep`替换`pause`，延长`while`每次间隔的时间**：
```
while (!pid)
	sleep(1);  //太慢了！
```
这样的问题就是循环检测的间隔太慢了：最坏的情况，在一次`while`条件检测和`sleep`执行之间收到`SIGCHLD`信号，需要等待1秒才能执行下一次检测，退出循环
而且`sleep`的间隔也很难确定一个比较好的时间


**最合适的解决方法是使用`sigsuspend`**:
```
#include <signal.h>

int sigsuspend(const sigset_t *mask);
```
该函数**暂时使用参数中的`mask`替换当前的阻塞集合，然后==挂起该进程==，直到收到一个信号**
同时，收到信号后的行为是**要么运行一个处理程序，要么终止该进程：**
- 若终止该进程，则该进程不从`sigsuspend`函数中返回就直接终止
- 若运行处理程序，则`sigsuspend`函数**从处理程序中返回，并在返回时恢复它在被调用时原有的阻塞集合**（`sigsuspend`在处理程序终止后恢复运行，把阻塞集合复原）

**`sigsuspend`函数等价于下面代码的==不可中断（原子）==版本**：
```
sigprocmask(SIG_SETMASK, &mask, &prev);  //设置阻塞集合
pause();   //暂停
sigprocmask(SIG_SETMASK, &prev, NULL); //恢复阻塞集合
```
它确保**前两行调用必定一起发生，不会被中断，因此消除了竞争问题**

下面展示使用`sigsuspend`代替原例子中的`while`循环的方法：
```c
#include "csapp.h"

volatile sig_atomic_t pid;

void sigchld_handler(int s) {
	int olderrno = errno;
	pid = Waitpid(-1, NULL, 0);  //阻塞当前进程，回收任意一个已经退出的子进程，记录回收子进程的pid
	errno = olderrno;
}

void sigint_handler(int s) {}

int main(int argc, char **argv) {
	sigset_t mask, prev;
	Signal(SIGCHLD, sigchld_handler); 
	Signal(SIGINT, sigint_handler);  //注册处理程序
	Sigemptyset(&mask);
	Sigaddset(&mask, SIGCHLD);  //将SIGCHLD加入阻塞列表，以避免父子进程的竞争

	while (1) { 
		Sigprocmask(SIG_BLOCK, &mask, &prev);
		if (Fork() == 0)  exit(0);  //子进程创建

		pid = 0;  //将pid重置为0，会在sigchld的处理程序中变为非0
		
		while (!pid)  
			sigsuspend(&prev);

		Sigprocmask(SIG_SETMASK, &prev, NULL); //取消阻塞SIGCHLD
		
		//此后已经完成了子进程结束的等待，父进程可以做下一步的工作了
		printf(". ");
	} 
	exit(0);
}
```

每次调用`sigsuspend`之前阻塞`SIGCHLD`信号，随后由`sigsuspend`短暂取消阻塞，进行休眠，直到父进程捕获到一个信号。

## 8.6 非本地跳转
C语言提供的**用户级异常控制流**形式称为**非本地跳转**，它的作用是**将控制直接从一个函数转移到另一个当前正在执行的函数，而无需经过正常的调用-返回序列**
非本地跳转通过函数`setjmp`和`longjmp`来提供，其签名为：
```
#include <setjmp.h>

int setjmp(jmp_buf env);
int sigsetjmp(sigjmp_buf env, int savesigs);
```
其中`jmp_buf env`是**缓冲区结构体，用于保存当前的调用环境**
- `setjmp`函数用于在缓冲区`env`中保存调用环境，以供后面的跳转函数使用。**该函数的返回值只能用于区分不同的代码路径，而不能被赋值给变量**
  `rv = setjmp(env);  //错误用法`
  但是**可以用于`switch`或条件语句中**：
  `if (setjmp(env) == 0) { // 第一次调用，正常执行情况下的代码 }`
  
- `sigsetjmp`函数则允许我们**在保存调用环境的同时处理信号（提供了信号屏蔽掩码）**，其中的`sigjmp_buf`类型在`jmp_buf`的基础上增加了信号屏蔽字的存储，允许我们把信号状态也一并记录下来

下面的函数用于实现跳转，其签名：
```
void longjmp(jmp_buf env, int retval);
void siglongjmp(sigjmp_buf env, int retval);
```
该函数从`env`缓冲区参数中恢复调用环境，处罚


544

# Chapter 9. 虚拟内存

**虚拟内存VM**是**对主存的抽象概念**，为每个进程提供了一个大的、一致的和私有的地址空间：
- 它将主存看作是一个**存储在磁盘上的地址空间的高速缓存，只保存活动区域，根据需要在磁盘和主存之间来回传送数据**
- 它为每个进程提供了一个**一致的地址空间**
- 它**保护了每个进程的地址空间不被其他进程破坏**

## 9.1 物理和虚拟寻址

计算机系统的主存被组织成一个**由M个连续的字节大小的单元组成的数组**，这个数组中的**每一个字节都有一个唯一的==物理地址==**。首字节的地址为0，然后是1、2......以此类推

CPU访问主存最自然的方式就是使用物理地址，即**物理寻址：加载指令传给CPU一个真实有效的物理地址，CPU将信号通过内存总线传递给主存，主存取出从该地址开始的固定字节大小的字返回给CPU**，CPU会把它存放在寄存器中
![[Pasted image 20250217213605.png]]

**虚拟寻址：CPU生成一个虚拟地址来访问主存，该地址在被送入内存前先转换为适当的物理地址，这个过程叫做==地址翻译==**
![[Pasted image 20250217213613.png]]

CPU芯片上的**内存管理单元**利用存放在主存中的**查询表**来**动态翻译虚拟地址**，表的内容由操作系统管理

## 9.2 地址空间

**地址空间是一个非负整数地址的有序集合**$\{0,1,2,\cdots \}$，这样整数是连续的地址空间是线性地址空间

在带有虚拟内存的系统中，CPU从一个有$N=2^n$个地址的地址空间中生成虚拟地址，产生**虚拟地址空间**$\{0,1,2,\cdots,2^n-1\}$
这样的虚拟地址空间也叫做一个**n位地址空间**，n是表示最大地址所需要的位数。现代系统通常支持32位或64位地址空间

**物理地址空间**则对应于**系统中物理内存的M个字节大小（M不要求是2的幂次）**：
$$ \{0,1,2,\cdots , M-1\}$$
为方便讨论，下文假设$M=2^m$

地址空间的概念将数据对象（字节）和它们的属性（地址）分离开，**让一个数据对象可以对应于多个不同的地址，每个地址选取自不同的地址空间**，这就是虚拟内存的基本思想
实际上，**主存中的每个字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址**

## 9.3 虚拟内存作为缓存的工具

在前面的存储器层次结构中可知，**磁盘（较低层）上的数据被分割成块，作为它和主存（较高层）之间的传输单元**。
**虚拟页VP：类似于存储器中的分块，VM系统将虚拟内存分割为大小固定为$P=2^p$字节的块来进行传输**
**物理页（页帧）PP：同理，物理内存分割成的P字节块称为物理页**

任意时刻，虚拟页的集合由下列三个不相交的子集构成：
- 未分配的：VM系统还没有创建的页，没有任何数据与其关联，不占用任何磁盘空间（**只是占据虚拟地址空间，但实际上没有对应的实际存储**）

- 缓存的：已经缓存在物理内存中的已分配页，即**这些虚拟页已经被操作系统分配了物理内存，并且它们的数据已经被加载到物理内存中**，可以直接从虚拟页指向的物理内存中读取数据，而无需从硬盘中读取

- 未缓存的：还没有缓存在物理内存中的已分配页，即**这些虚拟页已经被分配了物理内存，但数据还没有被缓存到这些物理内存中**，无法从其中读取数据
![[Pasted image 20250218171245.png]]

注意一个区别：图示 **“虚拟页存储在磁盘上“指的是虚拟页所指向的数据一开始存储在磁盘上，然后发生不命中后从磁盘取出到DRAM中，也就是缓存到物理页中**

### 9.3.1 DRAM缓存的组织结构

下面使用以下术语指代：
- SRAM缓存：位于CPU和主存之间的L1、L2和L3高速缓存
- DRAM缓存（**主存**）：**虚拟内存系统的缓存，在主存中缓存虚拟页**

DRAM缓存实际上**依然是磁盘的缓存**，它在**访问虚拟地址时对应的虚拟页不在物理内存中（缺页异常）时进行缓存作用**，结合后面的内容会更清晰

再次回顾一下存储器层次结构体系：
![[Pasted image 20241107134247.png]]
**DRAM缓存（主存）担任的是SRAM缓存和磁盘之间的缓存**，虚拟内存的目的是根据假想的地址空间取出真实存在磁盘中的数据，**因此必须和磁盘直接接触**，取出后通过SRAM传给CPU

前面已经提到，DRAM比SRAM要慢大约10倍，磁盘则比DRAM慢大约100000倍，可见**DRAM中的缓存不命中要比SRAM中昂贵得多**（DRAM中发生缓存不命中时需要磁盘进行服务）
同时，**从磁盘中的一个扇区读取它的第一个字节需要经过寻路，时间开销很大**

**DRAM缓存的组织结构就是由上述两点不命中开销驱动的**。具有以下特征：
- 虚拟页往往很大，4KB~2MB

- 由于巨大的不命中开销，DRAM缓存是全相联的（没有分组，所有高速缓存行都在同一组内）。**全相联缓存映射方式不像其他方式，它没有固定的规则，因此数据存储在DRAM缓存中的位置是灵活的**，这样一来就使得**任何虚拟页所对应的磁盘中的数据可以被加载到DRAM中的任何位置**，好处在于

- 由于**DRAM缓存也是直接对磁盘进行缓存**，访问时间很长，因此总是使用**回写**，而非直写

- 不命中时的替换策略也影响不命中开销，**对DRAM缓存的替换策略算法要比对SRAM的更复杂精密**

### 9.3.2 页表

虚拟内存系统**需要判断一个虚拟页所需要的磁盘数据是否已经缓存在DRAM中的某个地方**：
- 若已经缓存了，**必须确定虚拟页所对应的DRAM缓存中的物理页是哪个**
- 若还没有缓存，**必须判断这个虚拟页所需的数据存放在磁盘中的哪个位置，然后在DRAM中选择一个牺牲物理页来替换**

上述功能由以下软硬件联合提供：
- 操作系统软件
- 内存管理单元中的地址翻译硬件
- 存放在物理内存中的数据结构：**页表**

**页表将虚拟页映射到物理页**，每次**地址翻译硬件**将一个虚拟地址转换为物理地址时都会**读取页表**，页表的**维护和磁盘与DRAM之间的页传送由操作系统完成**

页表是一个由**页表条目PTE**组成的数组（下图左）：
![[Pasted image 20250219215111.png]]

虚拟地址空间中的每一个页在**页表中的一个固定偏移量**处都有一个PTE，我们简单地认为**PTE由一个有效位和n个地址字段组成**：
- 地址字段：虚拟页在磁盘上的起始位置，或者，虚拟页对应的物理页的起始位置
- 有效位：**表明该虚拟页当前是否被缓存在DRAM中**
    - 若没有设置有效位，且地址字段为空，代表**这个虚拟页没有被分配**
    - 若没有设置有效位，且地址字段不为空，代表**这个虚拟页被分配但未缓存到物理内存中**，地址是虚拟页在磁盘上的起始位置
    - 若已经设置有效位，地址字段表示DRAM缓存中，**相应的物理页的起始位置**

还是要提醒一下，任意DRAM中的物理页都可以对应于任意的虚拟页（即任意的磁盘数据），因为全相联性

### 9.3.3 页命中

当CPU想要读取虚拟内存中的一个字，且这个字已经被缓存在DRAM中时（即：**已经设置了有效位的情况**），利用之后9.6节会介绍的技术，**地址翻译硬件将虚拟地址作为索引，定位它在页表中相应的PTE，并从内存中读取该PTE**
读取PTE后，直接使用PTE存储的地址字段，在DRAM物理内存中找到起始位置进行读取即可

### 9.3.4 缺页

**缺页：DRAM缓存不命中**，在发生缺页时，有效位不会被设置
当CPU引用虚拟内存中的一个字，但这个虚拟页并未缓存在DRAM中，此时PTE中的有效位未被设置，引发一个**缺页异常**
触发缺页异常后，该异常调用**内核中的缺页异常处理程序**，该程序会：
- 选择一个牺牲页
- 首先检查这个页是否被修改，如果被修改了，那先将它复制回磁盘
- 然后再把未缓存在DRAM中的那个页的数据拷**贝到牺牲页对应物理地址，进行替换**
- 此时牺牲页对应的虚拟页未缓存在主存中，但我们需要的这个页已经缓存在主存中了，可以**重新启动发生缺页的指令**，再次发送虚拟地址到地址翻译硬件中，直接页命中

虚拟内存系统的产生在SRAM缓存（L1-L3级高速缓存）的出现之前，它们的许多概念相似，但是术语是不一样的：
- **虚拟内存中的“页”相当于是SRAM缓存中的“块”**，都是对内存空间进行分割
- 虚拟内存中，磁盘和内存之间进行的页的传送叫做**交换或页面调度**
- 虚拟内存中，**只有在不命中发生时才产生页面的换入**的这个策略叫做**按需页面调度**，所有的现代系统都使用这种策略

### 9.3.5 分配页面和局部性

当操作系统分配一个新的虚拟内存页时，例如调用`malloc`的时候，页表的更新过程如下：
![[Pasted image 20250226202601.png]]


568

681
# Chapter 12. 并发编程

[^1]: D

[^2]: 是这样的
