# 1. 概论概念汇总

操作系统：管理计算机硬件与软件资源的计算机程序
通道：用于控制I/O设备与内存间的数据传输，启动后独立于CPU运行，实现CPU与I/O的并行

中断：CPU在收到外部中断信号后停止原来工作，转向事件处理程序执行，完成后回到原来断点继续工作

进程：运行中的程序
文件：数据在存储介质上的存在形式

文件的存在隐藏了操作系统与外设的交互细节，用户只需要进行系统调用，其具体的操作都是由操作系统的驱动来完成的，发生错误时的相应错误信息也会通过OS传递给用户

设备文件：为了实时控制和管理硬件设备，通过使用标准命令直接操作设备文件以访问硬件设备
通常为了保证硬件设备的安全，大多数直接访问设备的操作都是读取数据，而不是写入设备
当某个设备不可用时，其对应的设备文件也不能正常访问，通过这个方式检测设备是否正常

管道文件：连接两个进程的虚拟文件
shell：文字接口，用户级的人机交互媒介，不属于OS，是用于操作OS的最便捷手段

系统调用system call：程序员级的人机交互媒介，是操作系统提供给软件开发人员的唯一接口，OS内核中都有一组实现系统功能的过程，系统调用就是对上述过程的调用

linux的文件保护机制：主要分为三个权限组：文件所有者（文件或目录的创建者）- 用户组（文件所属的用户组）- 其他用户
每个权限组规定三类权限：r（读）w（写）x（执行），对应位置没有权限就设为`-`，例如r-x、-w-等
进一步简化，将rwx设置为数字4-2-1，而'-'设置为0，那么用户组的权限就可以记为这些数字之和：rwx = 4+2+1 = 7, r-x = 4+0+1 = 5
这样的记法能够保证每种权限组情况都有唯一的数字和与其对应且和最高为7，三个权限组就可以表示为三个一位数字了，例如777，752等等

# 2. 进程

进程就是执行中的程序
对于单核处理器，其并行是伪并行，本质上是CPU在多个任务之间进行的快速切换；而多核处理器中的并行才是真正的同时运行

进程的特征就是状态机，包括程序计数器、寄存器、变量值等状态，所有运行中的软件被组织成一个顺序的进程集合中

程序是静态的概念，进程是动态的概念

进程具有层次关系：不同的操作系统为了支持进程，需要提供一个途径来创建所需要的各类进程
在Unix中，采用fork()【其实是clone()】系统调用来从一个进程中创建一个新的进程，新创建的进程是当前进程的子进程
系统启动时初始化一个最初的init父进程，从该父进程开始创建各个进程
所以对于unix来说，进程本质上是一种特殊的线程，它并不区分进程和线程的概念

进程微观模型的三种状态图如下所示
![[Pasted image 20250524161231.png]]
1. 进程阻塞：由于外部输入等原因从运行状态进入阻塞状态
2. 调度器选择另一个进程执行，当前进程进入就绪状态
3. 调度器选择当前进程执行
4. 阻塞事件处理完成，可以继续执行

进程表：每个进程都是表中的一个记录，每个记录都包含了进程的状态，程序计数器，栈指针，内存分配等，当进程处于就绪状态时，其所有的信息都是有效可访问的
进程控制块PCB是一个数组形式的数据结构，包含了执行一个进程所需的所有信息

中断向量：为了满足不同进程之间可以顺利切换，需要存储当前进程的各个变量信息并压入栈中，为其将来的状态恢复进行一些操作
保存完成后，清空整个运行现场（寄存器、栈等），为新的进程的运行做好准备

线程：传统的操作系统中一个进程只有一个控制线索和一个程序计数器，而现代操作系统在一个进程中可以支持多条控制线索，每条控制线索指引的就是一个线程

线程存在于内核和用户层中，其设计难度、安全性、管理难度都因系统而异，不同系统的线程语义也会有一定差异

进程间通信
进程之间的通信需要做到：
- 考虑进程给其他进程发送的信息的结构设计以及接收方法
- 必须确保进程通信时不能同时访问临界区内的资源
- 确定存在依赖关系的进程间的合适的运行顺序
spooler问题

Peterson算法：很简单，手写的思路稍微叙述一下：
对于整个线程执行的函数，包裹在一个while(True)循环中
每个循环最开始，将数组中本线程对应的标志从False设为True，然后设置一个全局变量turn为一个特殊的值，例如P0将其设置为0，P1将其设置为1，这个变量相当于是锁，其值代表这个锁**所排斥**的线程

当对应标志位为True且turn变量的值为本线程的编号时，进入等待；反之，执行自己所需的操作，执行完毕后将对应标志位设置为False

硬件方法TSL：
其实就是基于原子操作：将一个操作设置为运行过程中不允许被打断，不可分割的操作
设置的原子操作的基础功能是将一个存储器的字读取到寄存器中，在内存中存储一个非零的值
优点：适用于任意数目的进程，可以执行在多处理器上。支持进程内存在多个临界区，只需为每个临界区设置一个布尔变量即可
缺点：等待需要耗费CPU时间，不能让权等待；可能存在一直选不上的进程，出现“饥饿”；可能发生死锁情况

上面两种方式的共同缺点在于忙等待对CPU资源的浪费，以及进程的优先级的差别会导致调度时某个在临界区内的低优先级进程不被调度到，从而无法离开临界区

解决的方法是引入睡眠和唤醒，睡眠本质上是放弃调度权限，不占用CPU资源来忙等待，当满足触发条件时，由其他人来唤醒睡眠的进程进入临界区

生产者和消费者：共享一个缓冲区（存放任务的袋子）
生产者进程不断向缓冲区内写入任务，而消费者从缓冲区内取出任务执行，任意时刻只能有一个进程对共享缓冲区进行操作

当缓冲区内任务的数量`count == N`时，生产者进入sleep()；当缓冲区内的任务数量`count == 0`时，消费者进入sleep()；当生产者进程执行完毕后，count++，唤醒消费者进程；当消费者进程执行完毕后，count--，唤醒生产者进程

问题：类spooler目录问题：在检查count值和进入sleep()之间，另一类进程工作了使得满足唤醒要求，而被唤醒的进程根本没睡觉，但由于后续没有检查操作了，本应被唤醒的进程又睡眠了，此时两种进程都进入了睡眠

因此引入信号量机制，它是一种锁的计数器：
它主要具有PV两个操作：
- P操作：也称为**等待操作**，当一个线程请求访问资源时，它会先检查信号量（计数器）的值，若值大于0，说明线程可以访问资源，为其分配一把钥匙，**计数器-1**；若信号量为0，线程必须**等待**
- V操作：也称为**释放操作**，当一个线程在临界区内完成它的操作，需要释放钥匙时，要**将信号量的值加1**，并且**通知其他线程可以访问资源**

“原语”（Primitive）是指操作系统提供的基本操作或功能单元，它们是构成更复杂功能的基本构件。原语通常是无法再分解的操作，代表了操作系统或计算机系统中的最基本的、不可再细化的功能。

多元信号量的PV操作：
信号量semaphore结构体中，除了计数的变量count，还维护了一个队列queue
- P原语：将count减一，在count < 0的时候，将进程加入队列queue中并阻塞
- V原语：将count加一，在count <= 0的时候，从等待队列queue中取出一个进程，将进程加入就绪队列中执行
遗漏P原语不能保证互斥访问，遗漏V原语不能在使用完临界资源后将其释放给其他进程，因此PV原语不能遗漏或次序错误或重复

利用PV原语实现生产者与消费者，需要设置三个信号量：mutex用于控制只有一个线程对临界资源进行操作，full和empty分别代表**从生产者的角度看到的钥匙`empty`** 和 **从消费者的角度看到的钥匙`fill`**
- 生产者：P(&empty), P(&mutex), 生产任务, V(&mutex), V(&full)
- 消费者：P(&full), P(&mutex), 取出并执行任务, V(&mutex), V(&empty)

信号量同步缺点：
- 同步操作分散、易读性差、不易修改与维护、很难保证正确性

管程：将信号量与原语封装在一个对象内部，它是关于共享资源的数据结构以及一组针对该资源的操作过程锁构成的软件模块
用于提高代码的可读性，便于修改和维护
特征：模块化，能够单独编译、抽象数据类型、信息封装、共享变量在外部不可见、互斥进入
为每个共享资源设立一个管程，在某个时刻，只能有一个管程过程是活跃的，它的互斥操作是由编译器所支持的，更为安全，不宜出错。
缺点：支持管程的编程语言少，要求编译器的支持，很难被实际应用

哲学家进餐问题
会导致死锁，因为每个哲学家有可能拿到各自左手边的叉子，此时右手边的叉子被其他哲学家占用了，导致大家都无法继续进行下去

解决方法：先看看叉子都在不在，如果有一个不在就休眠，反之才拿走吃饭
```c
mutex_lock(&mutex);  // 首先先获得一把互斥锁：大家先别动，让我看看！
while (!(avail[lhs] && avail[rhs])) {  // 如果左边和右边的叉子有一个不在，进入休眠
  wait(&cv, &mutex);  // 睡眠，直到被其他人唤醒
}
avail[lhs] = avail[rhs] = false;  // 此时左边和右边的叉子都在，于是我拿走了，标记为“不在”
mutex_unlock(&mutex);  // 解除互斥锁：你们随意！
// 两把叉子都稳稳地拿到了，在线程本地进行“吃饭“操作

// 下面要还叉子了
mutex_lock(&mutex);  // 获得互斥锁：先让我还！
avail[lhs] = avail[rhs] = true;  // 还叉子，置为可用状态
broadcast(&cv);  // 唤醒所有在睡眠的线程
mutex_unlock(&mutex);  // 解除互斥锁，让其他线程获得叉子
```

读者-写者问题
核心在于如何让多个进程能够安全、有效地访问共享资源，同时满足以下需求：

1. **读者不互相干扰**：多个读者可以同时访问资源，但如果有写者在写入，所有的读者必须等待。

2. **写者与读者互斥**：如果有读者正在访问资源，写者必须等待；同样地，如果有写者正在写入资源，其他读者和写者都必须等待。
是数据库的访问模型
解决方法：

a. 读优先：如果有任何一个读者在读取数据，则写者不能进行写入。读者给数据库上锁
局限性：只要有一个读者在，就会无法写入，写者容易饥饿

b. 写优先：需要增加额外的信号量和变量
为了保证一个写进程声明想写时，不允许新的读进程访问该数据区，需要增加额外的信号量和变量：
- 信号量rsem:当至少有一个写进程准备访问数据区时，用来禁止所有的读进程；
- 变量writecount:控制rsem的设置；
- 信号量y:控制writecount的更新。
- 一个额外的信号量z，为了写进程优先，不要多余的读进程在rsem里等待，将多余的读进程放入z中，在那里排队。

# 3. 进程调度

进程调度按照调度的层次，可以分为下面三种
- 作业（高级调度、宏观调度）：从用户工作流程的角度，一次提交的若干个流程，每个程序按照进程调度
- 内外存交换（中级调度）：从存储器资源的角度，将进程的一部分或全部都换出到外存上，将当前所需部分换入到内存这个过程。因为指令和数据需要在内存中才能被CPU直接访问
- 进程或线程（低级调度、微观调度）：从CPU资源的角度定义的执行单位，执行频繁，需要效率高
![[Pasted image 20250527204822.png]]

按照调度的时间周期，分为长期、中期和短期

按照OS分类，分为批处理调度、分时和实时调度、多处理机调度

性能标准
面向用户：
- 周转时间：作业从提交到完成（得到结果）之间所经历的时间
在考题计算时，往往会给出进程的到达时间（开始执行的时间）以及进程的执行时间（连续情况下所需的CPU时间）
同时还会给出CPU调度算法，不同算法会影响每个进程的执行顺序，进而影响进程得到结果的时刻，然后影响周转时间
例如，先来先服务中，两个进程A（开始时刻1，执行时间5），B（开始时刻2， 执行时间4）
若A先到达，其结束时刻为6，B的结束时刻为6+4=10
A的周转时间就是执行时间5，而B的周转时间却是结束时刻-开始时刻=10-2=8

- 平均周转时间：所有进程的周转时间的平均数
- 平均带权周转时间：每个进程的周转时间与进程的服务时间（执行时间）之比的平均值
例如，上面的例子中，进程A的带权周转时间是5/5=1， B的带权周转时间是8/4=2，平均带权周转时间就是3/2

面向系统：
- 吞吐量：单位时间内所完成的作业的数量，与作业本身性质和调度算法都有关系
- 平均周转时间不是吞吐量的倒数，因为并发执行的作业在时间上可以重叠

- 处理机利用率

调度程序需要满足的功能：记录所有进程的运行情况、上下文切换
需要遵守的原则：公平有效、响应时间和周转时间尽可能短，吞吐量尽可能多
但是这些原则本身就存在矛盾，且进程的性质决定了其执行具有不确定性（这点可以设置计时器或者时钟，定期对在系统中的进程进行判断，来决定当前是否需要发生进程切换）

可剥夺调度：允许将逻辑上可运行的进程暂时挂起的测量
非剥夺调度：系统一直将进程运行至结束，主要用于早期的批处理系统以及专用系统
存在竞争的多用户系统一般使用非剥夺调度

调度策略
1. 先来先服务FCFS：按照进入系统的先后顺序来进行调度，当前作业或进程占用CPU，直到执行完成或者被阻塞时才让出，假设一个进程先因为IO让出CPU，IO结束后，它需要等待当前正在执行的进程让出CPU后才恢复执行
	是最直接的算法，比较有利于长作业和CPU繁忙的作业，不利于短作业和IO繁忙的作业

2. 时间片轮转调度算法：主要用于微观调度，说明切换的方式，目的是提高资源利用率。
	将系统中所有就绪的进程按照FCFS原则拍成一个队列，每次调度将CPU分派给队首进程，让其执行一个时间片的长度，大约为几到几百个ms，时间片结束时发生中断，暂停进程的执行并将其送到就绪队列的末尾，上下文切换到当前的队首进程执行
	时间片可以不完全被用完，例如等待IO时被阻塞

时间片过长，该算法退化为FCFS，时间片过短则上下文切换次数过多导致开销大。就绪进程越多，时间片越小（响应时间一定），同时还应考虑到系统的处理能力，使得用户输入通常在一个时间片内能被处理完，否则平均周转时间和响应时间都会增长

3. 优先级调度算法
	1. 静态优先级调度：创建进程时就根据进程类型、对资源的需求和用户要求确定该进程的优先级，进程终止前都不改变
	2. 动态优先级调度：进程的优先级在运行过程中可以更改，按照在就绪队列中的等待时间越长，优先级越高；执行的时间片越多，优先级越低等方式更改

4. 多重队列：引入多个就绪队列，根据作业或进程类型的不同，将就绪队列划分为若干子队列，每个作业归入一个队列中，不同队列可以有不同优先级、时间片长度和调度策略
5. 短进程优先：对于预计时间段的作业或进程，优先分派处理机，通常只对队列中就绪的进程进行这样的调整
	优点是能改善FCFS的平均周转时间，提高系统的吞吐量；缺点是对长作业非常不利，且作业的紧迫程度没有考虑，执行时间的预计方式也很难准确


# 4. 任务设计与实现

采用多任务的好处：任务的规模较小，应用可能具有多个任务的处理，任务之间独立性高，耦合性小，实时性强

进程：执行中的程序，由代码、数据、堆栈和进程控制块PCB构成
进程控制块：包含了操作系统用来控制进程所需要的信息的数据结构，包括进程状态、CPU寄存器、调度信息、内存状态管理、IO状态管理等

进程中，所有线程共享该进程的状态和资源，可以访问相同的数据
使用线程的优势：创建和终止的开销比创建进程少，切换和通信效率高

任务：进程和线程的统称，是一个具有独立功能的无限循环的程序段的一次运行活动，是实时内核调度的单位，具有动态性、并行性、异步独立性
主要包括代码、数据、堆栈、上下文信息，通常就是一个while(true)无限循环程序

程序是任务的组成部分，任务能真实描述工作内容的并发性，是动态的，有生命周期，一个程序可以用于多个任务中

任务的上下文环境等执行信息通过任务控制块TCB存储

任务的参数：
- 优先级：表示任务对应工作内容在处理上的优先程度
- 周期：周期任务的参数，任务周期性执行的间隔时间
- 计算时间：任务在特定硬件环境下被完整执行所需要的时间，通常使用最坏情况下的执行时间或统计时间

- 就绪时间：任务具备了在处理器上所执行的所需条件时的时间
- 截止时间：任务必须在该时间到来之前被完成，可表示为绝对截止时间和相对截止时间，相对截止时间时绝对截止时间减去就绪时间得到的
- 强截止时间用于关键任务，出现在强实时系统中

任务控制块TCB储存任务执行所需要的所有信息，包括名字、其实地址、优先级、状态、硬件上下文和队列指针等

任务切换就是保存当前任务的信息至TCB，然后根据下一个任务的TCB复原上下文的过程

任务调度的队列就由一个个TCB构成，可以使用单等待队列或多等待队列的方式，前者扫描队列中包含的所有任务，根据一定策略进行选取，放置到就绪队列。后者在每个资源对应的任务上进行队列排序，当资源对应的事件发生时，建立任务等待队列的速度更块

就绪任务等待队列的排序方式可以是直接排列，扫描整个队列找优先级最高的任务执行；也可以是一开始就按照优先级顺序建立队列，然后直接取出
具有不确定性

任务调度本身通过调度程序实现，以函数形式存在，调度程序是一个函数调用，而非任务，调用调度程序的具体位置称为调度点，调度本身需要系统调用的开销，计算下一个可悲执行的任务，因此应尽量简单
设计调度程序时，通常需要综合考虑如下因素：
CPU的使用率（CPU utilization）
输入/输出设备的吞吐率
响应时间（responsive time）
公平性
截止时间

# 5. 存储

IO硬件原理
IO设备一般分为机械和电子两部分，将其分开模块化管理，以提供更为通用的设计
- 机械部分：设备本身
- 电子部分：设备适配器
适配器与设备之间的接口是一个符合国际标准的标准接口，我们只需要关注适配器而无需考虑设备内部的工作，因为它与操作系统打交道

设备接口形式：按照主机与设备的约定格式和过程接受或发送数据和信号（端口地址译码）
IO指令的形式和IO地址是相互关联的，主要分为：
- 内存映像IO模式
- IO专用指令
我们对IO的期望是：
使得CPU利用率尽可能不被IO降低，脱离IO的负担，提高IO本身的绝对速度和设备利用率，并且让CPU不等待IO

因此，在设备与主机的硬连接上引入总线
总线：将计算机中的各个子系统，包括CPU、内存、外设等相互连接，这个连接是共享的
优点在于：低成本、灵活性、便于两个计算机系统之间共享外设
缺点在于：本身形成了通讯瓶颈，限制了IO的吞吐量

控制器（适配器，设备的电子部分）完成设备与主机之间的通讯
控制器与设备的接口是一种低层次的接口，从硬盘中读取信息，读出的是一个比特流，每个控制器都有一些与CPU进行通信的寄存器，将这些寄存器放入内存，就是内存映像IO
CPU通过向控制器的寄存器中写入信息来控制设备的工作

DMA：直接内存访问
数据在内存与IO设备之间直接成块传送数据
CPU在开始时会向设备发送“传送一块”的命令，其实际操作由DMA硬件直接完成，需要附加的辅助硬件来完成，这些硬件属于设备的电子部分，由控制器实现

DMA与常规磁盘访问的对比：
- 常规磁盘访问：控制器从磁盘驱动器中串行地逐位读取整个块，将整块信息放入控制器的内部缓冲区中，随后进行和校验计算以确保没有读错误发生。在这之后，产生中断，将控制转给操作系统，操作系统负责从控制器中逐字节读取缓冲区内的信息并送入内存
- DMA磁盘访问：允许DMA控制器接管地址总线的控制权，由其直接控制DMA控制器与内存之间的数据交换，不需要CPU介入以减轻CPU负担。需要向控制器传送数据块将要送往内存的起始地址以及需要传送的字节数

使用DMA的优点在于通过让控制器对数据进行第一步收集和校验，可以缓解设备之间对总线控制权的争夺，在启动DMA传送之前完全不使用总线，简化了结构设计与被阻塞任务的数量

共享区域的管理：
当数据从CPU或控制器被传入内存，且控制器本身也在读取磁盘扇区上的数据时，此时控制器就是一个共享区域，会在其中发生竞争
因此，如果数据从控制器到内存传输，且数据仍然需要被读取，那么因为读取的速度有限，如果数据连续地放置在磁盘上，就一定会发生数据丢失，有一些块来不及读取
此时需要采取间隔一个数据块读一个或几个数据块的读取方式，称为磁盘块交叉编址：将一整个数据拆散交叉放置在磁盘上的不同块中，以避免竞争导致的数据丢失
![[Pasted image 20250528151353.png]]
假设磁盘读取数据的速度只能支持间隔一个块读取一个块，那么对于a方式，需要转8周才能按01234567的方式读取完全部数据，而b方式只需要转2周
对于双交叉编码，主要是针对从控制器向内存传输数据的速度比从硬盘向控制器传输速度慢的情况

IO软件设计思想
- 设备无关性：操作系统从设备上获得输入和输出，设备应该是统一命名的：一个文件或设备的名字不应依赖于设备，设备的驱动和差异性由操作系统本身处理
- 错误处理：数据传输的错误尽量交给硬件和底层软件处理，如果实在无法处理，才交给较高层的软件
- 异步同步问题：数据传输对于IO硬件来说是异步的，在系统中实现异步应该实现阻塞和唤醒机制，操作系统使用中断机制来实现
- 独占与共享：例如，打印机是独占设备，而磁盘是共享设备，操作系统需要对两种设备都具有同时处理能力


设备驱动程序：与设备密切相关的代码，每个设备驱动程序处理一种设备类型
每个控制器都有一个或多个设备寄存器用于存放向设备发送的命令和参数，设备驱动程序就是用来释放这些命令并监督其正确执行的

大部分IO软件是与设备无关的，这些设备独立软件负责给文件和设备对象命名：把符号名映射到正确的设备驱动程序上，并且设置设备文件的rwx权限以保护设备

死锁
 一组进程中，**每个进程都无限等待被该组进程中另一进程所占有的资源**，因而永远无法得到的资源，这种现象称为进程死锁，这一组进程就称为死锁进程。
 - 参与死锁的进程至少有两个，且至少有两个进程已经占有资源
 - 所有进程都在等待资源
 - 参与死锁的进程是当前系统中所有进程的子集
若死锁发生，会浪费大量系统资源，这些资源指的是在任何时刻只能被单个进程所使用的对象，分为可剥夺式资源（例如存储器）和不可剥夺式资源（例如打印机）
资源的分配：被申请-被分配-被使用-被释放

对于可剥夺式资源：可以避免可能存在死锁的情况，直接剥夺其本身占有的资源即可
对于不可剥夺式资源：无法强行剥夺资源，否则会出现混乱，因此对于这种情况需要额外分析处理可能导致的潜在死锁

发生死锁的必要条件：
- 互斥使用：一个资源只能被分配个至多一个进程
- 保持和等待：进程在申请新的资源同时保持对原来资源的占有
- 不可抢占：资源申请者无法强行从资源占有者手中夺取资源，只能自愿释放
- 循环等待：必然存在由两个或多个进程组成的循环链，每个进程都在等待相邻进程手中的资源
使用有向图描述死锁的模型，资源使用矩形表示，进程使用圆形表示，一个从圆形到矩形的有向箭头代表进程申请资源，一个从矩形到圆形的有向箭头代表进程占有资源，这样的有向图中存在单向环路就是存在死锁

一个解决申请同类型资源时产生的死锁的方案：从资源分配的角度，应该满足：
- 每个进程一次只能申请一个单位的资源
- 满足总的申请后才能使用资源
- 使用资源完毕后所有线程一次性释放资源
死锁的处理方法：
- 忽略死锁的发生
- 检测死锁并恢复
- 破坏死锁发生的四个必要条件以预防
- 谨慎对资源进行动态分配以避免死锁

鸵鸟算法：对问题视而不见，对于不需要完备解决或是解决后效果差异不大的问题，直接忽略

死锁检测与恢复：主要检测资源的申请和释放，从而获取当前资源的使用情况，构造出资源申请占有有向图，检测是否存在环路即可。更简单的方式是直接检测阻塞时间，如果阻塞时间长于某一预定阈值，那就取消这样的进程

破坏死锁必要条件：
1. 破坏互斥使用：对于打印机这类设备，使用假脱机等技术来避免资源竞争，并且利用监控程序统一分配
2. 破坏请求和保持条件：要求进程在运行前必须一次性申请完它所需要的所有资源，且只有在这些资源都可以被使用时才一次性分配给它（对于资源在运行时才可以知道的进程，这种方案不现实）；或是当进程申请每个资源时，先释放自己已有的资源，申请成功后才回收刚才释放的资源
3. 破坏不可剥夺：允许进程动态申请资源的前提下，规定一个进程在申请新的资源不能立即得到满足而进入等待状态时，必须释放已有的全部资源
4. 破坏循环等待：采用资源有序分配法：将系统中的所有资源编号，进程在申请资源时必须按照编号的递增次序进行，否则不予分配

避免死锁：对进程发出的每一个系统能够进行满足的资源申请，进行动态检查，若分配后系统可能发生死锁，不予分配
安全状态：若存在一个由系统中的所有进程构成的安全序列P1, ... ,Pn，则系统处于安全状态
序列中，对于每一个进程Pi，它以后所需要的资源量不超过系统当前剩余资源量与所有j<i的进程Pj占用的资源量之和

安全状态下必定没有死锁发生，非安全状态下可能有死锁发生

单种资源的银行家算法：预防死锁的发生
银行家算法中，需要定义以下数据结构：
- **Available**：一个数组，表示系统中各类资源的可用数量。
    
- **Max**：一个矩阵，表示每个进程对每类资源的最大需求。
    
- **Allocation**：一个矩阵，表示每个进程当前已分配的资源数。
    
- **Need**：一个矩阵，表示每个进程还需要的资源数，`Need = Max - Allocation`。

安全状态就是存在一个不发生死锁的资源分配顺序，使得所有进程的资源需求都能被满足
银行家算法的核心是通过**模拟资源分配的过程**来判断系统是否处于安全状态。
具体来说，其过程如下：
1. - 创建一个“工作”向量`Work`，表示当前系统中可用的资源数，初始时，`Work = Available`。
	    
	- 创建一个“完成”向量`Finish`，标记每个进程是否完成，初始时为`False`。

2. 遍历所有进程，找到一个满足以下条件的进程`i`：
		
	- 该进程尚未完成，即`Finish[i] = False`。
	    
	- 该进程需要的资源数`Need[i]`小于等于当前的可用资源数`Work`

3. 如果找到这样的进程`i`，则：

	- 假设该进程运行完成，释放其所占用的所有资源，将其已分配资源加回到`Work`中。
	    
	- 将`Finish[i]`标记为`True`，表示进程`i`已完成。

4. 重复步骤2和3，逐个遍历每个进程，考察是否有need <= avaliable，直到所有进程都完成（`Finish[i] = True`），或找不到可以执行的进程。
5. 如果所有进程都完成了，那么就是安全状态；如果存在未完成进程，就不是安全状态

考试中，一般会给出类似如下的初始条件：
系统中有三种资源**Available**: `[3, 3, 2]` (系统中剩余的可用资源)
Max:
P1: [7, 5, 3]
P2: [3, 2, 2]
P3: [9, 0, 2]
P4: [2, 2, 2]
P5: [4, 3, 3]

Allocation:
P1: [0, 1, 0]
P2: [2, 1, 1]
P3: [3, 0, 2]
P4: [2, 1, 1]
P5: [0, 0, 2]

于是可以计算出：
Need = Max - Allocation
P1: [7-0, 5-1, 3-0] = [7, 4, 3]
P2: [3-2, 2-1, 2-1] = [1, 1, 1]
P3: [9-3, 0-0, 2-2] = [6, 0, 0]
P4: [2-2, 2-1, 2-1] = [0, 1, 1]
P5: [4-0, 3-0, 3-2] = [4, 3, 1]

#### 步骤2：初始化变量

- Available = `[3, 3, 2]`
    
- Work = Available = `[3, 3, 2]`
    
- Finish = `[False, False, False, False, False]`
    

#### 步骤3：查找满足条件的进程

- P1需要的资源是 `[7, 4, 3]`，它大于当前的可用资源 `[3, 3, 2]`，无法执行。
    
- P2需要的资源是 `[1, 1, 1]`，小于等于当前的可用资源 `[3, 3, 2]`，可以执行。
    
    - 执行P2后，释放资源 `[2, 1, 1]`，更新可用资源：`Work = [3+2, 3+1, 2+1] = [5, 4, 3]`。
        
    - `Finish[2] = True`，P2完成。
        

#### 步骤4：继续查找下一个进程

- P1需要的资源是 `[7, 4, 3]`，仍然大于当前的可用资源 `[5, 4, 3]`，无法执行。
    
- P3需要的资源是 `[6, 0, 0]`，小于等于当前的可用资源 `[5, 4, 3]`，可以执行。
    
    - 执行P3后，释放资源 `[3, 0, 2]`，更新可用资源：`Work = [5+3, 4+0, 3+2] = [8, 4, 5]`。
        
    - `Finish[3] = True`，P3完成。
        

#### 步骤5：继续查找

- P1需要的资源是 `[7, 4, 3]`，小于等于当前的可用资源 `[8, 4, 5]`，可以执行。
    
    - 执行P1后，释放资源 `[0, 1, 0]`，更新可用资源：`Work = [8+0, 4+1, 5+0] = [8, 5, 5]`。
        
    - `Finish[1] = True`，P1完成。
        

#### 步骤6：继续查找

- P4需要的资源是 `[0, 1, 1]`，小于等于当前的可用资源 `[8, 5, 5]`，可以执行。
    
    - 执行P4后，释放资源 `[2, 1, 1]`，更新可用资源：`Work = [8+2, 5+1, 5+1] = [10, 6, 6]`。
        
    - `Finish[4] = True`，P4完成。
        

#### 步骤7：继续查找

- P5需要的资源是 `[4, 3, 1]`，小于等于当前的可用资源 `[10, 6, 6]`，可以执行。
    
    - 执行P5后，释放资源 `[0, 0, 2]`，更新可用资源：`Work = [10+0, 6+0, 6+2] = [10, 6, 8]`。
        
    - `Finish[5] = True`，P5完成。

#### 步骤8：检查是否所有进程都完成

- 所有进程都完成，`Finish = [True, True, True, True, True]`。
    

因此，该系统处于**安全状态**


# 6. 内存

存储器是计算机不可缺少的部分
存储器层次结构：
- CPU寄存器
- 高速：价格昂贵，易失信息的Cache
- 中速：中等价格、易变化的RAM
- 低速：低廉价格，不易丢失信息的磁盘
管理这样层次结构的存储管理模块是Memory manager
由操作系统协调这些存储器的使用，目标是存取内存的速度尽量与CPU取指速度匹配，大小能够装下当前运行的程序与数据

内存空间：由存储单元组成的一维连续的地址空间，存放当前正在运行程序的代码和数据，是程序计数器所指向的存储器
内存空间分为系统区（存放操作系统）和用户区（存放用户程序和数据）

为了满足用户使用需求：多道程序并发执行、无需考虑硬件细节、能够解决程序空间比实际内存大的问题、程序执行时能动态伸缩、内存存取速度快等
引入多道程序设计技术

## 1.  内存空间的管理、分配与回收

如何记录内存的使用情况？设置内存分配表
如何划分内存空间？静态还是动态，等长还是不等长？

### 内存分配表（记录方式）

#### 1. 位图表示法
使用一个比特位表示一个页面，当该位为0时表示空闲，为1时表示占用
基于这样的位图，设置如下三个表格
- 空闲页面表：包括首页面号和页面个数（一组连续的空闲页的数量），连续若干的页面作为一个元组登记在表中
- 空闲块表：记录空闲块的首地址和长度，没有记录的区域就是被占用区域
- 空闲块链表：将所有的空闲块组织成链表形式

内存分配的其他问题：
- 确定分配算法
- 实施内存分配

内存回收的问题：
- 分配回收的方式根据静态分配和动态分配而不同

存储共享的问题：
- 内存共享：两个或多个进程应该共用内存中的相同区域，从而节省内存空间和提高内存利用率，实现进程之间的通信，包括数据和代码共享

存储保护的问题：
- 为多个程序共享内存提供保障，使得在内存中的各道程序只能访问它自己的区域，避免不同程序之间的干扰。由硬件完成保护功能，由软件辅助实现

保护的实现方式：
- 防止地址越界：每个进程都有自己独立的进程地址空间，若进程运行所产生的地址超出了它的地址空间，那么就是地址越界，发生中断，由操作系统进行相应处理。实现方式是提供一对基址寄存器+限长寄存器储存地址范围
- 防止操作越权：对于多个进程共享的存储区域，每个进程具有各自的访问权限，若进程对共享区域的访问越权了，就中断处理，其实就是读写保护
- 动态伸缩，内存扩充：通过虚拟存储技术实现，采用一定技术来“扩充”内存容量，使得用户好像在一个比实际内存大得多的内存空间，需要将内外存结合起来统一使用
- 快速存取：地址重定位和变换
	- 对于数据的地址，可以分为逻辑地址（相对的虚地址）和物理地址（绝对的实地址），这两个地址之间互相映射。在用户程序中，形成的目标代码通常采用相对地址的方式，相对于首地址0而编址，所以逻辑地址是无法直接从内存中读取信息的
- 重定位和保护：若多个作业为某一个程序服务，主程序调用作业的时候就需要定位到这些作业以保证程序的运行，此时链接器按照设定的分区机制来定位程序。也就是**把虚拟地址转换到物理地址**。常用方法有：
	- 静态重定位：当用户程序被装入内存时，一次性实现全部逻辑地址到物理地址的转换，以后不再转换（一般在装入内存时由软件完成）。
	- 动态重定位：在程序运行过程中**要访问数据时再进行地址变换**（即在逐条指令执行时完成地址映射，硬件上需要一对寄存器的支持

# 7. 基本内存管理

交换和分页技术的目标：由于没有足够大的主存来同时容纳所有进程，因此需要在有限的空间离进行数据的覆盖替换
## 无交换和分页的单道程序
同一时刻与操作系统共享存储器，现有的方案中，操作系统可以位于随机存取存储器RAM、只读存储器ROM，或是驱动程序部分位于ROM，其他部分位于RAM中，用户程序位于主存的上中下部分
系统位于ROM的部分实际上就是电脑的BIOS基本IO系统

这种方式下，操作系统把程序从磁盘中整个复制到存储器内执行，然后执行下一个程序时直接覆盖继续执行，一个时间只能执行一个程序，这种方式很慢，不适应现代的硬件发展

## 固定分区的多道程序
支持更多的程序：当某个程序处于等待I/O的时候，可以让CPU为别的程序服务
因此，另一种比较早期的方法是，将主存划分为几个固定大小的分区，根据程序的不同，将其加载进不同的分区
一个分区可能有多个程序被加载进入，所以可以按照单个或多个输入队列的方式，将进程按顺序塞入分区

显然，多个输入队列这种方式会出现一些分区很忙碌，另一些分区根本没有程序的情况；而单个输入队列的方式可以将较小的作业优先塞入小分区执行完成，或者按照任务被推后的次数增加执行优先级权重


## 内存交换
在分时系统和个人PC中，固定分区的方案不太实际：主存可能不够用，进程一部分需要保存在磁盘上，或者需要频繁将进程从磁盘调入内存
为此产生了交换技术和虚拟内存技术

### 可变分区的内存分配；交换技术
进程依次进入内存并获得自己所需的内存空间，在执行完毕后离开，释放原来占用的内存资源；新的进程进入之后，从剩余的空间中划分出新的空间占用

这是一种可变分区的内存分配，内存中的分区和大小随着进程变化而变化

但是实际上，内存空间不断划分的过程中，其分布越来越复杂，不便于管理，需要有机制去集中整理分配后剩余的零碎空间（空闲区域的合并）

另外，进程运行的时候其数据段也会增长，从而需要分配新的内存，所需空间变大。若相邻区域不是空洞，则需要进行进程的交换，把某一进程移动；若内存和磁盘交换分区都满了，进程必须等待或杀死

进程大多需要动态的内存空间，频繁交换会带来等待的时间开销
解决方法：
- 每个进程申请空间时多分配一些内存空间
- 对于具有多个可增长的数据部分的进程，在进程的分区内分开放置这些数据部分，进行管理
![[Pasted image 20250528212911.png]]

操作系统需要对内存进行跟踪才能实现分配管理和回收，内存管理的方式主要有以下集中
#### 1. 使用位图的内存管理

操作系统会将物理内存划分为若干大小的内存块（页），然后使用位图中的一个位表示一个内存块的状态，值为0代表该内存块空闲；值为1代表该内存块被占用
操作系统需要分配内存时，会扫描位图找到一个值为 `0` 的位置，表示该内存块空闲。操作系统将该位置设置为 `1`，表示内存已被分配。
当程序释放内存时，操作系统将对应的位图位置设置为 `0`，表示该内存块变为空闲状态

可以看见，单个内存块越小，位图的位数就越多
缺陷：**定位的速度受限**，由于每个位图单元代表一个被分配的单元，所以**连续性不强**，对于某个需要几个分配单元大小的进程就很难快速在位图中找到这样连续的空间。故实际不很常用

#### 2. 使用链表的内存管理

通过一个链表来管理已经分配的和尚未分配的内存段，通过对链表的维护达到对内存的管理。这里的内存段可以使被某个进程所占用，也可以是个空洞
链表中每一节的内容包括：
- 段的性质
- 开始地址
- 长度
- 指向下一个链表表项的指针
一般来说按照地址进行排序，也可以使用双向链表来有效进行进程切换

此时，需要对空洞进行处理：将相邻的空洞表项进行合并，形成一个长度更大的空洞表项

### 进程分配的算法

在链表内存管理方法的基础上，应该如何为新创建和新交换进入的进程分配合适的内存项？有以下几种分配算法

#### 1. 首次适配算法

存储管理器沿着内存段链表，从头开始寻找足够大的内存段来装载进程，将它塞到第一个大小大于等于进程所需空间大小的内存段中
如果是内存段大于进程所需空间，需要将内存段拆分为一个被占用内存段+一个空洞内存段

快速搜索，搜索开销小

#### 2. 下次适配算法

在首次适配算法的基础上，每次搜索完毕后，记录当前位置，下次搜索从该位置开始向后搜索

#### 3. 最佳适配算法

寻找最合适该进程大小的内存空间，即大于等于进程所需空间大小的内存段中大小最小的那个内存段，将其放入该内存段中
需要遍历整个链表，搜索速度很慢
同时，会生成很小的新的空洞内存段，不便于管理使用


#### 4. 最差适配算法

每次都找最大的内存空间分给进程，产生的新的空洞内存段都是足够大的，可以被继续使用

上述四种算法都不够有效，一种改进检索效率的思路是把占用内存段和空闲内存段放置在两个不太的链表中进行检索，但是当一个占用内存段被释放后，需要经过删除+添加到另一个链表中的过程，比较麻烦
其他改进思路：
思路一）进程和空洞存放在两个链表中，针对最佳适配算法的缺陷，将空洞的组织不按地址，而是按照大小来组织，这样就减小了搜索时的开销。
**空闲内存段单独按照从大到小放置在另一个链表中**

思路二）进程和空洞存放在两个链表中，用空洞本身来存放这个链表，第一个字存放空洞的大小，第二个字存放下一个空洞的地址。
**空闲内存段中取一部分字节来存放大小和下一空闲内存段地址等信息**

思路三）快速适配法，按照常见进程需要的空间大小设置单独的链表，这种算法就根据进程所需空间的大小快速在这些特殊的空洞链表中查找空内存。它需要将所有的空洞进行排序，即进程换出时的空洞合并判断。
**设置常见进程大小的空闲内存段**

# 8. 虚拟存储器

除了交换技术，还有一种早期操作系统使用的覆盖技术
一个作业或几个作业的程序段部分共享同一个存储空间，将程序划分为程序段，前面部分的程序段执行结束后，把后续程序段调入内存，覆盖原有存储空间进行运行
此时作业的各模块的调用结构需要明确，程序员要向系统指明覆盖结构，因此这个过程对于程序员是不透明的（可见的），增加用户负担

交换和覆盖技术的相同点：
进程的程序和数据主要放在外存，当前需要执行的部分放在内存，内外存之间进行信息交换。

因此，现代操作系统还是以交换技术为主。在交换技术的基础上，衍生出了虚拟存储技术
虚拟存储器的基本思想是：
 程序、数据、堆栈的大小**可以超过内存的大小**，操作系统把程序**当前使用的部分保留在内存**，而**把其它部分保存在磁盘上**，并在需要时**在内存和磁盘之间动态交换**。

因此，虚拟存储器支持多道程序设计技术

虚存：将内存和外存结合起来得到更大的虚拟内存，程序正在使用的部分装入内存，其余部分留在外存，当需要使用到外存部分时，由系统将其从外存调入内存
MMU内存管理单元：负责地址的计算和重新定位，将虚拟地址交给MMU，MMU将物理地址送给存储器，完成地址映射

每个进程操作的都是虚拟地址，虚拟地址经过MMU处理之后得到物理地址才能进行寻址

![[Pasted image 20250528220620.png]]

- **虚拟页**：在虚拟内存中，**虚拟地址空间被划分为多个固定大小的页**，每一页叫做虚拟页。虚拟页的大小通常为 4KB 或其他固定大小。
    
- **物理页**：**物理内存同样被划分为固定大小的页**，称为物理页。虚拟地址通过映射关系被转换为物理地址，指向相应的物理页。
	
- **页框**：**物理内存中的存储区域**，用于**存储虚拟页的数据**。每个页框大小与虚拟页的大小相同。当虚拟内存的页面被映射到物理内存时，它们会占据一个或多个页框。

上图中的箭头就是虚拟页与物理页框的映射关系，**映射关系通过后文所叙述的页表来进行管理**
虚拟页可能不映射到任何一个物理页框，用X表示

虚拟页的大小和物理页框一致，必然存在空页，有些地址没有对应实际的物理内存
对于这样的页，使用一个标志位来标志其为空页，当访问到这个页中的地址时，出现缺页故障，进行中断，操作系统负责将一个被替换出去的页框写入磁盘，然后引入虚拟页所引用的页覆盖该页框的位置，重新启动指令

页表：索引页面，通过设置存在位等信息，标识页的状态，并且从页表中直接获取虚拟地址对应的实际物理地址
现代计算机的虚地址可能很大，导致页表过于庞大，地址映射（索引）效率变低

一种解决方式是把页表放入寄存器中，进程运行时检查页表即可，但是寄存器很贵，且每次进程切换都需要装入内存中的页表，开销也很大
将页表全部放入内存，只需要索引页表的起始地址，让寄存器改变即可，但是执行指令时需要多次访问内存，很少使用

多级页表：虚拟地址空间被划分为多个层次，每一层级的页表记录都指向更低一层级的页表或物理内存。目的是解决单一页表规模过大带来的时间和空间开销

多级页表中，典型的虚拟地址（例如 32 位或 64 位）的位数被划分成若干部分，用于索引不同层级的页表。
虚拟地址的分层：
- **最上层页表（一级页表）PD**：最高的几位用于索引一级页表（通常称为 Page Directory）。
    
- **第二层页表（页表）PT**：接下来的几位用于索引二级页表（通常称为 Page Table）。
    
- **页内偏移Offset**：最低的几位表示页内的偏移量。

页表的分层：
- **一级页表（Page Directory）**：用于存储指向二级页表的地址。一级页表的每一项包含一个指向二级页表的物理地址。
    
- **二级页表（Page Table）**：用于存储指向物理页框的地址。每个条目包含一个指向物理内存页面的物理地址。
    
- **页框（Page Frame）**：最终指向实际的物理内存页面，包含真实的存储数据

通过增加多级页表，减小每次索引需要寻找的范围，从而增加索引效率，减小空间浪费

对于底层的页表，其每一项的结构如下所示：
![[Pasted image 20250528223346.png]]

另外，页表使用具有不均匀性，因此还会使用硬件TLB来存放常用页号，以快速取得这些页，TLB中的页号不断更新
工作时，遇到虚地址，先从TLB中寻找，找不到再去页表中查询
现代操作系统中，缺页故障也都交给TLB处理，简化MMU的涉及

# 9. 页面置换算法

当发生缺页，而主存中已无空闲页架时，需选一页淘汰。选取淘汰页的方法叫页的置换算法。

抖动：被淘汰出去的页面不久后又被访问，随后又被淘汰出去，引起反复更换页面的现象，以至于系统的大部分时间花在页面的调度和传输上，效率很低

颠簸：进程执行过程当中，一个隔几个指令就发生一次页面故障的程序称为发生了颠簸。


缺页率：f = (缺页次数/访问页面总数)%

## 1. 最佳置换算法OPT

理想中的算法：  淘汰在将来再也不被访问，或者是在最远的将来才能被访问的页。
实际上无法进行预测

一般要考就会给出一个页面访问序列和进程页架数
3， ABCDABCDACD
一开始取ABC，然后在ABC中，寻找下一个页面访问序号在页面访问序列中离C最远的序号，将其排除，替换为D，以此类推

缺页率中的页面访问总数就是页面访问序列中的元素个数，这里是ABCDABCDACD=11
缺页数就按照算法流程数即可

## 2. 最近未使用置换算法NUR

在页表中，为每个页面设置两个硬件位—访问位和修改位
- 访问位= 0：该页尚未被访问过	R:读写时设置
        = 1：该页已经被访问过			
- 修改位= 0：该页尚未被修改过 	M:修改时设置
        = 1：该页已经被修改过

基本原则：淘汰最近未使用的页，且希望其在**主存**逗留期间页面内数据未被修改过
过程：
- 最初，所有页的访问位和修改位都是0
- 随着进程访问和修改，将其置为1
- 当需要淘汰一个页时，按照下面的顺序从前往后进行淘汰：未被访问未被修改-未被访问已被修改-已被访问未被修改-已被访问已被修改。**也就是被访问的页往后排**
- 周期性地对访问位清0，这个周期就决定了系统认为最近未使用的“最近”是什么时间范围

## 3. 先进先出置换算法FIFO

基本原则：选择最早进入主存的页面淘汰。因为最早进入的页面比近期进入的页面更可能被不使用

实现很简单，按照时间次序构成队列（链表或表格），每次淘汰队头页面即可

只有按照线性顺序访问地址空间时才是理想的，否则效率不高。
异常现象：对于一些特定的访问序列，随分配页架数增加，缺页频率反而增加！

## 4. 第二次机会页面替换算法

对FIFO进行改进：对页面的**引用位**进行检查，来判断这个页的使用情况，如果**未被引用，则替换掉此页**，如果不为0，表示此页**被使用过**，则**清除引用位为0**，并**放入队列最后**，将它当作新的页面来对待，从而保证了经常使用的页面能够被保持下来。
把被引用过的页面留下来


## 5. 时钟页面替换算法

第二次机会页面替换算法需要在链表中移动页面，因此使用循环链表的实现方式
原理同第二次机会算法一样，但只是实现方法不一样而已

## 6. 最久最少使用页面替换算法LRU

为页设定一个访问时间戳，检查时间戳选择最近一段时间内最长时间没有被访问过的页面淘汰。

需为每个页设置一个特定单元，记录上次访问后到现在的时间量 t，并选择 t 最大的页淘汰。无论硬件还是软件实现开销都很大！

## 7. 软件仿真的LRU算法

使用计数器追踪每个页面被引用的次数，每次淘汰掉计数器值最小的页面
弊端：保留了每次的访问信息，会影响到以后的页面的访问信息。
改进方案：计数器累加前先右移一位，R位累加到计数器的前端而不是后端。

# 10. 分页系统设计

从整体把握分页模块的设计
请调：根据需求将需要的页面调入内存中的工作方式
访问局部性：进程对页面访问的局部性，而且对于所有进程都有此特性（趋向于取时间和空间上靠近的页面）
工作集：一个进程当前使用的页的集合叫做此进程的工作集

颠簸：进程执行过程当中，一个隔几个指令就发生一次页面故障的程序成为在颠簸。

读入页面的开销远远高于指令执行的开销


预调：将常用的页作标识，则移出后之保留，进行跟踪，以后再调入的时候，根据这些信息来快速调入。从工作集的角度的优化

实际上内存中存在的是多个进程的页面，当其中某个进程发生缺页故障的时候，实际的替换应该有很多种方法，即涉及到了对某个进程的页面替换还是对整个内存中页面的替换的问题。

- 局部页面替换策略：替换页面时只从此进程拥有的页面中进行淘汰
- 全局页面替换策略：只关心页面的年龄进行淘汰，而不关心属于哪个进程（每个进程的页框数可以变化）

一般来说，全局优于局部：
- 局部：当内存中有空页框的时候，仍然在自己固定的段内替换，会导致很高缺页率；工作集增大，颠簸变大，工作集变小，内存又会被浪费。

- 全局：系统需要不断确定该给不同的进程多少页框，但是由于工作集变化的过快，跟踪年龄位也很难实现。
	- 可以定期为当前进程平均分配同等页框，但进程的大小不同，这种分配仍不合理；也可按照进程大小来分配；或者为每个进程规定最小页框数，这样可保证每个进程都可以执行。

所有方案都是为了减少颠簸，可以将颠簸次数直接计算，控制页框数量在颠簸数量适中的区间（PFF算法）

**内零头**:是指在内存分配过程中，**已分配的内存块内**存在**未使用的空间**
内零头的平均大小为 段数×页长/2。

温馨提示：
外零头是指内存中存在大量的小的未使用空间，但这些空间都不连续，无法满足分配一个足够大的内存块的需求。换句话说，外零头是在系统中分配和释放内存时，造成的大量小空闲区域的碎片。外零头通常是动态分配内存的结果

![[Pasted image 20250528230554.png]]

# 11. 分段与段页式

段式虚拟存储器：将程序的地址空间划分为多个逻辑段，每个段包含一个特定类型的数据或代码

常见的段有：

1. **代码段（Code Segment）**：存放程序的指令。
    
2. **数据段（Data Segment）**：存放程序运行时使用的变量。
    
3. **堆栈段（Stack Segment）**：用于存储函数调用时的局部变量、返回地址等。

分段的方式使得数据的组织更加具有逻辑性

直接进行分段的缺点：当各个部分在一维空间中增长的时候，会进入到邻接块中，而且某一部分会增长迅速，填满自己的空间，而其他部分仍有大量空余空间。

为此，采用独立分配：每个段都具有自己独立的地址空间，不必担心与其他段的地址冲突，每个段的长度可以在运行时根据需要增长或减少大小，不受其他段的影响
![[Pasted image 20250529095902.png]]
这种方式，确保了段的灵活性，避免固定大小段分配中的限制，解决了内存中存在未使用的空闲空间且这些空闲空间不足以容纳一个完整的段，导致出现外零头问题的现象

在分段式虚拟存储器中，每个程序段都有一个段名，且有一个段号。段号从0开始，每一段也从0开始编址，段内地址是连续的。
因此，一个**逻辑地址=段号+段内地址（段内偏移量）**

可以对不同的段进行不同的控制，例如要求只读、只执行等，设置段的标志来进行标识

分段方法能够便于单独进行编译和连接，便于程序的修改，并且多个进程可以共享同一部分数据或过程，以节省地址空间的使用

使用段表进行映射




## 段页式内存管理
分段和分页式的差别：根本差别是页定长而段非定长

段非定长的后果是系统在运行一段时间后的内存会变得混乱，有些空闲空间不足以容纳整个段而被浪费（跳棋盘现象）
对于这些零散的空间，需要通过紧缩的方式将其合并为一个较大的连续空闲空间

由于分段式和分页式各自有自己的优点和缺点
分页：统一的页面大小，只用段的一部分时，并不用全部调入内存；
分段：易于编程、模块化、保护和共享。
因此考虑将分段和分页式结合起来作为段页式内存管理：

在这种内存管理方案中
虚拟地址=段号+页号+页内偏移
首先将程序的地址空间划分为多个逻辑段，每个段中存储的对象类型一致，例如代码段、数据段、堆栈段等，每个段的长度可以不同，段大小可以动态变化
然后将每个段内部按照固定大小划分为页面，每个页面可以单独映射至物理内存的任何区域

地址转换过程中，首先根据段号查询段表找到该段在物理内存中的起始地址与长度，然后根据页号查询页表找到在物理内存中的页框号，最后根据页内偏移计算出最终的物理地址
MULTICS使用段页式内存管理方案：
进行内存访问时，执行的算法是：
1.由段号找段描述符；
2.判断段的页表是否在内存中，如果在，就找到位置，如果不在，就发出段故障，如果违反保护要求就发出故障；
3.检查所请求虚页的页表项，页面不在内存就发出一个页面故障，在就从页表项中取出此页在主存中的起始地址；
4.将偏移地址加到页的起始地址上得到字主存中的地址；
5.最后进行读或写操作。

## 分页、分段、段页式内存管理方案特征与优缺点

1. 分页式：
	1. 特征：将物理内存和虚拟内存划分为大小固定的块，称为页框（物理）和页面（虚拟），页面和页框大小相同，维护页表以存储虚拟页面到物理页框的映射关系，虚拟地址包括页号和页内偏移
	2. 优点：内存分配固定，因此不会出现外零头问题，能够完整利用空闲空间，且页表管理简单，支持访问比物理内存更大的虚拟内存
	3. 缺点：会出现内零头问题，每个页面中可能存在许多程序没有使用的内存空间；且当虚拟内存较大时，页表体积过大带来的索引效率慢和管理的开销大（可以通过多级页表来优化）
2. 分段式：
	1. 特征：根据程序的逻辑结构将地址空间划分为多个段，每个段包含特定类型的内容，具有独立的起始地址和大小，段的大小可以动态调整。通过记录了每个段的起始地址和大小的段表来管理段信息
	2. 优点：每个段可以根据需求动态调整大小，具有灵活性；分段的方式使得数据的组织更有逻辑性；将程序逻辑划分允许对于不同的部分模块进行修改，提高了可维护性，支持动态共享库技术，节省内存空间
	3. 缺点：由于动态调整大小的机制，容易出现外零头问题，可能导致不足以容纳整个段的空洞出现，浪费内存空间；地址转换复杂，需要先查找段表，再通过偏移量定位，且多个段的管理困难
3. 段页式：
	1. 特征：结合分段和分页式内存管理，首先将程序的地址空间逻辑划分为多个段，由段表进行索引，然后再将每个段按照固定的大小划分为多个页面，由页表进行管理
	2. 优点：灵活高效，且通过处理段内的内存分配，可以减少外零头的出现可能，支持更大的虚拟内存并保留逻辑结构
	3. 缺点：管理复杂，每次使用虚拟地址寻址需要经过段表和页表的两级查找，且存储段表和页表具有额外的开销


补充：
缺页故障：程序在访问虚拟内存中的某个页面时，发现该页面没有在物理内存中所对应的页框，因此向操作系统报告缺页故障，产生中断，由操作系统负责将该页面从磁盘中加载到物理内存中

产生原因：
页面未加载至物理内存中，出现频繁缺页故障的原因可能是：
- 因为程序的工作集发生变化或大小超过物理内存的容量；
- 程序的虚拟内存访问模式不具有连续性，频繁跳跃到不同的页面中；
- 内存管理的页面置换算法不够高效，产生震荡，被频繁访问的页面被替换出去了；
- IO操作引起页面的缺失

解决方案：
- 增大页面的大小
- 优化程序的时间局部性和空间局部性
- 使用更高效的页面置换算法
- 增大物理内存
# 12. 文件

文件的出现所期望解决的问题：
- 能够存储大量的信息；
- 进程使用信息后，即使结束，也该保存好信息；
- 多个进程可以并发的存取信息。

文件：一组带标识的在逻辑上具有完整意义的信息项序列，标识就是文件名
操作系统中，文件是信息的组织者和承担者，不受一般进程影响，为进程提供信息
文件管理（组织结构、命名规则、存取控制、安全保护等）都由操作系统实现，这个模块称为文件系统

数据项：最低级的数据组织形式，分为基本数据项（字段，是数据组织中可以命名的最小逻辑数据单位）和组合数据项（组项，由若干基本数据项组合而成）
记录：一组相关数据项的集合，用于描述一个对象在某方面的属性
关键字：唯一标识一个记录的一个或多个数据项

## 1. 文件命名
不同系统的的文件命名规则有所不同，有限长度的字符串+文件扩展名的形式比较常见，文件扩展名指示了

## 2. 文件结构

常见的文件结构有三种：
1. 无结构字节序列：操作系统不关心文件的内容，文件的含义在用户程序中。因此文件只是一堆字节序列，可以由用户方便进行读写，但系统不提供任何帮助
2. 记录序列结构：文件按照固定的记录长度组织，每次读取文件时，系统按照顺序读取记录，返回一条记录。当文件新增内容时，将新记录添加到文件的末尾。由于记录长度固定，文件在存储时可以直接结算出每条记录的位置
3. 记忆树结构：将文件记录组织成树状结构，每个记录的长度可能不同，但是在固定位置都具有一个关键字域，记录树按照关键字进行排序，操作系统负责记录存放的位置。能够非常方便地进行信息的检索

文件分类：
- 正规文件：包含用户信息的文件
- 目录文件：用于管理文件系统结构的文件
- 设备文件：用于模拟外部IO设备或磁盘的文件
主要研究的是正规文件

正规文件：
- ASCII文件：由多行ASCII字符组成，换行使用回车或换行符，每行长度可能不同。方便编辑和打印
- 二进制文件：由二进制位组成的文件，难以直接阅读，不同二进制文件有不同的结构，由对应程序进行读取修改和执行

根据文件性质与用途，可以分为：
- 系统文件：由系统软件构成的文件，只允许用户调用，但不可修改
- 用户文件：由用户的源代码、目标文件、可执行文件和数据等组成的文件，用户将这些文件委托系统保管
- 库文件：由标准子例程和常用例程等所构成的文件，只允许用户调用而不能修改

UNIX根据组织形式和处理方式分类：
- 普通文件：由ASCII码或二进制码组成的字符文件
- 目录文件：由文件目录组成的文件
- 特殊文件：特指的系统中的各类IO设备，将IO设备视为文件以进行同统一管理

另外根据文件内容分类：
- 可执行文件：由五部分组成，程序装入内存中根据这些部分的内容进行重定位来运行
- 存档文件：由许多编译过但未链接的库过程或模块组成，每个模块具有模块头，列出了模块名、创建时间等信息

## 3. 文件存取方法

常用的文件存取方法
1. 顺序存取法：按照文件的逻辑地址顺序存取，在记录式文件中反映为按照记录的排列顺序存取；在无结构字符流文件中则是读写指针的变化
2. 随机存取法：允许用户根据记录的编号来存取文件的任意记录，或是根据命令把读写指针移动到相应位置读写
3. 按键存取法：在复杂文件系统中，根据给定的键或记录名进行存取，在数据库管理系统中常用


文件属性：操作系统赋予文件的属性，包括创建日期、文件长度等等额外的属性

# 13. 目录

多数系统中，目录也是一种文件

文件控制块FCB：操作系统为了管理文件而设置的数据结构，存放了文件名、文件号、文件地址等等为管理文件所需的所有有关信息，是文件存在的标志

文件目录：将所有的FCB组织在一起，形成的文件控制块的有序集合
目录项就是FCB

目录的组织方式：
1. 最早最简单的方式：只需要维护一个单独的目录，其中包含所有用户的文件。在用户变多时出现混乱而无法工作
2. 较好的方式：按照用户进行管理，为每个用户分配一个目录，文件放置在对应目录下，所有文件是平行的，相互关系无法组织管理，缺乏条理
3. 理想方式：每个用户具有自己的目录，且能在目录下面创建新的目录，按照自己的方式组织文件

绝对路径：最常见的直接索引文件在系统中的具体位置的方式，指示从根目录开始经过多个子目录到文件的直接具体位置
相对路径：和工作目录一起使用，相对于工作目录的路径

特殊目录：创建目录时默认出现的目录，例如.代表当前目录，..代表父目录


# 14. 文件系统实现

## 1. 文件中的数据在磁盘上的存储方式

系统对数据进行存储、修改、检索的方法一般有以下几种

### 1. 连续分配

将文件做成连续的数据块放置在磁盘上，根据磁盘上块的大小来划分本体

优点：只需要记录每个文件的首存储块地址，文件读取操作简单
缺点：一次存储困难，文件的大小必须预先知道且不再变动，会产生磁盘碎片，浪费空间

### 2. 链接表分配

改进的连续分配：不再连续地存放文件数据块，而是通过链接表将各个分散的块链接起来
链接表中，每个块的第一个字是指向下一个链接块的指针，其余部分用于存放数据

优点：减少磁盘碎片（外零头），充分利用磁盘空间，且只需要记录第一个块的地址，顺序读取方便
缺点：随机存取困难，指针占用一定空间，寻址和取数据时需要花费时间

### 3. 使用索引的链接表分配

在内存中建立每个磁盘块的指针，建立索引将指针放入索引表，查询索引表以检索每个文件具有的磁盘块，实现随机存取

优点：表中每一项内容也都是指向下一物理块的地址，但是在表中检索很快，因为是在内存中顺着链表移动的
缺点：磁盘较大时链接表较大，放入内存空间占用大

### 4. i结点

为每个文件赋予一张小型的索引表，列出文件的属性和各个块在磁盘上的地址，每个文件都有这样的表
文件小的时候，直接通过索引表得到磁盘块地址；文件大的时候，使用间接块的方式索引
间接块：一级间接块包含附加的磁盘地址；二级间接块包含很多一级间接块的地址；三级间接块包含很多二级间接块的地址，以此类推

# 15. 目录结构

## CP/M中的目录结构

该系统中只有一个唯一的目录，因此找到目录项就知道了文件磁盘号
所以目录项包含的信息就比较多了：
![[Pasted image 20250529130507.png]]
在文件过大，目录项的磁盘块号容纳不下的时候，分配额外的目录项

## MS-DOS目录结构

该系统是属于层次目录系统，目录项中保存第一个磁盘块的块号
![[Pasted image 20250529130856.png]]

## UNIX目录结构

UNIX采用i结点目录结构，是目录项最简单的目录结构，每个目录项包含文件名及其i结点号，打开文件时根据给出的文件名找出它所在的磁盘块
![[Pasted image 20250529130947.png]]

UNIX中，查找一个路径的方式是：首先找到根路径，然后在根目录中找到下一个子目录的i结点号，定位到该目录结点，然后查找下一部分，以此类推，直到定位到文件

## 分块存储

连续地存储文件会导致文件增大时出现文件的整体移动，因此一般的系统都使用分块存储的方式

分块存储时，块大小的分析非常重要：块过大，对于平均文件较小的系统，磁盘空间浪费严重；块过小，每个文件又需要多个块，取出效率很低
磁盘空间的利用率与读取磁盘的速率是互相矛盾的：当空间利用率降低的同时，磁盘数据的读取速率也在提高，因此时间效率和空间效率本质上是相背的。

折中的方式是根据模拟的曲线，选择块大小为512、1K或2K字节

## 记录空闲块的方法

### 1. 链接表

将所有空闲块链接成一个链表

### 2. 位图法

使用一串二进制位反映磁盘空间中的分配使用情况，每个物理块对应一位，被分配的物理块设置为1，否则为0，申请物理块时查找为0的块置1，归还时将块置0

描述能力强，适合多种物理结构

## 文件可靠性保证

可靠性：系统抵抗和预防各种物理性和人为性破坏的能力
通过备份：转储操作，形成文件或文件系统的多个副本
海量转储：定期将所有文件拷贝到后援存储器。
增量转储：只转储修改过的文件，即两次备份之间的修改，减少系统开销。

一致性：文件需要经过从磁盘块取出至内存，再从内存写回到磁盘块的过程，若在写回之前发生系统崩溃，则文件系统可能出现不一致

解决方式是设计一个程序在系统重新启动时，检查磁盘块和目录系统的一致性

UNIX中的一致性检查工作如下：
维护两张表格，表中的每个块对应一个计数器，初值为0
表格1：记录每块在文件中出现的次数
- **目的**：该表确保每个磁盘块都只会出现在文件中一次，避免重复使用。
    
- **操作**：每当文件系统操作（如创建、删除文件或修改文件）时，都会更新这个表，记录块的使用情况。

表格2：记录每块在空闲块表中的出现次数
- **目的**：保证文件系统中所有磁盘块的状态（空闲或已用）是准确的。
    
- **操作**：每当文件系统执行如格式化、卸载或系统崩溃恢复时，都会通过此表检查和恢复磁盘块的状态。

如果某个块在表2中标记为空闲，但在表格1中被文件使用，说明发生了错误，由系统进行恢复

## 块高速缓存-磁盘服务

系统中在内存中保存一些块，逻辑上这些块是属于磁盘的
对于读请求，首先看所需要的块是否在高速缓存中，如果在，直接进行读操作，若不在，则需要把块读到高速缓存中
若高速缓存已满，则需要淘汰其中的块

UNIX中会使用每30秒进行一次sync的方式，保持一个较高的更新频率，以减少崩溃带来的数据损失
MS-DOS则是直写高速缓存，数据修改后直接写入磁盘，因此磁盘IO访问量极大

文件写入的三个步骤：
1. 从data block bitmap中分配一个数据块；
2. 在inode中添加指向数据块的指针；
3. 把用户数据写入数据块。

其中每一个步骤出错了都会出现问题
日志文件系统就是为了解决这些问题的：在进行写操作之前，把即将进行的各个步骤（称为transaction）事先记录下来，保存在文件系统上单独开辟的一块空间上，这就是所谓的日志(journal)
记录完日志之后，再进行真正的写

为了避免保存日志过程中出现问题，实际上是这么做的：给每一条日志设置一个结束符，只有在日志写入成功之后才写结束符，如果一条日志没有对应的结束符就会被视为无效日志，直接丢弃

## 磁盘访问

一次访盘时间=寻道时间+旋转延迟时间+存取时间
减少访问时间可以通过减少寻道时间和延迟时间完成，因为存取时间很短，几乎不需要考虑
（寻道：寻找磁盘上对应的柱面磁道的过程；延迟时间：等待磁盘旋转至数据起始位置的时间）
### 1. 先来先服务

按照访问请求的次序，进行磁盘访问
简单公平，但效率不高，因为两次请求可能访问距离很远的两个磁道，使得磁头反复移动，增加服务时间

### 2. 最短寻道时间优先

优先选择距离当前磁头最近的访问请求进行服务

优点：改善了磁盘的平均服务时间
缺点：某些访问请求长期等待不到服务

### 3. 扫描算法（电梯算法）

当没有访问请求时，磁头不动；当有访问请求时，按照一个方向移动，移动过程中判断该方向上是否还有访问请求，对遇到的访问请求进行服务，如果有就继续扫描；否则，改变移动方向，继续判断该方向上是否有访问请求，以此类推

# 16. 文件系统安全

安全性：确保未经授权的用户不能存取某些文件
保护机制：用于保护计算机信息的特定操作系统机制

文件系统安全的重要问题：
- 数据丢失（使用备份）
- 入侵者：需要判断是积极的还是消极的入侵者

病毒：特殊的安全性攻击

安全性的设计原则：系统设计必须公开，缺省属性不可访问；为每个进程赋予一个最小的可能权限；保护机制应该简单一致，嵌入到系统底层

保护域：计算机中需要保护的对象，每个对象具有对应的一系列操作，限制每个对象能够执行的合法操作的集合

文件的保护域主要通过 **访问控制** 来实现，即通过一组 **访问权限** 来限定不同**用户**对文件的操作
一个文件可以出现在不同的域，在不同域中权限可以不同
以 **UNIX/Linux** 系统为例，文件的保护域可以通过 **文件权限（rwx）** 来设定：

- 每个文件都有三个基本的权限集：所有者（owner）、所属组（group）和其他用户（others）。
    
- 比如一个文件权限设置为 `rwxr-xr--`，意味着：
    
    - **所有者（Owner）**：具有读、写和执行的权限（rwx）。
        
    - **所属组（Group）**：具有读和执行的权限（r-x）。
        
    - **其他用户（Others）**：只有读权限（r--）。


UNIX系统中使用保护矩阵（UID, GID)来描述域，将文件及对象与域对应起来，行是文件列是域，

保护矩阵的空间浪费较大，进行优化后使用存取控制表：对于每个文件，有三元组（用户， 用户组， 权限），权限就是RWX，没有的权限位置使用-代替
权限表：为每个进程赋予一张该进程可以访问的对象表以及每个对象可以执行的操作

权限表需要被保护起来：使用特征位/放入操作系统内部/加密后放入用户空间等

# 17. 补充

1. 操作系统引入信号量的原因
操作系统引入信号量和P/V操作的主要目的是为了实现 **进程同步** 和 **进程间互斥**，以避免在并发执行的多进程环境中出现竞态条件（race condition）和资源冲突。信号量机制的引入解决了以下几个问题：

2. **互斥**：多个进程/线程对共享资源的并发访问可能会导致资源的冲突和不一致。信号量可以保证在同一时刻只有一个进程可以访问某个临界资源，从而避免资源访问冲突。
    
3. **同步**：当进程A的执行依赖于进程B的执行结果时，信号量可以帮助进程A等待进程B完成任务。信号量机制能够保证进程按一定顺序执行。

### P/V 操作的概念

P/V 操作（也叫做 **Wait/Signal 操作**）是信号量机制中的两种基本操作。其名称来源于荷兰语的 **Proberen (P)** 和 **Verhogen (V)**，分别表示“试图”和“增加”。

- **P 操作 (Wait, down)**：如果信号量的值大于 0，执行此操作后信号量的值减 1，表示资源占用或者一个进程进入临界区。如果信号量的值为 0（即没有资源可用），该操作会阻塞当前进程，直到信号量值大于 0。
    
- **V 操作 (Signal, up)**：执行此操作时，信号量的值增加 1，表示释放一个资源或让某个被阻塞的进程得以继续执行。如果有进程在等待这个信号量，操作系统会唤醒其中一个等待的进程。

- **临界区（Critical Section）**：  
    临界区是指在多任务或多线程程序中，共享资源（如内存、文件、变量等）的访问代码段。因为多个进程或线程可能同时访问这些共享资源，因此必须进行适当的同步和互斥，以避免竞态条件（race condition）。临界区内的代码必须保证在任何时刻只有一个进程或线程能进入，以确保数据的一致性和正确性。为了避免多个进程或线程同时访问临界区，操作系统通常提供同步机制（如信号量、互斥锁等）。
    
- **临界资源（Critical Resource）**：  
    临界资源是指多个进程或线程共享的资源，当这些资源的访问没有适当控制时，可能会引发问题（如数据破坏、死锁等）。典型的临界资源包括共享内存、文件、打印机等硬件资源。为了确保系统的稳定性和数据的完整性，访问这些资源时需要进行适当的同步控制，例如通过互斥锁、信号量等方式限制同时访问。
    
- **信号量（Semaphore）**：  
    信号量是操作系统用于进程或线程同步的一种机制，它通过一个整数值来表示对资源的控制。信号量主要有两种类型：
    
    - **二值信号量（二进制信号量）**：值为 0 或 1，常用于实现互斥锁。在多线程环境中，二值信号量可以确保只有一个进程或线程访问临界区。
        
    - **计数信号量**：信号量的值可以是任意非负整数，用于表示对多个同类资源的访问控制。例如，限制某一时刻只有一定数量的进程可以访问某个资源。
        
    
    信号量提供两个基本操作：
    
    - **P 操作（wait, down）**：将信号量的值减 1，如果信号量的值为 0，则进程阻塞，直到信号量的值大于 0。
        
    - **V 操作（signal, up）**：将信号量的值加 1，如果有进程在等待该信号量，则唤醒其中一个进程。


1. **文件索引表（File Allocation Table，FAT）**：  
    文件索引表是一种文件系统结构，用于管理存储介质（如硬盘）上的文件分配和存储位置。FAT 文件系统将硬盘划分为多个簇（cluster），并通过文件索引表记录每个文件数据簇的位置。索引表中的每个条目对应存储设备上的一个簇，指向下一个簇的位置，从而实现文件的存储和读取。当文件被保存到磁盘时，FAT 会记录该文件的起始位置及后续簇的链表，确保文件在磁盘上的正确存储。
    
2. **管道文件（Pipe）**：  
    管道文件是用于在操作系统中进行进程间通信（IPC, Inter-Process Communication）的一种机制。管道可以将一个进程的输出直接作为另一个进程的输入。在类 Unix 操作系统中，管道可以分为“匿名管道”和“命名管道”：
    
    - **匿名管道**：在两个相关联的进程之间进行数据传输，通常通过管道符（`|`）在命令行中使用。例如，`command1 | command2` 会将 `command1` 的输出传递给 `command2` 作为输入。
        
    - **命名管道（FIFO）**：具有名字的管道文件，允许无关的进程进行通信，通常存在于文件系统中，进程可以通过文件名进行访问。
        

管道文件通常用于在不同进程之间传输数据，且是一种半双工的通信方式（即数据只能单向流动）。


### 1. **全局性页面调度算法（Global Page Replacement Algorithm）**

**定义**：  
全局性算法是在整个系统的所有进程之间进行页面替换。即，系统会根据所有进程的内存需求来选择需要替换的页面，而不仅仅是一个进程的页面。

**典型算法**：

- **最少使用页面替换算法（LRU）**：系统根据所有进程的页面使用频率来进行替换，选择最少使用的页面进行替换。
    
- **先进先出（FIFO）**：系统根据所有进程的页面加载顺序来选择最早加载的页面进行替换。
    

**优点**：

- **更高的内存利用率**：全局性算法可以利用整个系统的内存资源，避免因单一进程占用过多内存而导致的内存浪费。
    
- **系统整体效率较高**：在进程较多时，系统能够更灵活地调配资源，提高整体性能，尤其是在多任务环境下。
    

**缺点**：

- **可能导致个别进程的性能下降**：虽然全局性算法提高了整体的内存利用率，但某些进程可能因为其他进程频繁调入页面而导致频繁的页面替换，影响进程的性能。
    
- **无法保证每个进程有足够的内存**：一个进程可能会因为全局性替换策略而经常发生页面缺失（page fault），即使该进程的内存需求较高。
    

### 2. **局部性页面调度算法（Local Page Replacement Algorithm）**

**定义**：  
局部性算法是指每个进程只能从自己的页面集内进行页面替换，而不能影响到其他进程的页面。每个进程都有自己独立的页面调度决策，页面替换仅在进程的页面集合中进行。

**典型算法**：

- **最少使用页面替换算法（LRU）**：每个进程独立进行LRU页面替换，根据各自的页面使用情况决定替换。
    
- **先进先出（FIFO）**：每个进程独立进行FIFO页面替换，替换进程自己页面中的最早加载的页面。
    

**优点**：

- **保证每个进程的内存独立性**：由于每个进程只会替换自己所占用的页面，因此不会影响其他进程的性能。这样，个别进程不会因为其他进程的内存需求而导致性能下降。
    
- **较好的局部性能**：对于长期运行的进程，局部性调度算法能有效地提高进程内的页面命中率，避免了过多的页面置换。
    

**缺点**：

- **较低的内存利用率**：每个进程独立管理自己的页面替换，可能会导致某些进程的内存使用不足，而其他进程有较多内存占用。整体内存资源的利用率可能不如全局性调度。
    
- **进程间资源共享困难**：由于局部性策略对进程进行独立调度，进程之间的资源共享可能不如全局性调度高效，尤其是在需要频繁切换页面的多任务环境中。